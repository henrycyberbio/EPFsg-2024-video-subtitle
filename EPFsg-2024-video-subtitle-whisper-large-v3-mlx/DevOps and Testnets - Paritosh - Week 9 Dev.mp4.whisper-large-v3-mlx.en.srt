1
00:00:30,000 --> 00:00:54,379
 Thank you.

2
00:01:00,000 --> 00:01:29,980
 Thank you.

3
00:01:30,000 --> 00:01:40,000
 ¶¶

4
00:01:40,000 --> 00:01:50,000
 ¶¶

5
00:01:50,000 --> 00:02:00,000
 ¶¶

6
00:02:00,000 --> 00:02:10,000
 ¶¶

7
00:02:10,000 --> 00:02:20,000
 ¶¶

8
00:02:20,000 --> 00:02:30,000
 ¶¶

9
00:02:30,000 --> 00:02:59,979
 Satsang with Mooji

10
00:03:00,000 --> 00:03:29,979
 Thank you.

11
00:03:30,000 --> 00:03:59,979
 Thank you.

12
00:04:30,000 --> 00:04:51,519
 All right.

13
00:04:51,519 --> 00:04:57,019
 Welcome back to the Ethereum Protocol Fellowship Study Group.

14
00:04:57,019 --> 00:05:02,120
 We are here on week nine, only a couple weeks left.

15
00:05:03,219 --> 00:05:08,359
 And today we are here with Pari Tosh from EF DevOps,

16
00:05:08,680 --> 00:05:15,859
 who is going to be talking about some test nets and prototyping and all sorts of fun stuff.

17
00:05:16,019 --> 00:05:20,639
 So I'll go ahead and let Mario introduce Pari a little bit more deeper here,

18
00:05:20,680 --> 00:05:22,399
 and we'll get started.

19
00:05:22,979 --> 00:05:23,939
 Thanks for being here, Pari.

20
00:05:25,500 --> 00:05:26,279
 Hey, Pari.

21
00:05:26,279 --> 00:05:35,000
 it's amazing to have charters here because uh we already had a presentation by mario before

22
00:05:35,559 --> 00:05:41,639
 uh montague um we've been talking about testing and i mentioned it is important in testing the

23
00:05:41,639 --> 00:05:48,039
 merge and so on but uh the merch also would not happen without pari and uh ef devops or

24
00:05:48,039 --> 00:05:55,799
 as they became during the merge actually the panda ops uh team working on uh testing tooling

25
00:05:55,800 --> 00:06:02,199
 uh on prototyping tooling on uh these devs tools which not just uh enable the thing itself but

26
00:06:02,199 --> 00:06:10,439
 making it easier for developers to uh run uh local or public business uh shadow forks and uh and they

27
00:06:10,439 --> 00:06:16,759
 uh and and they develop uh some tools which can help you to monitor even your own nodes and uh

28
00:06:17,400 --> 00:06:23,319
 that's what this is so lots of interesting stuff uh the panda albums became a powerhouse of these

29
00:06:23,319 --> 00:06:29,639
 things and uh and papari is the it's kind of the face of uh breaking the test nets and creating

30
00:06:29,639 --> 00:06:34,920
 new ones uh ethereum so it's it's really great to have you here um i think we can we can get

31
00:06:34,920 --> 00:06:41,480
 into it uh get the presentation ready so so the stage is yours yeah it's a temporary perfect

32
00:06:42,360 --> 00:06:48,120
 thank you guys for having me again um so today i'm going to be talking about uh testing and

33
00:06:48,120 --> 00:06:53,560
 prototyping Ethereum upgrades, which might be an interesting topic for a lot of you, because

34
00:06:53,560 --> 00:06:58,120
 I'm assuming through the protocol studies, once you're done with this, you would want to

35
00:06:58,120 --> 00:07:04,879
 try out making changes to Ethereum. And the nicest part is because everything is open source,

36
00:07:04,879 --> 00:07:12,879
 you can run it yourself. And it might just, there's quite a bit of a learning curve in

37
00:07:12,879 --> 00:07:18,060
 running a fresh network where you're not ruining anything, or you're not breaking someone's system.

38
00:07:18,120 --> 00:07:22,800
 So we've been trying to make that easier. We've been trying to make the concept of prototyping easier.

39
00:07:23,819 --> 00:07:27,139
 And through that, we've also built a lot of new testing tools.

40
00:07:27,240 --> 00:07:30,800
 So I'm going to introduce a couple of those concepts to you today.

41
00:07:32,160 --> 00:07:35,879
 So the first thing I want to just set the stage, right?

42
00:07:36,579 --> 00:07:40,360
 Ethereum has something like 20 plus client combinations.

43
00:07:40,360 --> 00:07:43,500
 There's more every week, every month.

44
00:07:43,500 --> 00:07:51,399
 um we're recently going to start um onboarding the lambda class elixir client we worked on

45
00:07:51,399 --> 00:07:56,980
 onboarding the grandin client over the last month so it feels like the number of combinations and

46
00:07:56,980 --> 00:08:03,740
 this matrix keeps increasing because we try to test each and every el with each and every cl

47
00:08:03,740 --> 00:08:11,379
 so even having like one new client adds 10 new systems for 10 new columns in the matrix matrix

48
00:08:11,379 --> 00:08:19,000
 for us debugging them also gets really difficult as you can imagine you kind of have to get a bit

49
00:08:19,000 --> 00:08:24,259
 into each and every you have to get in the intricacy of each and every EL and CL

50
00:08:24,259 --> 00:08:30,800
 and we had to figure out how to reliably test all of these things it didn't help if one person ran

51
00:08:30,800 --> 00:08:38,159
 a script on one machine and then this says trust me it works up until the merge I think we mostly

52
00:08:38,159 --> 00:08:45,439
 just did single client testing. So you would test Geth in itself, you would test Nethermind

53
00:08:45,439 --> 00:08:48,740
 in itself, and maybe there were one or two test suites where you would test Geth and

54
00:08:48,740 --> 00:08:53,759
 Nethermind together, but not that many. So over the last year or two years, we've been

55
00:08:53,759 --> 00:08:58,159
 focusing a lot on getting this interop level testing. So you have all of these clients

56
00:08:58,159 --> 00:09:03,299
 spinning up and ensuring that they're all working equally well, irrespective of if they're

57
00:09:03,299 --> 00:09:09,699
 majority client or not um and another thing is that every upgrade is going to inherit some of

58
00:09:09,699 --> 00:09:15,899
 this complexity so we're trying to build something such as that is a bit expandable so if you build

59
00:09:15,899 --> 00:09:20,799
 it once you can use it for the next few upgrades we don't want to re-envision the testing stack

60
00:09:20,799 --> 00:09:25,199
 for each and every upgrade that just adds a lot of toil adds a lot of time so we're trying to keep

61
00:09:25,199 --> 00:09:31,139
 things as generic as possible and with anyone who's worked with software in the past that can

62
00:09:31,139 --> 00:09:36,919
 be very hard because we don't even know what's coming on ethereum um so how are you generalizing

63
00:09:36,919 --> 00:09:42,480
 something without knowing it right and i'll go a bit into how we've attempted to tackle the problem

64
00:09:42,480 --> 00:09:49,659
 at least and competences for ELs and CLs are quite separate so um different teams look build

65
00:09:49,659 --> 00:09:56,100
 different clients there's not that many people who have an overlap of the entire stack so we try

66
00:09:56,100 --> 00:10:01,460
 to separate testing in such a way that it's also conducive to it. So we first try to figure out,

67
00:10:01,460 --> 00:10:07,460
 is this a CL issue? Is this an EL issue? Then we try to escalate in those directions. So

68
00:10:08,100 --> 00:10:14,340
 it's kind of pointless if you escalate every CL bug to all the EL devs, that's just how you get

69
00:10:14,340 --> 00:10:24,420
 people ignoring bugs. So the next kind of step of the introduction is a really big part of our

70
00:10:24,419 --> 00:10:31,139
 testing stack uh they're called dev nets so you might have interacted with test nets in the past

71
00:10:31,139 --> 00:10:37,539
 the major difference is that dev nets are really short-lived about maybe even a few months and then

72
00:10:37,539 --> 00:10:44,019
 they're down there's absolutely no um long-term support for dev nets and they might even be local

73
00:10:44,019 --> 00:10:50,259
 they might just last like half an hour test nets on the other hand are more public we have a reliable

74
00:10:50,259 --> 00:10:56,500
 testnet schedule right now so you can expect testnets like go girly uh sorry not girly but

75
00:10:56,500 --> 00:11:02,819
 holsky and sepolia to last for a certain number of years you can expect the network to be up

76
00:11:03,460 --> 00:11:10,100
 so the devnets themselves are um testing mirror of the ethereum base layer so they have the same

77
00:11:10,100 --> 00:11:16,980
 components that ethereum main net has uh they contain execution clients they contain consensus

78
00:11:16,980 --> 00:11:22,500
 layer, beacon node clients, it can contain validators, you have MEV infrastructure on there.

79
00:11:24,259 --> 00:11:30,740
 And the way we do it is because we control the entire devnet ecosystem, we can set it up in

80
00:11:30,740 --> 00:11:36,519
 whatever configuration that we want. So you could imagine that for whatever reason, we want to test

81
00:11:36,519 --> 00:11:43,300
 a super majority bug, right? So we can set up that a majority of client validators are running a

82
00:11:43,299 --> 00:11:50,819
 specific client and we can simulate that incident. So having this level of control on devnets allows

83
00:11:50,819 --> 00:11:56,399
 us to deploy forks and changes without affecting mainnet, without affecting any stable testing

84
00:11:56,399 --> 00:12:03,939
 network or anything. While they are still public, so community members, so you guys, for example,

85
00:12:04,279 --> 00:12:09,359
 are more than welcome to come test with us. An example, right now we don't have any

86
00:12:09,360 --> 00:12:15,800
 uh petra devnet up we're planning on having one up over the next few weeks but uh we do have

87
00:12:15,800 --> 00:12:21,399
 vocal devnets up for example so you could uh take part in a vocal devnet try and break it and if you

88
00:12:21,399 --> 00:12:30,560
 break it then it's going to make its way into a fix and you have your fame there um yeah and like

89
00:12:30,560 --> 00:12:35,320
 i mentioned before you're able to design all of these edge cases these network faults and things

90
00:12:35,320 --> 00:12:44,740
 like that that are kind of harder to do anywhere else and testing today so uh we actively are

91
00:12:44,740 --> 00:12:50,740
 talking about a petra devnet um tbd maybe in the next week two weeks you will be seeing something

92
00:12:50,740 --> 00:12:57,800
 uh a lot of our focus right now is on work so trying to get some work transition tests going

93
00:12:57,800 --> 00:13:02,260
 making sure the tooling is ready for the next fork because we have some amount of downtime to work on

94
00:13:02,259 --> 00:13:09,279
 it right now. We recently relaunched the Costinan devnet with some changes that were found from

95
00:13:09,279 --> 00:13:16,379
 earlier iterations. We're also doing some prototyping. So inclusion lists is one strong

96
00:13:16,379 --> 00:13:23,439
 example. Another one is EIP-7441, which is WISC, where you have some amount of base layer

97
00:13:23,439 --> 00:13:29,120
 validator privacy. So we also have some long-running testnets that achieve that.

98
00:13:29,120 --> 00:13:36,399
 it's also not just, sorry dev nets that achieve that, it's not just future folks that dev nets can use.

99
00:13:36,399 --> 00:13:44,340
 Sometimes current clients also need some sort of testing, right?

100
00:13:44,340 --> 00:13:49,000
 For example, it's EthereumJS wanting to have snapsync support on their client.

101
00:13:49,000 --> 00:13:53,379
 And doing this on a full-fledged test net is quite heavy.

102
00:13:53,379 --> 00:13:56,840
 You have a lot of blocks, it's a lot of state.

103
00:13:56,840 --> 00:13:59,200
 you might not want to target that immediately.

104
00:13:59,680 --> 00:14:03,780
 So we set up a small-scale Ethereum.js snapsink test

105
00:14:03,780 --> 00:14:07,120
 that they can just use for that use case.

106
00:14:07,660 --> 00:14:11,660
 And we often do run, we call them big boy beacon chain tests.

107
00:14:11,660 --> 00:14:15,920
 So they are maxing out any one parameter of the beacon chain

108
00:14:15,920 --> 00:14:18,460
 that we think makes sense to max out.

109
00:14:18,600 --> 00:14:21,480
 So an example might be increasing the validators

110
00:14:21,480 --> 00:14:24,940
 to a million and a half validators or two million validators.

111
00:14:24,940 --> 00:14:30,860
 And this is indeed a test that we ran before committing to how big the validator set on Holsky will be,

112
00:14:31,120 --> 00:14:35,780
 so that we know that the clients are actually able to handle such a big network.

113
00:14:36,500 --> 00:14:41,720
 Same with blobs. We would spam blobs and see, hey, if in our controlled environment,

114
00:14:41,880 --> 00:14:46,820
 we're not able to do X amount of blobs, there's no way that we'd be able to do this on mainnet.

115
00:14:47,180 --> 00:14:52,820
 So this sort of devnet level testing allows us to achieve a lot of different things there.

116
00:14:54,940 --> 00:14:59,100
 But dev nets require a lot of coordination.

117
00:14:59,840 --> 00:15:02,580
 You would want a bunch of client teams.

118
00:15:02,580 --> 00:15:08,060
 You would probably expect a DevOps team to be setting up this network.

119
00:15:08,420 --> 00:15:12,660
 And it takes some amount of effort to coordinate everyone.

120
00:15:13,680 --> 00:15:19,860
 And we don't want to always do that, especially if we put in all of that effort

121
00:15:19,860 --> 00:15:23,300
 and the network breaks just because a client didn't start up

122
00:15:23,299 --> 00:15:29,059
 or just because someone had the wrong specification implemented it's a lot of toil for

123
00:15:29,059 --> 00:15:35,539
 too little effort and at some point last year we realized this and we wanted to push for we want

124
00:15:35,539 --> 00:15:40,659
 to do a heavy push for local testing because then i can spin up a really small network

125
00:15:41,539 --> 00:15:45,699
 to sanity check that everything is working before i commit to the bigger devnet

126
00:15:46,419 --> 00:15:52,019
 so this also allows us for faster iterations so i can have i don't know 10 different parameter

127
00:15:52,019 --> 00:15:58,100
 change is running over 20 different dev nets all running on one laptop um and then figure out yeah

128
00:15:58,100 --> 00:16:03,939
 okay i found this bug in this one this one and that one and let's see which is the um optimum

129
00:16:03,939 --> 00:16:12,179
 that i i'll commit to for a dev it also allows us to work async on a lot of features so if client a

130
00:16:12,179 --> 00:16:18,019
 and b say they are feature complete we normally publish like a config that everyone can use and

131
00:16:18,019 --> 00:16:22,179
 and then you can update and append your own client and see if interop works.

132
00:16:22,179 --> 00:16:27,299
 And if it works, then you already know that when the devnet happens, the devnet will also work.

133
00:16:28,659 --> 00:16:36,179
 And to also help this local fast iterative testing, we also allow you to configure slot

134
00:16:36,179 --> 00:16:41,939
 times, you can change the fork epoch version, you can do the entire map workflow. So there's a lot

135
00:16:41,940 --> 00:16:48,260
 of really nice things that can happen here and i'm going to go through a couple of examples of

136
00:16:48,900 --> 00:16:53,540
 how these local testings look and i do definitely want to focus on this for a bit especially in the

137
00:16:53,540 --> 00:16:59,220
 context of prototyping because i think it is a really really powerful tool for not only

138
00:16:59,220 --> 00:17:05,140
 understanding how ethereum works but to know what components ethereum has and for whenever you feel

139
00:17:05,140 --> 00:17:13,700
 ready how to test your own changes on uh sort of your own network that you get some more

140
00:17:13,700 --> 00:17:21,940
 confidence of it um and this setup that we have um it's also very scalable and we've kind of

141
00:17:21,940 --> 00:17:28,900
 achieved this via this tool that's called kurtosis so kurtosis is um you can imagine it as a cli tool

142
00:17:28,900 --> 00:17:38,580
 it consumes um yaml and then it passes this yaml via the definitions and the definitions are all

143
00:17:38,580 --> 00:17:45,220
 in starlark which is a python-based language and what it spits out is something that docker as well

144
00:17:45,220 --> 00:17:51,860
 as the kubernetes engine can understand so you're going from a yaml definition into a ethereum

145
00:17:51,860 --> 00:17:57,540
 network that is deployed either on your local docker machine or on a remote kubernetes instance

146
00:17:57,539 --> 00:18:11,539
 The reason we want to support both of these is for local docker instance it's great if you just want two, three nodes, you just want to set up something quick, you want to see if a fork works in under five minutes, and then you're done.

147
00:18:11,539 --> 00:18:25,539
 Whereas if we want to do bigger tests, say you want 500 nodes because you want to test some edge case, or you want to make use of the Kubernetes layer abstractions that are offered to you, for example, chaos testing.

148
00:18:25,539 --> 00:18:31,680
 testing, right? Then you want to support the Kubernetes engine as well. So we kind of offer,

149
00:18:31,859 --> 00:18:36,599
 or you want to have a more production system where it can run in the cloud, someone can access data

150
00:18:36,599 --> 00:18:43,099
 from it, you can have like a public dev net in the cloud, you can use that Kubernetes engine for it.

151
00:18:43,099 --> 00:18:48,539
 It's all configurable, you can have a look at the kurtosis documentation. And there is a repository,

152
00:18:48,539 --> 00:18:54,440
 I highly, highly recommend that you guys are also going to this repository. And please over the

153
00:18:54,440 --> 00:18:59,559
 course of this call try and download kurtosis as well as make sure that docker is on your local

154
00:18:59,559 --> 00:19:06,039
 machine because towards the end if you want uh and try to run some of these examples and you

155
00:19:06,039 --> 00:19:12,920
 have questions we can also talk about the questions it's extremely simple to run and i'm

156
00:19:12,920 --> 00:19:16,860
 just going to go through this definition once because we're going to be using this definition

157
00:19:16,860 --> 00:19:24,180
 also later on so kurtosis name of the cli you're using you want to run something an enclave is sort

158
00:19:24,180 --> 00:19:29,920
 of namespace it contains what this network will be called and other networks won't touch this

159
00:19:29,920 --> 00:19:35,019
 so it's just some amount of separation you can have more than one enclave on your machine you

160
00:19:35,019 --> 00:19:40,140
 can do a lot of fun things with names with enclaves we normally just call it ethereum

161
00:19:40,140 --> 00:19:46,380
 network or each two or whatever you want to call it the next github link that is pasted there

162
00:19:46,380 --> 00:19:53,600
 is the starlark definition of what the network needs to look like this is just generic understanding

163
00:19:53,599 --> 00:19:58,019
 This definition, for example, defines what a get node is.

164
00:19:58,439 --> 00:20:02,359
 It defines what the YAML fields mean.

165
00:20:02,439 --> 00:20:05,099
 What do I do with Genesis time?

166
00:20:05,480 --> 00:20:07,279
 It defines all of those things.

167
00:20:07,399 --> 00:20:08,459
 It's very extendable.

168
00:20:08,819 --> 00:20:11,899
 And the really cool part is if you clone this Git repository

169
00:20:11,899 --> 00:20:15,279
 and you make a change to the star lock, you don't even need to push it.

170
00:20:15,500 --> 00:20:19,519
 You can just replace that remote GitHub URL with dot

171
00:20:19,519 --> 00:20:22,500
 or whatever the path, the local path of the repository.

172
00:20:22,500 --> 00:20:28,920
 and kurtosis will pick it up and kurtosis won't then deploy a network as defined in github it'll

173
00:20:28,920 --> 00:20:34,660
 deploy the network as defined in your local machine so not only can you modify parameters

174
00:20:34,660 --> 00:20:41,559
 of a network you can also modify what it means to be a network in itself um the next one is args

175
00:20:41,559 --> 00:20:47,420
 file and then you pass a file which has a bunch of predefined parameters and i'm going to go through

176
00:20:47,420 --> 00:20:53,519
 a couple of them to show you what type of networks you can set up with this local testing tool.

177
00:20:54,700 --> 00:21:02,940
 So here's an example of a YAML definition. So you define the participants. You're saying you want

178
00:21:02,940 --> 00:21:12,160
 one participant that is a get Tecku node. So this will be get EL, Tecku, CL, as well as

179
00:21:12,160 --> 00:21:17,320
 validator and then you want one participant that is a nether mind EL and

180
00:21:17,320 --> 00:21:25,420
 prism CL as well as validator you can also override every single part of this

181
00:21:25,420 --> 00:21:29,320
 by the way and I will talk about overrides later on but every single bit

182
00:21:29,320 --> 00:21:36,420
 of kurtosis is overridable here and then you can you you are defining here

183
00:21:36,420 --> 00:21:40,100
 that you want some additional services you want this network to have a

184
00:21:40,099 --> 00:21:43,939
 transaction spammer so that there's some transaction load on the network you want

185
00:21:43,939 --> 00:21:48,419
 this network to have a blob spammer some transaction some blob load on this network

186
00:21:49,299 --> 00:21:55,299
 dora is an explorer so it will give you a url you can access a local explorer that will help

187
00:21:55,299 --> 00:21:59,939
 you understand what's going on in your network you'll be collecting all the metrics and pushing

188
00:21:59,939 --> 00:22:08,740
 it to your own prometheus instance and a snooper sits between all the apis that are available so

189
00:22:08,740 --> 00:22:14,720
 between your engine in your engine api in your beacon api and every one of them and it just spits

190
00:22:14,720 --> 00:22:18,420
 out every single thing that's happening on that interface so it's a man in the middle

191
00:22:18,420 --> 00:22:24,460
 um and it's very very useful for if you're doing a new fork and you actually want to know hey the

192
00:22:24,460 --> 00:22:31,120
 cl sent something and that broke the el can i maybe figure out what message the el sent me so i can

193
00:22:31,120 --> 00:22:36,880
 reproduce this bug uh saves us a bunch of time having this sort of man in the middle and key

194
00:22:36,880 --> 00:22:41,720
 manager enabled enables the key manager API and you can do whatever you want with the key manager

195
00:22:41,720 --> 00:22:55,040
 API as well. And I'm guessing a lot of you are in the MEV environment or at least curious about

196
00:22:55,040 --> 00:23:03,480
 the MEV environment. And we also support the entire MEV workflow on Kurtosis. So if you do,

197
00:23:03,480 --> 00:23:10,759
 for example, mev type full, then it will spin up a local relay, it will spin up a local

198
00:23:12,279 --> 00:23:19,160
 database for accessing all the relay validator registrations, it will spin up mev boost so that

199
00:23:19,160 --> 00:23:24,920
 your validator can connect to the relay, it will spin up a builder, it will use all open source

200
00:23:24,920 --> 00:23:29,720
 images, so most of them are from FlashPots and you can override any of them in case you're building

201
00:23:29,720 --> 00:23:35,160
 your own relay in case you're building your own map boost implementation or whatever it is and

202
00:23:35,799 --> 00:23:41,000
 one important thing to note here if you notice in the previous list there was a participants

203
00:23:41,000 --> 00:23:47,079
 whereas here there's no participants so whenever you don't specify something in kurtosis it just

204
00:23:47,079 --> 00:23:51,880
 uses the default and the default is i think one participant with the geth in lighthouse so that's

205
00:23:51,880 --> 00:23:59,160
 what will be spun up in this network um and here we're also having a few additional services so

206
00:23:59,160 --> 00:24:10,040
 So this custom flood that comes up and what custom flood does is it sends very malleable transactions so that there's some juicy payloads that the builder can build.

207
00:24:10,500 --> 00:24:14,779
 Otherwise, the builder is not building anything that the validator is going to propose with.

208
00:24:16,560 --> 00:24:26,400
 And what I meant by overrideable, if you look at the MEV params, so I'm launching with custom flood.

209
00:24:26,400 --> 00:24:33,240
 that's also available earlier and I'm specifying the MEV relay image and what this means is you

210
00:24:33,240 --> 00:24:39,420
 no longer want the default MEV relay image that Kurtosis ships with but instead you have your

211
00:24:39,420 --> 00:24:44,420
 own MEV boost relay that you've implemented and you want to use your docker image there

212
00:24:44,420 --> 00:24:51,259
 so that's also possible and this is extremely useful for us in rapid fork testing so we can

213
00:24:51,259 --> 00:24:56,839
 have the latest version that has not been released yet override it here and

214
00:24:56,839 --> 00:25:00,680
 it's only if it breaks something it will only break something my local testing

215
00:25:00,680 --> 00:25:05,779
 environment nowhere else and to make things faster you can also override

216
00:25:05,779 --> 00:25:12,500
 certain parameters so anything that makes sense to override in the in the

217
00:25:12,500 --> 00:25:16,259
 consensus specs there's a file called conflict or gamma so this is the

218
00:25:16,259 --> 00:25:20,680
 definition of what a beacon chain looks like anything there that makes sense to

219
00:25:20,680 --> 00:25:25,960
 override we allow you to override here so one of them is seconds per slot so ethereum beacon chain

220
00:25:25,960 --> 00:25:31,720
 today has 12 seconds per slot and here i'm saying that's too long i don't actually care about

221
00:25:31,720 --> 00:25:36,279
 waiting for 12 seconds i don't actually care about finality i just want to make sure that my payload

222
00:25:36,279 --> 00:25:41,720
 is getting delivered so you're overriding it to once every three seconds and now you have four

223
00:25:41,720 --> 00:25:47,240
 times the number of calls uh happening which means the chances of whatever you're testing to be

224
00:25:47,240 --> 00:26:01,319
 triggered or probably four times as likely. So, yeah, so the next thing is, I've shown you guys

225
00:26:01,319 --> 00:26:07,640
 how you do some local testing. The question is now how do I actually prototype things, right?

226
00:26:08,440 --> 00:26:13,000
 So like I've mentioned earlier, Kurtosis works on the concept of everything can be overwritten

227
00:26:13,000 --> 00:26:15,799
 outside of the network basics.

228
00:26:16,160 --> 00:26:20,220
 So a simple example is in the mainnet spec,

229
00:26:20,279 --> 00:26:23,420
 there will always be 32 slots per e-box.

230
00:26:24,000 --> 00:26:25,619
 You can try to override it.

231
00:26:25,779 --> 00:26:27,220
 It's not supported by any client.

232
00:26:27,960 --> 00:26:30,420
 So you can specify it in kurtosis if you want.

233
00:26:30,500 --> 00:26:31,380
 We're just going to ignore it

234
00:26:31,380 --> 00:26:33,720
 because it's a sane check

235
00:26:33,720 --> 00:26:36,359
 that we know will break the network.

236
00:26:36,940 --> 00:26:39,059
 Like that, we have a lot of sanity checks

237
00:26:39,059 --> 00:26:43,339
 that make sure you can't break your setup too much.

238
00:26:43,859 --> 00:26:45,419
 So as long as you read the docs,

239
00:26:45,500 --> 00:26:48,659
 as long as you change something that we specify in the docs,

240
00:26:49,019 --> 00:26:50,879
 chances are it will work quite well.

241
00:26:52,440 --> 00:26:54,940
 In case you want to test protocol changes,

242
00:26:55,039 --> 00:26:59,480
 you might want to update or override the client images itself.

243
00:26:59,639 --> 00:27:02,379
 So you don't want to use NetherMind latest.

244
00:27:02,720 --> 00:27:07,200
 You might want to use NetherMind fork that you have built yourself

245
00:27:07,200 --> 00:27:09,720
 in order to test new tools.

246
00:27:10,140 --> 00:27:12,140
 You can run an existing kurtosis network.

247
00:27:12,240 --> 00:27:14,180
 You can run like a tiny kurtosis network.

248
00:27:14,720 --> 00:27:17,120
 And once at the end of the kurtosis run,

249
00:27:17,220 --> 00:27:19,360
 it will give you all the API endpoints.

250
00:27:19,580 --> 00:27:21,240
 And your tool can connect to those APIs

251
00:27:21,240 --> 00:27:23,340
 and you can test building whatever you want to build.

252
00:27:24,360 --> 00:27:27,340
 An example is we've built a local explorer with this.

253
00:27:27,620 --> 00:27:30,019
 So we no longer have to sync a whole network.

254
00:27:30,259 --> 00:27:31,420
 You don't have to do all of that.

255
00:27:31,480 --> 00:27:34,840
 You can just sync a local network, which is a lot faster.

256
00:27:34,839 --> 00:27:40,000
 and then you can make sure that your explorer works as expected before you do anything wild

257
00:27:40,000 --> 00:27:46,119
 a lot of people also do this for smaller tools that they're building so there's this one tool

258
00:27:46,119 --> 00:27:53,439
 where you can have a CLI that kind of notifies you when your validator is selected for proposals

259
00:27:53,439 --> 00:28:01,879
 it's being built by someone who works at T-Mobile as far as I'm sorry Telecom as far as I know

260
00:28:01,880 --> 00:28:09,000
 and he's using kurtosis to run it locally so connect to a local devnet so he doesn't he

261
00:28:09,000 --> 00:28:13,300
 controls the entire validator set and he wants his tool to do a lot of other things and he has

262
00:28:13,300 --> 00:28:19,020
 entire control without relying on a public network without spending gigabytes to download something

263
00:28:19,020 --> 00:28:25,720
 keep it in sync etc and in case you want to test quicker forks like i showed earlier you can change

264
00:28:25,720 --> 00:28:30,860
 the second per slot you can change when the fork happens so you can say hey why don't i have my

265
00:28:30,859 --> 00:28:38,459
 fork happen at epoch one already so if i do epoch one as well as set the seconds per slot to three

266
00:28:38,459 --> 00:28:45,659
 seconds then pretty much in about two minutes you're testing a fork which is extremely fast

267
00:28:45,659 --> 00:28:51,339
 when you want to iterate stuff when you want to prototype type things and here's an example

268
00:28:51,339 --> 00:28:58,379
 of prototype testing so vocal is a huge beast and it's a big fork and we've been trying to

269
00:28:58,380 --> 00:29:05,340
 support it with local testing as much as we can so here's an example of how um we can test the

270
00:29:05,340 --> 00:29:11,580
 transition as a worker transition locally so if you copy this and you run it in kurtosis you

271
00:29:11,580 --> 00:29:17,100
 you're basically testing a worker transition so i'm going to go through this from top to bottom

272
00:29:17,100 --> 00:29:22,300
 so what happens is right now i'm specifying a participant list and i'm saying i want a geth

273
00:29:22,299 --> 00:29:27,980
 node and i want the geth node to run this particular docker image this particular docker

274
00:29:27,980 --> 00:29:34,139
 image is built from a fork of geth by guillaume who's working on worker and the for uh the yeah

275
00:29:34,139 --> 00:29:41,339
 he's doing a transition post a network genesis and there's a lodestar image that g11 tech has

276
00:29:41,339 --> 00:29:46,299
 built that supports the worker transition because both the el as well as the cl need to have a

277
00:29:46,299 --> 00:29:50,460
 concept of what the fork is for it's just to work and I want three of them

278
00:29:50,460 --> 00:29:54,779
 and you can specify count as whatever you want and it will replicate the same

279
00:29:54,779 --> 00:29:59,919
 definition for all the participants and then in my network parameters I'm

280
00:29:59,919 --> 00:30:05,619
 specifying that at the time it was called an Electra fork epoch will still

281
00:30:05,619 --> 00:30:10,639
 be basing so don't pay attention to that particular name but it is Electra fork

282
00:30:10,640 --> 00:30:18,240
 epoch1 so the transition will happen at epoch1 the network will start roughly 100 seconds after

283
00:30:18,240 --> 00:30:23,700
 i run my kurtosis command and you might want to do this for a certain number of reasons maybe

284
00:30:23,700 --> 00:30:31,100
 there's an amount of time that takes for um for you to spin up all your uh terminal windows with

285
00:30:31,100 --> 00:30:37,720
 the logs maybe you want to wait some time for some processing that your node has to do it in it

286
00:30:37,720 --> 00:30:41,880
 Maybe you just don't want to have it immediately so you don't miss anything.

287
00:30:41,880 --> 00:30:46,600
 So, in this case, we're just doing it with Genesis Delay of 100 seconds.

288
00:30:46,600 --> 00:30:50,400
 And then Snoopers enables, so I'll be able to see each and every single call that happens

289
00:30:50,400 --> 00:30:56,880
 between the EL and CL, and this was very useful early on because the CL dev could say, oh,

290
00:30:56,880 --> 00:30:59,180
 this is how I interpreted the spec.

291
00:30:59,180 --> 00:31:03,940
 I wanted to have these calls, and the EL dev is like, yeah, but that puts me in this state.

292
00:31:03,940 --> 00:31:06,200
 Maybe you send it this way instead.

293
00:31:06,200 --> 00:31:08,799
 it helps us to actually see what's going on.

294
00:31:10,059 --> 00:31:15,740
 Persistence true is important in case you want to have this network running for a longer amount of time.

295
00:31:16,200 --> 00:31:20,740
 It just means if a container restarts or whatever, it starts back up with the same state.

296
00:31:21,160 --> 00:31:27,680
 So if you have persistent true, you could say kudos to stop participant number two.

297
00:31:28,100 --> 00:31:32,019
 You can wait 10 seconds or whatever, two minutes until some blocks are built,

298
00:31:32,019 --> 00:31:34,299
 and then you can start that particular instance again,

299
00:31:34,299 --> 00:31:38,240
 and then that instance will start syncing to the head of the chain.

300
00:31:38,700 --> 00:31:40,579
 So you're also testing sync in a way.

301
00:31:41,319 --> 00:31:44,460
 So you can use this for a lot of really cool things.

302
00:31:44,660 --> 00:31:47,139
 Or it could also be something as simple as,

303
00:31:47,279 --> 00:31:50,980
 hey, if I built a client and I shut down the node and I started back up,

304
00:31:51,180 --> 00:31:52,480
 will it even start back up?

305
00:31:53,420 --> 00:31:55,859
 That is also something you want to test, right?

306
00:31:56,980 --> 00:32:00,299
 And yeah, I'm wanting to launch some additional services.

307
00:32:00,299 --> 00:32:05,579
 services one of them is dora the explorer and the other one is the certer i won't talk about

308
00:32:05,579 --> 00:32:12,059
 a certain now um i don't want to overload you guys with tools but yeah for now kind of get this is

309
00:32:12,059 --> 00:32:18,220
 how you would do prototype testing so if you have your own el your own cl fork and you want to test

310
00:32:18,220 --> 00:32:26,220
 it all you have to do is replace el image and cl image and maybe a good first example is fork any

311
00:32:26,220 --> 00:32:31,420
 one client it doesn't matter which one whatever language you're comfortable in and just add some

312
00:32:31,420 --> 00:32:37,339
 log message saying you were here build a docker image put the docker image here and then once you

313
00:32:37,339 --> 00:32:43,180
 start the network in the log it will say you were here it's a nice first start to understand how the

314
00:32:43,180 --> 00:32:53,019
 prototype testing system will work so once people are kind of comfortable with local testing what we

315
00:32:53,019 --> 00:32:59,980
 normally do is upgrade to remote testing. And I've mentioned the reasons earlier, remote testing

316
00:32:59,980 --> 00:33:05,339
 needs a lot more synchronous time. We try to do it only once we feel like clients are ready.

317
00:33:06,940 --> 00:33:13,740
 Worker, for example, has a lot of local testing for a rebase that's going on, but we've deployed

318
00:33:13,740 --> 00:33:21,819
 some older versions for public devnet testing. Even though they do take some amount of effort

319
00:33:21,819 --> 00:33:29,579
 in time, we want to make them as easy as possible to set up when we're doing it. And

320
00:33:29,579 --> 00:33:35,500
 they used to be very error prone and time consuming, because the definition of how to

321
00:33:35,500 --> 00:33:42,379
 spin up a dev net, what parameters are there it. I think two, three years ago, every single team

322
00:33:42,379 --> 00:33:49,339
 was maintaining their own start test net scripts earlier, at least that's largely how that worked.

323
00:33:49,339 --> 00:33:52,139
 and I'm sure they still do, and it's very good that they do.

324
00:33:53,959 --> 00:33:57,220
 But it gets hard to do interrupt testing

325
00:33:57,220 --> 00:33:59,480
 if you're reliant on those scripts.

326
00:33:59,659 --> 00:34:02,039
 It's harder to modify things.

327
00:34:02,959 --> 00:34:06,419
 And it becomes very easy for a drift to occur

328
00:34:06,419 --> 00:34:09,519
 between setup configs and customizations you might need.

329
00:34:09,519 --> 00:34:11,759
 So, Verkle needs quite a few customizations

330
00:34:11,759 --> 00:34:13,840
 on quite a few levels.

331
00:34:14,059 --> 00:34:16,860
 So, we have...

332
00:34:16,860 --> 00:34:18,759
 Verkle has a specific type of genesis,

333
00:34:18,760 --> 00:34:27,140
 and that genesis requires you to use a fork of another library that is using a fork of another

334
00:34:27,140 --> 00:34:33,180
 library so there's like three levels of forks that are required and needed to be maintained for it

335
00:34:33,180 --> 00:34:38,600
 and now you can imagine if we're doing this across many clients it just starts to get very tedious it

336
00:34:38,640 --> 00:34:41,180
 there's a huge drift i might not want to

337
00:34:41,180 --> 00:34:48,180
 you'll drift so much that you might not be able to merge stuff back into your main whenever you're

338
00:34:48,179 --> 00:34:54,199
 So what we did was we split the bare-bones logic of

339
00:34:55,219 --> 00:34:57,219
 What is a node and?

340
00:34:57,379 --> 00:35:03,339
 What needs to happen on a network ie generate validator keys get Genesis?

341
00:35:04,279 --> 00:35:06,279
 Start a node

342
00:35:06,639 --> 00:35:11,299
 Wait for a node to start up get the nodes peer-to-peer address

343
00:35:12,079 --> 00:35:14,199
 Shut down a node clean up node

344
00:35:14,199 --> 00:35:21,359
 we've taken these generic definitions and we've used a we normally write all

345
00:35:21,359 --> 00:35:26,500
 of these things in ansible ansible is a I'm going to call it a fancy scripting

346
00:35:26,500 --> 00:35:33,359
 language it's not a language it's like a fancy scripting methodology to do things

347
00:35:33,359 --> 00:35:38,919
 across a lot of nodes a lot of cloud instances and there's a concept of a

348
00:35:38,920 --> 00:35:45,960
 role so a role is sort of like a function that you can call pass some parameters and what you passed

349
00:35:45,960 --> 00:35:53,480
 in is what happens so we've generalized these concepts into this ansible collection general

350
00:35:54,280 --> 00:36:00,680
 and then we've moved generic components into their own tools so genesis is a concept that

351
00:36:00,680 --> 00:36:06,440
 almost every single devnet has to do at some point right if you don't have genesis you don't

352
00:36:06,440 --> 00:36:13,720
 of the genesis files the network will not be able to start up so we built this genesis generator

353
00:36:13,720 --> 00:36:20,519
 uh tool all it is is a docker file that wraps through a lot of tools and scripts so there's some

354
00:36:20,519 --> 00:36:28,840
 sanity checks some logic some methodology on how you call it but it's very configurable you're able

355
00:36:28,840 --> 00:36:34,920
 to handle the case of vocal that i just gave you where there's fork over fork canonicalized there

356
00:36:34,920 --> 00:36:42,720
 as well as mainnet ethereum as well as shadowfox as well as the next extra devnet all within this

357
00:36:42,720 --> 00:36:48,539
 one repository and the interface between this repository and the ansible connection is defined

358
00:36:48,539 --> 00:36:57,019
 so they're tightly coupled in that way um but you can modify both if you want um and you can get a

359
00:36:57,019 --> 00:37:04,940
 new different thing and the next problem was tooling if for example i have work um the

360
00:37:05,900 --> 00:37:10,699
 work devnet changes so many things that my explorer might not work out of the box

361
00:37:10,699 --> 00:37:17,340
 i might need forks of my explorer it gets hard to maintain that and it gets hard to keep them up

362
00:37:17,340 --> 00:37:23,739
 when a network is running it gets hard to scale them up it gets yeah you have operational issues

363
00:37:23,739 --> 00:37:31,259
 that so what we do is we use kubernetes and there's a concept called git ops so git ops is

364
00:37:31,259 --> 00:37:37,739
 basically what is on git is what gets deployed on your kubernetes instance it's one to one so you

365
00:37:37,739 --> 00:37:45,179
 define what you want on github and uh kubernetes makes this git ops thing we use argo it makes it

366
00:37:45,179 --> 00:37:52,379
 happen for you and these definitions happen via um another packaging language or packaging system

367
00:37:52,380 --> 00:37:58,260
 called Helm Charts. So this will, for example, spin up all of our tooling for us. So

368
00:37:58,260 --> 00:38:06,800
 we now have a way to spin up Ethereum nodes, we have a way to spin up what a network is,

369
00:38:06,920 --> 00:38:11,420
 and we have a way to spin up what the tools are. The question is, how do you bring all of these

370
00:38:11,420 --> 00:38:17,019
 disparaging things together, right? So what we've done is we've generalized the setup

371
00:38:17,019 --> 00:38:24,420
 for all testnets possible into this repository called template testnet so

372
00:38:24,420 --> 00:38:28,679
 what template testnet does is it has

373
00:38:28,900 --> 00:38:37,840
 template testnet has terraform code to spin up the network it then uses the

374
00:38:37,840 --> 00:38:45,360
 ansible code as you define it to spin up the nodes as well as to spin up Genesis

375
00:38:45,360 --> 00:38:52,519
 information and get all of that and put it somewhere. And then it also spins up the

376
00:38:52,519 --> 00:38:57,980
 entire definition for what your tooling needs to look like. And then once you push this entire

377
00:38:57,980 --> 00:39:04,360
 thing to GitHub, GitOps just makes that tooling magically appear. So GitOps also makes sure that

378
00:39:04,360 --> 00:39:11,980
 your certificates appear, that your URLs look nice, that you have a load balancer in front,

379
00:39:11,980 --> 00:39:17,579
 all of those nice things are just taken care of so by splitting these things up into small

380
00:39:17,579 --> 00:39:23,500
 components and then combining them together in template testnet when i have a huge diff i can

381
00:39:23,500 --> 00:39:28,619
 maintain it nicely in template testnet and move stuff back into the template as and when it

382
00:39:28,619 --> 00:39:34,380
 becomes important to move it back so you're very you're reducing the amount of drift that happens

383
00:39:34,380 --> 00:39:41,179
 between template uh that set up set up conflicts um we've successfully been using this for about

384
00:39:41,179 --> 00:39:48,139
 year now uh we did the entire denkoon fork at the same time testing whisk at the same time testing

385
00:39:49,099 --> 00:39:55,579
 vocal at the same time doing other test nets and we've used this exact same infrastructure for our

386
00:39:57,339 --> 00:40:03,019
 holesky nodes sepulia nodes all of them so i would say it's a relatively battle tested

387
00:40:03,019 --> 00:40:08,539
 system and we're quite happy with it it's not to say it doesn't have its downsides but i would say

388
00:40:08,539 --> 00:40:12,860
 we've minimized the downsides as much as possible once someone understands the system

389
00:40:14,619 --> 00:40:22,699
 um i'm not sure how we do questions but maybe this is a good spot to stop for questions um maybe

390
00:40:22,699 --> 00:40:29,420
 mario or josh can tell me if that's a good idea yeah yeah great thank you so much kare uh we have

391
00:40:29,420 --> 00:40:34,460
 uh discussion going on in this court here before asking questions and sometimes answering if you

392
00:40:34,460 --> 00:40:36,840
 if I'm able to answer.

393
00:40:36,840 --> 00:40:38,619
 So we've been going through it.

394
00:40:38,619 --> 00:40:41,220
 People are running kurtosis here.

395
00:40:41,220 --> 00:40:44,480
 And let's see if you folks have any questions regarding

396
00:40:44,480 --> 00:40:45,179
 the kurtosis.

397
00:40:45,179 --> 00:40:48,679
 If you ran into some issues or something, let us know.

398
00:40:48,679 --> 00:40:52,280
 I've also updated my local kurtosis binary

399
00:40:52,280 --> 00:40:53,699
 and ran it again.

400
00:40:53,699 --> 00:40:56,360
 After a while, I have to say it works super nicely.

401
00:40:56,360 --> 00:40:59,420
 The quick start is very easy compared

402
00:40:59,420 --> 00:41:04,099
 to scrambling together bash script from some client team

403
00:41:04,099 --> 00:41:07,539
 to run a test net two, three years ago.

404
00:41:07,539 --> 00:41:08,779
 Like it's it's incredible.

405
00:41:08,779 --> 00:41:09,279
 Yeah.

406
00:41:11,779 --> 00:41:13,819
 So yeah, there was a question.

407
00:41:15,219 --> 00:41:17,619
 How are the Docker images published?

408
00:41:17,619 --> 00:41:20,779
 I shared them the itpandaops on Docker Hub.

409
00:41:21,860 --> 00:41:23,579
 Maybe if you can tell us more about that,

410
00:41:23,579 --> 00:41:25,819
 like how do you publish the images for testing it?

411
00:41:25,819 --> 00:41:30,420
 Maybe whether you use also images from the client teams themselves?

412
00:41:30,420 --> 00:41:32,019
 Yeah. Yeah.

413
00:41:32,019 --> 00:41:51,980
 So we do it two ways. The first one is, maybe I can explain the problem to begin with. Before we started, every client team published Docker images, and they still do. But when or what triggers that Docker image publish varies wildly per client.

414
00:41:51,980 --> 00:42:04,599
 So some client teams publish on latest, some client teams publish just the master main brand, some publish on each and every PR, some publish forks, some don't publish forks.

415
00:42:05,039 --> 00:42:15,480
 It was a bit of a headache to always ping the dev working on the fork who then had to reach out to their DevOps person to build a Docker image for us.

416
00:42:15,880 --> 00:42:20,420
 It gets very out of hand to do this.

417
00:42:20,420 --> 00:42:28,980
 So what we did is, we, of course, when there's a client image, we use the client image, because I think that's a better way of testing.

418
00:42:29,700 --> 00:42:38,500
 But when there isn't one for an early fork, for example, that is based off of a lot of other forks, we have a generalized Docker image builder.

419
00:42:38,760 --> 00:42:45,380
 I've shared the link in the private chat here, maybe Mario or Josh can move it over to the other chat.

420
00:42:45,380 --> 00:42:55,599
 So this repository is able to build the client images of each and every single EL and CL out there.

421
00:42:56,140 --> 00:43:02,320
 There's a config.yaml file, and that config.yaml file is consumed by a scheduled builder.

422
00:43:02,579 --> 00:43:10,760
 So once every two hours, for a branch that we think is interesting to target, we build and preemptively publish images.

423
00:43:10,760 --> 00:43:20,060
 So every image we publish will have a generalized name, so Latest Devil whatever, that gets updated

424
00:43:20,060 --> 00:43:29,800
 every two hours, as well as Latest Dash Char Commit Slug, so that when we do testing, I don't want to

425
00:43:29,800 --> 00:43:34,580
 run Latest and say, hey, my Latest is broken, because that means nothing to a developer. They

426
00:43:34,579 --> 00:43:42,340
 want to know which commit you ran when you ran it. So you can choose in some cases for example CI

427
00:43:42,340 --> 00:43:47,219
 tests it makes sense to just use latest. In some cases when you're doing a local test it makes

428
00:43:47,219 --> 00:43:54,900
 sense to specify exactly which commit hash you're doing. So you're able to build every single EL and

429
00:43:54,900 --> 00:44:02,259
 CL and if you go to the actions tab over here we also support manually building them. You would

430
00:44:02,260 --> 00:44:08,660
 need to be invited to this repository to build because it gets very easy to spam the builder

431
00:44:08,660 --> 00:44:15,940
 with requests otherwise but almost any client dev who wants access gets access there's no real

432
00:44:15,940 --> 00:44:21,780
 gating over there and it also if any of you really feels like you are actively testing something and

433
00:44:21,780 --> 00:44:28,820
 you want access to this builder please let us know um and then if you choose for example you want to

434
00:44:28,820 --> 00:44:36,019
 build the Ethereum.js Docker image. And on the top right, there's a, there would be a run workflow.

435
00:44:36,480 --> 00:44:42,720
 And with that, I can specify which repository to target and which branch and what the result in

436
00:44:42,720 --> 00:44:50,580
 Docker image should be called. And with that, I can do this ad hoc testing of, hey, I don't want

437
00:44:50,580 --> 00:44:56,300
 to push this fix into the Ethereum.js main repository. I have this tiny fork of mine that

438
00:44:56,300 --> 00:44:58,120
 no one else knows about, can you use this?

439
00:44:58,580 --> 00:45:00,240
 I can still build a Docker image from there

440
00:45:00,240 --> 00:45:01,680
 without relying on my local machine.

441
00:45:02,260 --> 00:45:04,280
 And it will build ARM images, it will build

442
00:45:04,280 --> 00:45:06,420
 Linux x86 images,

443
00:45:06,620 --> 00:45:08,039
 it will build you a macOS image,

444
00:45:08,160 --> 00:45:09,000
 all the nice stuff.

445
00:45:09,980 --> 00:45:11,700
 And then everyone's just happy.

446
00:45:12,240 --> 00:45:14,220
 You can just target, it always

447
00:45:14,220 --> 00:45:15,840
 results in an ethpandaops

448
00:45:15,840 --> 00:45:17,900
 client name Docker image.

449
00:45:22,519 --> 00:45:24,300
 Yeah. I hope that

450
00:45:24,300 --> 00:45:26,240
 answered the question about the Docker image

451
00:45:26,239 --> 00:45:31,679
 that's usually where we that's usually how we consume them yeah yeah it totally did uh i'm just

452
00:45:31,679 --> 00:45:39,119
 sharing my screen showing the actual uh if uh it gets lost in the uh presentation just wanted

453
00:45:39,119 --> 00:45:44,799
 to show that uh awesome yeah thank you so much barry um thank you so much for doing that and

454
00:45:44,799 --> 00:45:51,279
 if there are any issues questions or kurtosis you can still keep asking yes uh maybe we can

455
00:45:51,280 --> 00:45:55,200
 ask one more questions before we move forward um

456
00:45:59,600 --> 00:46:07,120
 um can i point kurtosis to the local get or is it only forks of remote repos or dicker images

457
00:46:07,760 --> 00:46:14,640
 so you can also point kurtosis to local anything so if you don't want to use if you use github

458
00:46:14,640 --> 00:46:20,720
 slash whatever then it's remote if you just point it to dot slash and then put a relative path then

459
00:46:20,719 --> 00:46:26,559
 it just uses local yeah yeah that's what you said you can just pull the repo you can just

460
00:46:26,559 --> 00:46:32,719
 close the repo and and do your modifications right quickly it's it's it's very very nice that

461
00:46:32,719 --> 00:46:40,079
 you can just provide a local path um exactly awesome awesome yeah and uh the whole kurtosa

462
00:46:40,079 --> 00:46:45,759
 setup is completely open source you can mess with kurtosis itself you can mess with uh test net

463
00:46:45,760 --> 00:46:50,560
 definitions you can mess with basically anything you want to mess the whole stack open sourced

464
00:46:52,480 --> 00:46:56,880
 okay awesome awesome yeah thank you barry i think we can go on with the presentation and

465
00:46:57,520 --> 00:47:05,600
 it back to the questions perfect so the next one's a bit of a loaded topic um shadowfox

466
00:47:05,600 --> 00:47:11,360
 so you might have heard of shadowfox both in um the context of the merge as well as almost

467
00:47:11,360 --> 00:47:17,760
 everything single ethereum upgrade that happens so shadow forks allows us to

468
00:47:19,360 --> 00:47:25,440
 what it essentially does is you take a main network and then you fork it but you fork it

469
00:47:25,440 --> 00:47:31,920
 just in a small subset of nodes leaving the main network untouched as a result you inherit the

470
00:47:31,920 --> 00:47:39,599
 state of the main network but if you configure a fork then you're forking in your tiny shadow chain

471
00:47:39,599 --> 00:47:46,699
 There's a nice visual in the next graph, but before we get there, doing this setup helps us

472
00:47:46,699 --> 00:47:51,980
 understand and check compatibility across clients through the entire life cycle. So

473
00:47:51,980 --> 00:47:59,639
 you are inherently building a mainnet block. It's just that Ethereum mainnet, for example,

474
00:47:59,880 --> 00:48:05,139
 rejects your block because it's non-canonical. But you've gone through the process of building

475
00:48:05,139 --> 00:48:13,059
 mainnet block which is the important part for my testing perspective. This allows us to check a lot

476
00:48:13,059 --> 00:48:19,699
 of assumptions so for example when we were doing blob testing if for whatever reason building a

477
00:48:19,699 --> 00:48:26,579
 blob and verifying that with a mainnet state size was infeasible we would have seen that here. This

478
00:48:26,579 --> 00:48:33,619
 was extremely valuable in the merge because we would set an override ttd that just happened a

479
00:48:33,619 --> 00:48:39,059
 a few blocks in the future. And when we do that, you're essentially simulating the merge

480
00:48:39,059 --> 00:48:44,099
 without touching main net Ethereum, which was very powerful to have as a testing tool.

481
00:48:45,839 --> 00:48:50,039
 You're stress testing the client, this will be as close to main net as possible,

482
00:48:50,039 --> 00:48:54,739
 or as close to whatever network you're shadow forking as possible. So it comes with all of

483
00:48:54,739 --> 00:49:03,919
 those assumptions. Because of the way peer-to-peer works, you still stay peered to the main network

484
00:49:03,919 --> 00:49:10,859
 for a significant amount of time. So you're still importing transaction load. So if mainnet Ethereum

485
00:49:10,859 --> 00:49:16,539
 has a hundred something transactions that are happening in a block, your ShadowFork also has

486
00:49:16,539 --> 00:49:22,159
 those transactions included. Not all of them probably, but there are some intricacies as to

487
00:49:22,159 --> 00:49:29,039
 they won't get included the same way but fundamentally they are included which is

488
00:49:29,039 --> 00:49:37,199
 really really useful for stress testing how a network performs and uh yeah you're controlling

489
00:49:37,199 --> 00:49:42,559
 the entire validator set so you can take care of how the network needs to be and it acts as a

490
00:49:42,559 --> 00:49:48,879
 release test so this is kind of the last stage of the testing devnet testnet cycle that we see

491
00:49:48,880 --> 00:49:50,340
 it's going to work as expected.

492
00:49:52,180 --> 00:49:55,980
 So I'm going to preface this with simple in principle.

493
00:49:55,980 --> 00:50:00,220
 It is simple, but it is a bit of a hard-ish concept

494
00:50:00,220 --> 00:50:02,559
 to grok in the beginning.

495
00:50:02,559 --> 00:50:07,059
 So what you do is also ignore that it's using Girly.

496
00:50:07,059 --> 00:50:08,260
 I haven't updated my slides.

497
00:50:08,260 --> 00:50:10,640
 It should be Polsky or Sopolia by now,

498
00:50:10,640 --> 00:50:13,700
 but yeah, all right, it's pretty much the same.

499
00:50:13,700 --> 00:50:15,099
 So it's pretty much the same.

500
00:50:15,099 --> 00:50:16,599
 So it's pretty much the same.

501
00:50:16,599 --> 00:50:24,000
 earlier by now but um yeah or ephemera but um yeah for now let's talk about girly you take the

502
00:50:24,000 --> 00:50:30,480
 girly genesis file you can find this in github slash eth dash clients there's a repository

503
00:50:30,480 --> 00:50:38,360
 uh there for each testnet where all the genesis files exist i modify the genesis file so forget

504
00:50:38,360 --> 00:50:46,920
 this is genesis.json and I add a fork timestamp. So I say petra timestamp colon

505
00:50:48,280 --> 00:50:56,920
 one hour from now. Now I set up a new beacon chain with validators which also has the

506
00:50:56,920 --> 00:51:02,920
 Electra fork configured at the same exact timestamp and the deposit contract points

507
00:51:02,920 --> 00:51:11,159
 to the earlier girly chain right so now what you've done is you have a subset of validators

508
00:51:11,159 --> 00:51:18,360
 in a new beacon chain that understand when the fork is happening you have a subset of execution

509
00:51:18,360 --> 00:51:24,360
 nodes with your modified genesis json file that think a fork is supposed to happen at some time

510
00:51:24,360 --> 00:51:29,720
 no other golly node in the network has this configuration just your subset so when this

511
00:51:29,719 --> 00:51:35,480
 timestamp is hit, so in this case when TTD was hit, the canonical chain, the

512
00:51:35,480 --> 00:51:39,679
 girly chain that you or me or anyone else is using, just continues as if

513
00:51:39,679 --> 00:51:46,000
 nothing happened. But my local nodes with this modified girly config will think a

514
00:51:46,000 --> 00:51:54,139
 fork has happened, so they will execute the fork code. And since the EL just

515
00:51:54,139 --> 00:52:02,519
 builds the block when the CL tells it to and the CL is configured to build a block with this fork

516
00:52:02,519 --> 00:52:11,420
 timestamp it will build on top of the last canonical girly block but this new curly block

517
00:52:11,420 --> 00:52:16,940
 is invalid in the main chain because it was built by a validator that no one in the main chain knows

518
00:52:16,940 --> 00:52:23,379
 or recognizes but in my controlled validator set all of them no one recognize that validator so

519
00:52:23,380 --> 00:52:30,240
 they accept it. So what I've essentially done is forked the EL to build on top of the girly state

520
00:52:30,240 --> 00:52:36,579
 but just for my subset of validators. No one else has any indication of this.

521
00:52:37,760 --> 00:52:44,360
 This new chain builds on top until infinity. Everyone who has a balance on girly will also

522
00:52:44,360 --> 00:52:50,619
 have a balance on this shadow fork. Some intricacies of course but all of it is essentially

523
00:52:50,619 --> 00:52:57,480
 the same you're building on top of a existing network there's some peering complexities on top

524
00:52:57,480 --> 00:53:02,839
 there's some mempool complexities on top i won't really go into that over here but you would stay

525
00:53:02,839 --> 00:53:08,019
 peered you would still fetch from the mempool for a certain amount of time slowly the state

526
00:53:08,019 --> 00:53:12,719
 will continue to diverge because you're allocating transactions in different orders your

527
00:53:12,719 --> 00:53:20,059
 balances go out of sync after a while and then you stop peering with the main network and then

528
00:53:20,059 --> 00:53:23,900
 ShadowFork is just it's own thing and will continue until you shut it down.

529
00:53:24,539 --> 00:53:28,699
 But for that period of time where it stays connected to the main network it's very very

530
00:53:28,699 --> 00:53:33,820
 valuable. And based on most testing this period of time is not trivial it stays like two days,

531
00:53:33,820 --> 00:53:38,460
 three days depending on the size of your network and number of transactions and what you do with

532
00:53:38,460 --> 00:53:47,820
 this ShadowFork and so on. I know it was quick after the previous question session but usually

533
00:53:47,820 --> 00:53:53,660
 ShadowFox, since it's a biggish topic, I do want to stop for questions before we talk about what

534
00:53:53,660 --> 00:53:57,580
 tools we have and what you can play around with in the testing world.

535
00:54:00,620 --> 00:54:05,820
 Right, thank you Pari. So ShadowFox are very exciting, I love to follow them and see what

536
00:54:05,820 --> 00:54:10,940
 nodes drop off and it just gives us this exciting feeling about getting to the

537
00:54:10,940 --> 00:54:22,280
 it's always like a little moon lounge or something like that.

538
00:54:22,280 --> 00:54:25,159
 I'm waiting for some questions to come in.

539
00:54:25,159 --> 00:54:28,340
 Maybe while we're waiting, there's a link I've sent,

540
00:54:28,340 --> 00:54:31,079
 and you could open this link, and then I

541
00:54:31,079 --> 00:54:35,760
 can showcase what is happening.

542
00:54:35,760 --> 00:54:40,360
 So you can actually, we've added ShadowFox to OpsCore,

543
00:54:40,360 --> 00:54:45,320
 fox to kurtosis so you can do like a one-line shadow fork just with the kurtosis command

544
00:54:45,320 --> 00:54:53,000
 and we do this with vocal um on a ci on a nightly basis so i talk about this later as well and i

545
00:54:53,000 --> 00:54:58,360
 think i've linked it later in the slide maybe since we're up here or you can open the link

546
00:55:00,599 --> 00:55:08,920
 so um what you see here is the kurtosis config um as you this was updated just three hours ago this

547
00:55:08,920 --> 00:55:12,079
 This is a live testing system, right?

548
00:55:12,079 --> 00:55:16,079
 So Guillaume is working on rebasing the work code base

549
00:55:18,039 --> 00:55:19,500
 such that both the transition

550
00:55:19,500 --> 00:55:23,500
 as well as work genesis happens in the same thing

551
00:55:23,500 --> 00:55:25,139
 and it has a concept in it.

552
00:55:26,320 --> 00:55:29,360
 So this is the rebase that we are testing.

553
00:55:29,360 --> 00:55:31,760
 We've defined one time load star get

554
00:55:31,760 --> 00:55:35,240
 and one time, this time it's both load star get,

555
00:55:35,240 --> 00:55:36,820
 you could also just change count two

556
00:55:36,820 --> 00:55:40,260
 and achieve the same thing.

557
00:55:40,260 --> 00:55:45,380
 I want Electra to happen at fort epoch 1, so this is when the work will transition actually

558
00:55:45,380 --> 00:55:46,380
 happens.

559
00:55:46,380 --> 00:55:54,880
 And here, I'm doing network holeski-shadowfork-workl, and network sync base URL, and this, we're

560
00:55:54,880 --> 00:55:59,760
 running it locally, so we have an S3 bucket with the holeski snapshot.

561
00:55:59,760 --> 00:56:05,880
 So what this does is, Kurtosis will go to this IP address and fetch the S3 bucket that

562
00:56:05,880 --> 00:56:11,160
 has the entire holsky state it will then start geth with this holsky state

563
00:56:11,880 --> 00:56:20,440
 and it will have a vocal fork that happens at epoch one so the only part missing in this situation

564
00:56:21,160 --> 00:56:28,440
 was how do i know the transition succeeded or not right um and just for some more sprinkling

565
00:56:28,440 --> 00:56:33,880
 of clarity we do this on a kubernetes cluster so if you see global node selector um

566
00:56:33,880 --> 00:56:38,599
 that doesn't mean anything to anyone else except our Kubernetes instance it

567
00:56:38,599 --> 00:56:42,440
 will run this transition on one machine that knows how to access that IP address.

568
00:56:42,440 --> 00:56:50,300
 So we're running this other tool called Asserta and you might have seen this once or twice and

569
00:56:50,300 --> 00:56:54,940
 in the future I will be going a bit deeper into what it does but what Asserta does is

570
00:56:54,940 --> 00:57:02,820
 it checks and asserts that a certain condition is true or false and in this case Asserta is

571
00:57:02,820 --> 00:57:06,059
 is fetching this test definition,

572
00:57:06,059 --> 00:57:08,059
 work will conversion check,

573
00:57:08,059 --> 00:57:10,880
 and every epoch or so it checks

574
00:57:10,880 --> 00:57:13,180
 if the work or transition was a success.

575
00:57:13,180 --> 00:57:15,059
 So from the CI perspective,

576
00:57:15,059 --> 00:57:18,120
 what this looks like is once a day,

577
00:57:18,120 --> 00:57:21,240
 I'm pulling the latest image from Guillaume's fork,

578
00:57:21,240 --> 00:57:23,780
 I'm fetching the latest Holsky snapshot,

579
00:57:23,780 --> 00:57:26,039
 I'm going through the entire work or transition,

580
00:57:26,039 --> 00:57:28,740
 and then Asserta will give me a tick or a cross

581
00:57:28,740 --> 00:57:31,360
 in GitHub CI that tells me if the transition

582
00:57:31,360 --> 00:57:36,880
 a success last night or not um you can also trigger this manually so if i've made a big change

583
00:57:36,880 --> 00:57:42,400
 and before i merge in a pr i want to make sure that it's working i can do this and this is just

584
00:57:42,400 --> 00:57:49,840
 an example of work right there's no reason that um this cannot happen otherwise so you can also

585
00:57:49,840 --> 00:57:56,000
 run this locally on your machine if you don't specify a network sync base url you're just going

586
00:57:56,000 --> 00:58:01,920
 to sync a holesky node locally it's not a big deal it'll just take more time so you probably want to

587
00:58:01,920 --> 00:58:07,199
 add a bigger genesis delay but 100 seconds is enough for a local network to pull a snapshot so

588
00:58:07,199 --> 00:58:08,639
 we're we're running it with that

589
00:58:12,880 --> 00:58:18,000
 awesome thank you very much pari for showing us this um because it was there was a question

590
00:58:18,000 --> 00:58:23,760
 there like what is the tooling to run shadow for it so you just yeah yeah so there's one example

591
00:58:23,760 --> 00:58:38,300
 there and maybe there's another quick example it should be yes so I will send

592
00:58:38,300 --> 00:58:44,880
 you another link one second so there's another link if you could open this

593
00:58:44,880 --> 00:58:56,640
 mario

594
00:58:59,519 --> 00:59:07,200
 yeah so this is our um ci runner for um for kurtosis itself and we want to test that

595
00:59:07,200 --> 00:59:11,920
 we're not breaking any functionality so we've just defined a wide range of things that you

596
00:59:11,920 --> 00:59:19,200
 can do with kurtosis and then the ci just runs it on before a pr um so if you ever need examples for

597
00:59:19,200 --> 00:59:25,039
 how to configure a certain thing this is the place to look and for example you can see hoski shadow

598
00:59:25,039 --> 00:59:35,039
 fork work no run a bit up in the hitch hitch yeah that so here you're looking at uh or maybe go back

599
00:59:35,039 --> 00:59:45,119
 and look at the next example uh so without work yes so this example is where uh you are simply

600
00:59:45,119 --> 00:59:52,079
 doing a husky shadow fork that will run the latest version of get teku that's it there's no complexity

601
00:59:52,079 --> 00:59:57,759
 and you have to of course set denkoon for kipok is zero because the whole ski network has already had

602
00:59:57,759 --> 01:00:04,639
 denkoon um and then this will spin up a explorer for you that's that's all this file is doing so

603
01:00:04,639 --> 01:00:07,579
 So you can play around with ShadowFox all you want,

604
01:00:07,579 --> 01:00:09,900
 single one-liner, you can override the images

605
01:00:09,900 --> 01:00:11,239
 if you want to test your changes,

606
01:00:11,239 --> 01:00:13,940
 you can, yeah, do a lot of things,

607
01:00:13,940 --> 01:00:17,699
 and we also support Ephemery.

608
01:00:17,699 --> 01:00:19,779
 Yeah, you can, by the way,

609
01:00:19,779 --> 01:00:23,059
 also use Kurtosis to sync a live network.

610
01:00:23,059 --> 01:00:25,239
 So if you go back to Ephemery,

611
01:00:27,579 --> 01:00:31,599
 this will spin up all of these participants

612
01:00:31,599 --> 01:00:33,159
 and configure them to sync

613
01:00:33,159 --> 01:00:35,039
 to the latest iteration of ephemerly.

614
01:00:36,440 --> 01:00:38,639
 Nothing else is needed, you sync to ephemerly

615
01:00:38,639 --> 01:00:42,440
 and that's it, you can change ephemerly to be mainnet,

616
01:00:42,440 --> 01:00:44,199
 I really don't recommend mainnet

617
01:00:44,199 --> 01:00:46,420
 because kurtosis is a local testing tool,

618
01:00:46,420 --> 01:00:49,659
 it's not meant for mainnet level,

619
01:00:49,659 --> 01:00:53,039
 one terabyte node, your laptop will get filled up,

620
01:00:53,039 --> 01:00:55,819
 we only do mainnet on kubernetes,

621
01:00:55,819 --> 01:00:58,519
 but you can do polsky, sepolia, whatever it is,

622
01:00:58,519 --> 01:01:01,079
 and it will sync that network that you specify.

623
01:01:01,079 --> 01:01:07,239
 if you do so the naming convention we also try to standardize things so it's always network name

624
01:01:07,799 --> 01:01:13,400
 dash shadow fork if you want to do dash shadow fork and then if you put vocal after that then

625
01:01:13,400 --> 01:01:18,119
 there's some genesis magic that happens that uses the vocal genesis information

626
01:01:20,119 --> 01:01:27,799
 yeah awesome yeah yeah thanks much it's very interesting uh beginning to the

627
01:01:27,800 --> 01:01:40,940
 package repo so there are some questions on on Shadow forks how do we define

628
01:01:40,940 --> 01:01:47,900
 successful transition it's simply clients not failing up but you have some

629
01:01:47,900 --> 01:01:56,059
 to the definitions of tests that you measured um usually for us the transition success right now

630
01:01:56,059 --> 01:02:03,820
 is just if all the nodes are at the same head and if the the we're working with the gets guys to add

631
01:02:03,820 --> 01:02:10,700
 an api to know when the transition is done um and then we yeah we just wait for them to all be on

632
01:02:10,700 --> 01:02:16,220
 the same head and for the logs i think to not show that it's the transaction in progress or something

633
01:02:16,219 --> 01:02:21,500
 But yeah, we want to make that configurable via API so that you can just query the API

634
01:02:21,500 --> 01:02:24,779
 and it says transition in progress or transition completed.

635
01:02:24,779 --> 01:02:27,559
 Thank you.

636
01:02:27,559 --> 01:02:35,019
 And a question, whether you can run a new validators, remove validators from ShadowForks,

637
01:02:35,019 --> 01:02:38,459
 whether it's further testing that you do?

638
01:02:38,459 --> 01:02:40,299
 Could you repeat that?

639
01:02:40,299 --> 01:02:41,599
 If you run new validators?

640
01:02:41,599 --> 01:02:47,059
 So yeah, if you after the Shadowfork, whether it's one of the tests you do or you can do

641
01:02:47,059 --> 01:02:51,019
 is like doing it deposit it up in your yes.

642
01:02:51,019 --> 01:02:58,219
 So I will talk about that particular question when I'm introducing it to you guys.

643
01:02:58,219 --> 01:02:59,779
 But for now, the answer is yes.

644
01:02:59,779 --> 01:03:01,480
 And I will show you how.

645
01:03:01,480 --> 01:03:02,480
 Okay, awesome.

646
01:03:02,480 --> 01:03:03,480
 Awesome.

647
01:03:03,480 --> 01:03:04,480
 Thank you so much.

648
01:03:04,480 --> 01:03:14,880
 There were some questions for demoing the issue with Kurtosis,

649
01:03:14,880 --> 01:03:17,860
 but it's a log, so maybe we can leave it for later.

650
01:03:17,860 --> 01:03:19,740
 Yeah.

651
01:03:19,740 --> 01:03:23,599
 Kurtosis guys also have a Discord.

652
01:03:23,599 --> 01:03:25,920
 They have a product support page.

653
01:03:25,920 --> 01:03:28,320
 Please feel free to put stuff there.

654
01:03:28,320 --> 01:03:29,699
 Because we actively change stuff,

655
01:03:29,699 --> 01:03:31,099
 sometimes we also break things.

656
01:03:31,099 --> 01:03:33,420
 But we try as much as possible not to break.

657
01:03:34,480 --> 01:03:43,039
 Awesome Pari, go ahead and we will get to the questions.

658
01:03:43,039 --> 01:03:48,800
 I think we have roughly about half an hour for the rest of the calls.

659
01:03:48,800 --> 01:03:53,280
 That should be enough for finishing questions.

660
01:03:53,280 --> 01:03:57,960
 Okay, so overview about handy tools.

661
01:03:57,960 --> 01:04:01,019
 We have a website, ethpandaops.io.

662
01:04:01,019 --> 01:04:08,059
 visit the website pretty self-explanatory the there's a tool there's a tools page on the top

663
01:04:08,059 --> 01:04:14,980
 right you can see all the tools that we maintain as well as all the tools that we um that we have

664
01:04:14,980 --> 01:04:19,360
 along with some blog posts on how to use them and more are coming there's an asserter blog post

665
01:04:19,360 --> 01:04:25,259
 coming up this week next week at this time all the code bases for every single tool we build

666
01:04:25,260 --> 01:04:33,100
 can be found in github everything is open source except for our logic is the tool is always open

667
01:04:33,100 --> 01:04:38,920
 sourced the config depending on if there's secrets or anything might not be open source but every

668
01:04:38,920 --> 01:04:44,140
 single tool every single test we have is open source from a licensing perspective we tend to

669
01:04:44,140 --> 01:04:53,300
 use mit sometimes it may be gpl agpl but 99 of the time is mit so feel free to fork away feel free to

670
01:04:53,300 --> 01:05:00,280
 make PRs, add features. We're very happy when people add features. Yeah, also happy to modify

671
01:05:00,280 --> 01:05:07,600
 our tools to support anyone else. We often, the tools get reused by other networks. They get used

672
01:05:07,600 --> 01:05:15,620
 by L1s, L2s. Some of the DVT guys like Obal also use some of the tools. So we try to accommodate

673
01:05:15,620 --> 01:05:22,780
 everyone's needs so that there's also better maintenance. That's how you build an ecosystem

674
01:05:22,780 --> 01:05:29,420
 around things rather than everyone building their own thing in silos um there's some reading for you

675
01:05:29,420 --> 01:05:37,180
 guys and i will make sure to also put this later in uh some some talk or copy it around but there's

676
01:05:37,180 --> 01:05:42,540
 a testing overview doc so both mario and i spent some time over the last week compiling it it is

677
01:05:42,540 --> 01:05:49,820
 not exhausted yet but we are getting there it aims to define every single major testing tool that we

678
01:05:49,820 --> 01:05:59,740
 have as well as who the maintainer is, what the tool does, and what layer of the stack the tool

679
01:05:59,740 --> 01:06:12,940
 is touching or testing. So please have a look at this one. As we go into Pectra,

680
01:06:12,940 --> 01:06:18,460
 we're also going to use this testing overview doc to try and understand what order we should test

681
01:06:18,460 --> 01:06:24,539
 things to coordinate a bit better between the different teams if you're interested in testing

682
01:06:24,539 --> 01:06:30,860
 in itself find a project start contributing keep an eye out on ith r d interop usually

683
01:06:31,980 --> 01:06:36,539
 you might notice oh this is hard this is difficult does anyone know how to do this test

684
01:06:36,539 --> 01:06:43,900
 pick it up make a tool make a pr to an existing tool um add support for a new fork usually when

685
01:06:43,900 --> 01:06:49,420
 neofock is defined there's like a list of prs we have to do some for some libraries some for

686
01:06:49,420 --> 01:06:54,619
 some genesis tools some for tooling uh help us make those prs that's a great way to learn about

687
01:06:54,619 --> 01:07:02,460
 a neofock so the first tool big one that i'm going to talk about was kurtosis so we've covered it i

688
01:07:02,460 --> 01:07:08,940
 think in quite extensive detail so i won't be going more into kurtosis uh please have a look

689
01:07:08,940 --> 01:07:17,179
 at the github test join the it are the ethereum kato sorry the kurtosis discord chat uh server

690
01:07:17,179 --> 01:07:22,780
 in case you have questions uh they have a great support team um yeah like i said everything is

691
01:07:22,780 --> 01:07:29,900
 open sourced feel free to use it as much as you want template devnets so i did mention this the

692
01:07:29,900 --> 01:07:37,659
 template devnets uh repository is combining all of these different ansible terraform as well as

693
01:07:37,659 --> 01:07:44,539
 Genesis files and all of this into one coherent repository. So GitHub has this feature where

694
01:07:45,420 --> 01:07:51,659
 you can fork a repo out of a template or it's kind of like implement a template, right?

695
01:07:52,460 --> 01:07:56,859
 So if you go to the template test net, there should be a button somewhere that says use this

696
01:07:56,859 --> 01:08:02,219
 template. And what that will do is it will create a new repository using that template in your

697
01:08:02,219 --> 01:08:08,779
 namespace and we often do this for example if you go to work with dev nets on the top somewhere

698
01:08:08,779 --> 01:08:16,219
 it will say forked from template test net or part of template test net thing so if you ever want to

699
01:08:16,219 --> 01:08:21,420
 know the entire diff between our template and workl just make a pr between main and main and

700
01:08:21,420 --> 01:08:28,939
 you will see all the changes required for buckle testing um this is very useful if you want to

701
01:08:28,939 --> 01:08:34,299
 run nodes on a larger scale if you want to run your own ethereum nodes so i run ethereum nodes

702
01:08:34,299 --> 01:08:40,479
 at home we run ethereum nodes in the office uh we use this exact infrastructure for doing all of it

703
01:08:40,479 --> 01:08:47,179
 it's very mainnet compatible it's very safe feel free to use it there's not much magic that happens

704
01:08:47,179 --> 01:08:55,379
 this is this level of testing you normally get to once the local testing tools are inadequate

705
01:08:55,380 --> 01:09:03,079
 it tends to happen a bit later in the fork process so if anyone is questioning it i would say spend

706
01:09:03,079 --> 01:09:08,140
 more time on kurtosis because with template testnet you need to know what ansible is you

707
01:09:08,140 --> 01:09:13,180
 need to know what terraform is before you can actually start doing stuff and if you for example

708
01:09:13,180 --> 01:09:19,600
 spin up a terraform a bunch of cloud instances which terraform that's also going to cost you

709
01:09:19,600 --> 01:09:25,000
 money whereas in kurtosis the worst thing that can happen is that you have a docker container

710
01:09:25,000 --> 01:09:31,239
 running for one day too long. There's no risk involved there. So play around with template

711
01:09:31,239 --> 01:09:38,359
 test net, especially if you're someone who's looking to get into a bit more DevOps-y role,

712
01:09:38,359 --> 01:09:42,920
 a bit more deep insight into how DevOps works, then this is the place to go.

713
01:09:45,000 --> 01:09:51,960
 So now for the big one, Asserta. So you can find the Asserta repository under ithpandaops.

714
01:09:51,960 --> 01:09:57,659
 The idea of Asserta is it asserts a network level expectation.

715
01:09:57,659 --> 01:10:01,260
 Example, can a network handle deposits?

716
01:10:01,260 --> 01:10:05,920
 Can it handle a transaction that has every opcode being called?

717
01:10:05,920 --> 01:10:07,659
 Can it handle a reorg?

718
01:10:07,659 --> 01:10:10,699
 That's the question that Asserta tries to answer.

719
01:10:10,699 --> 01:10:17,920
 And it's a generalized testing tool, so you can use this for assertions on any network.

720
01:10:17,920 --> 01:10:24,180
 you just have to define what the assertion is, what the health check or what is correct wrong is,

721
01:10:24,520 --> 01:10:28,800
 and then you have to run Assertor with that test definition, and you have to point it at which

722
01:10:28,800 --> 01:10:34,500
 nodes to check. So when you do these three things, Assertor will check those nodes based on your

723
01:10:34,500 --> 01:10:39,199
 definition, and it will assert the definition assertion that you've given over there.

724
01:10:40,239 --> 01:10:45,960
 So the example that I was mentioning was the transitional success. So ideally, we'd like to

725
01:10:45,960 --> 01:10:52,840
 it in a place where I can just query all the APIs and the API says transition success equals

726
01:10:52,840 --> 01:10:58,520
 to a transition equals complete and then Asserta will say okay the work transition was defined as

727
01:10:58,520 --> 01:11:04,760
 when this API call returns true then it's done and you can add a timeout saying if it doesn't happen

728
01:11:04,760 --> 01:11:10,199
 within one hour then it's a fail and Asserta will say okay it didn't happen within one hour

729
01:11:10,199 --> 01:11:17,159
 let's return a fail. Asserta can be interacted with via the API, so you can run it and then

730
01:11:17,159 --> 01:11:23,720
 configure tests. This is very useful in some cases like Kubernetes or if you have public instances,

731
01:11:23,720 --> 01:11:29,319
 you can also run it at runtime with all the tests defined, you can fetch information from

732
01:11:29,319 --> 01:11:35,319
 Asserta via its API, you can fetch information via its logs. It's kind of like this middleware

733
01:11:35,319 --> 01:11:42,599
 that does everything you need it to do for ensuring a network behaves as it should behave

734
01:11:45,079 --> 01:11:51,159
 because the timeouts are also configurable, we do deposit tests with this, we do withdrawal

735
01:11:51,159 --> 01:11:57,880
 tests with this, we do slashing tests with this, so I can define how a Sorter creates a

736
01:11:57,880 --> 01:12:02,439
 slashable condition and then it executes the slashable condition for me and it makes sure

737
01:12:02,439 --> 01:12:08,839
 that every node has accepted the slam. So you know that when and if this happens on a real network,

738
01:12:08,839 --> 01:12:15,159
 that all of these are working. You can also configure something like, make sure that every

739
01:12:15,799 --> 01:12:22,199
 node in my local dev net has proposed a block at least once. And this is really useful for

740
01:12:24,359 --> 01:12:28,199
 fork testing, because you want to make sure that you're not breaking attestations, that you're not

741
01:12:28,199 --> 01:12:32,519
 breaking proposals, that you're not breaking the fundamental parts of what makes a network.

742
01:12:34,599 --> 01:12:41,079
 Yeah, so you can do a lot of these things. And we also do, we're currently focusing on trying to get

743
01:12:41,720 --> 01:12:47,159
 every validator client compatible with every beacon node. So that's a quite a big matrix.

744
01:12:47,960 --> 01:12:54,199
 And that should be compatible with every execution layer node. And you can see in, I think in

745
01:12:54,199 --> 01:12:59,639
 kurtosis already in the page we have a matrix of which combinations don't work you might see

746
01:12:59,639 --> 01:13:04,840
 some chatter about this on the interop channel as well um and we're slowly taking them off

747
01:13:04,840 --> 01:13:12,039
 one by one we're getting there but we primarily use assorter to figure this out um it can also

748
01:13:12,039 --> 01:13:17,880
 be run locally so like i showed you earlier via kurtosis it has a certain built-in or you can

749
01:13:17,880 --> 01:13:23,399
 integrate it into a ci so there's an assertive github action and you can use this github action

750
01:13:23,399 --> 01:13:29,399
 in your repository that's what we've done with the vocal uh devnets repository so that just calls

751
01:13:29,399 --> 01:13:34,920
 a sort of points it at a in that example a kubernetes cluster it does a shadow fork and

752
01:13:34,920 --> 01:13:42,039
 that shadow fork as seen here that shadow fork does the local conversion check the test as you

753
01:13:42,039 --> 01:13:46,119
 might have guessed can also be a local definition it doesn't have to be a remote definition it could

754
01:13:46,119 --> 01:13:53,319
 be a github gist it can be a notes on hackmd it can be whatever you want it to be so it's a very

755
01:13:53,319 --> 01:13:57,639
 very generalized testing tool please use a Sauter as much as possible it's a

756
01:13:57,639 --> 01:14:01,779
 relatively new tool it's only a few months old at this point so it hasn't

757
01:14:01,779 --> 01:14:08,799
 gotten the prime time that it deserves but we're hoping to use it more and for

758
01:14:08,799 --> 01:14:12,699
 those of you who attended Mario's call you might notice that it has a lot of

759
01:14:12,699 --> 01:14:18,219
 overlap with hive so hive also does a lot of assertions right it says I give

760
01:14:18,219 --> 01:14:22,420
 this transaction this is the EVM state transition that needs to happen did that

761
01:14:22,420 --> 01:14:27,260
 happen on this node. Hive does this. So why did we build a whole new tool to do this?

762
01:14:27,960 --> 01:14:36,100
 Because the way Hive is architected it's very very nice for single nodes. It is possible in Hive

763
01:14:36,100 --> 01:14:43,920
 to do inter-orb multiple node testing it's just more cumbersome and Hive is built such that each

764
01:14:43,920 --> 01:14:49,300
 test takes a very short-ish duration of time. You can configure it to do a longer duration it's not

765
01:14:49,300 --> 01:14:56,460
 made for it. Asserta doesn't have those assumptions. A deposit, for example, on a perfect

766
01:14:56,460 --> 01:15:04,199
 network level thing takes, what, half a day to process through the queue. Hive, it's not

767
01:15:04,199 --> 01:15:10,140
 necessarily multi-threaded in the same way, so it might, depending on how you configure it, get stuck

768
01:15:10,140 --> 01:15:15,140
 on that one deposit until it's processed by the network before it moves on to the next test. So

769
01:15:15,140 --> 01:15:21,280
 Asserta is just built from the ground up to work in a network-wide scenario.

770
01:15:22,079 --> 01:15:25,720
 So the way my mental model works is Hive is what we will always use

771
01:15:25,720 --> 01:15:30,820
 for single-node black box-level testing,

772
01:15:31,420 --> 01:15:33,900
 and Asserta is what we'll use for network-level testing,

773
01:15:33,980 --> 01:15:35,560
 where the network itself is a black box,

774
01:15:35,600 --> 01:15:37,700
 and I just want to assert behaviors in a network.

775
01:15:38,360 --> 01:15:40,579
 So they're very synergetic.

776
01:15:40,579 --> 01:15:46,340
 it's energetic ideally hive finds all the critical bugs before it gets to the

777
01:15:46,340 --> 01:15:49,539
 assortment level but if it does then it's also nice to have these two tools

778
01:15:49,539 --> 01:15:53,720
 that can kind of compare outputs and say hey this should have failed in hive why

779
01:15:53,720 --> 01:15:58,539
 didn't it or this should have failed in assort or why didn't it still give us

780
01:15:58,539 --> 01:16:05,500
 this level of flexibility that that we can benefit from so please try this out

781
01:16:05,500 --> 01:16:12,479
 So let us know if you have feedback, and we'll be announcing it more widely over the next weeks.

782
01:16:15,159 --> 01:16:19,680
 Now for a bit smaller CLI-level tools.

783
01:16:19,960 --> 01:16:23,000
 Some of you might be tempted to work on the fork choice.

784
01:16:24,180 --> 01:16:30,420
 May whichever DAT you believe in support you in that endeavor.

785
01:16:30,420 --> 01:16:36,199
 it's a difficult field and it's very difficult to understand what is going on with fork choice

786
01:16:36,199 --> 01:16:43,960
 hence we built forky so forky is a fork choice visualizer it relies on the beacon node

787
01:16:43,960 --> 01:16:50,899
 standard api so every single node supports it and what this does is it connects to nodes that

788
01:16:50,899 --> 01:16:57,340
 you've linked it to and it visualizes fork choice you can also upload a fork choice from your local

789
01:16:57,340 --> 01:17:02,460
 node and it will visualize this for you it sometimes helps with fork choice debugging

790
01:17:02,460 --> 01:17:09,260
 to see the tree of what was built on what and what weight something had it really really helps

791
01:17:09,260 --> 01:17:16,140
 in a critical situation this can run in uh as a binary as a docker file as a helen chart as

792
01:17:16,140 --> 01:17:22,460
 ansible under kurtosis as you see we support a wide range of things and if you're ever intrigued

793
01:17:22,460 --> 01:17:26,779
 what the forkchars and mainnet does please don't take the instance down by a thousand people

794
01:17:26,779 --> 01:17:32,380
 calling it at the same time but let's see if the auto scaling works well go to this url and you

795
01:17:32,380 --> 01:17:39,179
 will see how the fork choice on ethereum looks exactly at this moment you will see tiny lines

796
01:17:39,179 --> 01:17:45,420
 at the bottom as well those lines are snapshots that are being taken once every slot so you can

797
01:17:45,420 --> 01:17:51,899
 also share that snapshot link with someone and it links to an s3 bucket so even one day later if you

798
01:17:51,899 --> 01:17:57,059
 want to debug something it will load from that snapshot and it's a lot of

799
01:17:57,059 --> 01:18:03,460
 quality-of-life improvements we spend some time on. The next tool I want to

800
01:18:03,460 --> 01:18:08,519
 talk about is Tracer it's still an active work in progress I don't know how

801
01:18:08,519 --> 01:18:13,319
 many of you have worked with the trace API yet but it's not the most standard

802
01:18:13,319 --> 01:18:23,960
 thing in the world and when there's a big mainnet incident, traces tend to be the first thing we go

803
01:18:23,960 --> 01:18:31,019
 to or one of the first things we go to see. So we have a mainnet tracer it connects to one of each

804
01:18:31,019 --> 01:18:38,059
 EL and CL and what it does is every single block it traces it, uploads it there, every single slot

805
01:18:38,060 --> 01:18:46,660
 it gets the beacon SSE, the state SSE, it uploads it there. It has instructions on how to take the

806
01:18:46,660 --> 01:18:52,940
 traces from two different ELs and then compare them to see if there's a diff. Ideally, in mainnet,

807
01:18:53,020 --> 01:18:58,160
 there's zero diffs. But when there's an issue, the diff helps us find out where the problem was.

808
01:18:59,000 --> 01:19:05,160
 And with state.sse, what you can do is you can take the previous state, the next state,

809
01:19:05,159 --> 01:19:10,159
 and then you can use a host of tools to go through this transition. Ideally, every single one of

810
01:19:10,159 --> 01:19:15,059
 those tools gives you the same output. If it doesn't, you have a problem and you need to figure out why.

811
01:19:15,979 --> 01:19:24,260
 And this tool kind of is a tool that we hope to never use, but when you need to use it,

812
01:19:24,319 --> 01:19:30,199
 it's something we want to use. We had a blog post about this recently. And in the same form as

813
01:19:30,199 --> 01:19:33,319
 Checkpoint Z, the team has built this tool,

814
01:19:33,599 --> 01:19:36,340
 but ideally we would like the community to run it.

815
01:19:36,720 --> 01:19:38,519
 We don't want to run this ourselves.

816
01:19:38,519 --> 01:19:41,939
 As an ethos, the ETH Panda Ops team

817
01:19:41,939 --> 01:19:43,880
 tries to never run anything for mainnet

818
01:19:43,880 --> 01:19:46,939
 because we don't want to canonicalize what mainnet is.

819
01:19:47,079 --> 01:19:48,500
 That should be dependent on the community.

820
01:19:48,739 --> 01:19:50,420
 We tend to just run stuff for testnets.

821
01:19:50,899 --> 01:19:52,619
 We are running Tracer for mainnet

822
01:19:52,619 --> 01:19:55,439
 purely until the network effects of community

823
01:19:55,439 --> 01:19:57,260
 running these tools builds up.

824
01:19:58,679 --> 01:20:00,099
 This really helps.

825
01:20:00,199 --> 01:20:01,939
 So if you have a lot, then please do.

826
01:20:04,359 --> 01:20:05,779
 The next one is Dora.

827
01:20:06,720 --> 01:20:12,380
 So Dora is a lightweight beacon chain explorer, extremely extendable.

828
01:20:12,579 --> 01:20:16,340
 So we have Dora for Verkle, we have Dora for Holsky, you have Dora for everything.

829
01:20:17,019 --> 01:20:22,019
 Even the beacon chain guys run Dora as a backup in case beacon chain has a problem.

830
01:20:22,760 --> 01:20:25,019
 It gives you low-level access to the database.

831
01:20:25,020 --> 01:20:32,000
 so much so that you can it you can run dora and very often when we want to do some mev style

832
01:20:32,000 --> 01:20:36,480
 analysis we just run like a sql query against the dora database and we get the information we want

833
01:20:36,480 --> 01:20:44,320
 to do it's very extendable very useful please have a look easy to run and dora has a built-in

834
01:20:44,320 --> 01:20:48,740
 like fork visualizer so if you have 10 nodes it'll tell you if two of those nodes are forked

835
01:20:48,739 --> 01:20:57,779
 or whatever you can do ELF or CLFox it does all the nice things the next one and last tool I'm

836
01:20:57,779 --> 01:21:04,979
 going to talk about today is xatu anyone who is really interested in data and data visualization

837
01:21:05,779 --> 01:21:10,659
 should be paying attention to these two repositories the ethereum peer-to-peer

838
01:21:10,659 --> 01:21:16,420
 layer is notoriously hard to get visibility about there's a lot of noise to go through

839
01:21:16,420 --> 01:21:18,699
 There's millions of events that go through.

840
01:21:22,380 --> 01:21:23,699
 Okay, that's something different.

841
01:21:23,699 --> 01:21:26,819
 There's millions of events to go through.

842
01:21:26,819 --> 01:21:31,220
 There's literally every slot, a couple million

843
01:21:31,220 --> 01:21:34,460
 or a couple hundred thousand attestations that go through it.

844
01:21:34,460 --> 01:21:37,579
 So what we did is Zhaotu

845
01:21:40,380 --> 01:21:44,300
 analyze or collect all of this data, puts it in a shared database,

846
01:21:44,300 --> 01:21:51,720
 And then you can use a tool like Grafana that visualizes this,

847
01:21:51,860 --> 01:21:53,960
 but the database can also be queried directly.

848
01:21:54,699 --> 01:21:58,159
 All the data or almost all of the data that Zato has is open sourced.

849
01:21:58,340 --> 01:22:02,079
 We're still in the process of open sourcing whatever's left over.

850
01:22:02,900 --> 01:22:05,820
 And in case you're someone who's interested in the data challenge

851
01:22:05,820 --> 01:22:09,579
 that the Ethereum Foundation's organizing right now,

852
01:22:09,940 --> 01:22:11,199
 please have a look at the Zato data.

853
01:22:11,340 --> 01:22:13,820
 It might save you a lot of time from collecting your own.

854
01:22:14,300 --> 01:22:21,279
 The way it works is, we have these things called xatu sentries, so these sentries collect

855
01:22:21,279 --> 01:22:27,360
 to a consensus node, and it uses the event stream, it fetches the event stream, it annotates

856
01:22:27,360 --> 01:22:31,039
 the data and pushes it to xatu server.

857
01:22:31,039 --> 01:22:35,380
 There's another crawler that does some diskv5, diskv4 stuff, there's something else that

858
01:22:35,380 --> 01:22:43,720
 collects mempool data, all of this gets backfilled, put in xatu server, and this is persisted

859
01:22:43,720 --> 01:22:50,440
 I think we have over a year worth of main net data in this pipeline, a couple billion rows in it,

860
01:22:50,440 --> 01:22:57,280
 there's a lot. And all of this gets ingested into a data pipeline. And the reason it goes into a data

861
01:22:57,280 --> 01:23:03,900
 pipeline is the questions you want to answer are not apparent from the data, you might need to do

862
01:23:03,900 --> 01:23:09,820
 transformations, you might need to do some amount of analysis, right, and you want to canonicalize

863
01:23:09,819 --> 01:23:15,259
 these analyses so we have an entire data pipeline built for this already and the output of the data

864
01:23:15,259 --> 01:23:21,340
 pipeline can be graphs like this where you can see a heat map of when attestations arrive at which

865
01:23:21,340 --> 01:23:27,019
 millisecond in which network you can see how long they took to propagate along the network so

866
01:23:27,019 --> 01:23:32,219
 something you might find interesting is usually there's a strong heat map at the four second mark

867
01:23:32,219 --> 01:23:38,299
 because that's when there's a attestation deadline and proposals tend to go through then before that

868
01:23:38,300 --> 01:23:43,220
 And you can also look at blob sidecars and when different nodes saw it.

869
01:23:43,340 --> 01:23:46,220
 And you can create like a P95 metric for this to know,

870
01:23:46,940 --> 01:23:50,520
 okay, I have 100 nodes in 50 different locations.

871
01:23:50,520 --> 01:23:57,340
 And 95% of them saw a particular number of blobs arrive

872
01:23:57,340 --> 01:24:02,140
 well under a certain time that we expect the network to handle in a healthy manner.

873
01:24:02,500 --> 01:24:06,300
 This allows us to make really deep decisions on Ethereum,

874
01:24:06,300 --> 01:24:10,440
 how many blobs to have, how the propagation statistics look like, etc.

875
01:24:11,300 --> 01:24:14,619
 And the entire stack is reproducible on testnets.

876
01:24:14,779 --> 01:24:18,500
 We do reproduce it on testnets, and it helps us answer a lot of these questions.

877
01:24:19,860 --> 01:24:23,699
 One thing we're still working on is trying to automate more analyses.

878
01:24:23,699 --> 01:24:26,060
 So you might notice in the ETH PandaOps blog,

879
01:24:26,180 --> 01:24:29,760
 we have one manual analysis done for the mainnet and KuhnFork.

880
01:24:29,760 --> 01:24:39,260
 we're trying to analyze and figure out how to better get that kind of output without someone

881
01:24:39,260 --> 01:24:46,340
 having to sift through the data each time there's some answers to use stuff like local llm models to

882
01:24:46,340 --> 01:24:51,739
 analyze the data still not really happy if someone wants to explore that side please do

883
01:24:51,739 --> 01:24:57,960
 the data is all out there so yeah i think that's a great synergy that could exist

884
01:24:57,960 --> 01:25:05,159
 and what next um like i was mentioning i think in most of the call the highest value thing i

885
01:25:05,159 --> 01:25:09,939
 would like you guys to take away is how to run your local devnet and how to do a prototype

886
01:25:09,939 --> 01:25:19,079
 so please at the bare minimum fork a client add hello world to the terminal output run

887
01:25:19,079 --> 01:25:24,180
 kurtosis with your fork client and be happy that your name is printed out in the get logs

888
01:25:24,180 --> 01:25:30,659
 and that's just a gateway to get you into knowing how the system works into how you can extend it

889
01:25:30,659 --> 01:25:36,280
 there was someone last year from the protocol fellowship who worked on

890
01:25:36,280 --> 01:25:41,680
 a version of i want to say epbs but i'm not particularly sure if it was epbs or not

891
01:25:41,680 --> 01:25:48,680
 and he used kurtosis extensively for his testing and once he was done with kurtosis for his testing

892
01:25:48,680 --> 01:25:52,600
 He also migrated the entire stack onto the girly network, I think.

893
01:25:53,619 --> 01:25:57,240
 And that helped give us a lot of insight into what works, what doesn't work.

894
01:25:57,360 --> 01:26:01,980
 He worked with the researchers to do some analysis on how difficult the implementation might be,

895
01:26:02,060 --> 01:26:03,820
 what edge cases might exist and so on.

896
01:26:04,840 --> 01:26:13,100
 And I do think that everyone should use tests and testing as a great starting point

897
01:26:13,100 --> 01:26:16,560
 because it's a really nice way to learn how Ethereum works.

898
01:26:16,560 --> 01:26:23,220
 please again go through whatever mario has shown you guys in the last uh talks the testing team is

899
01:26:23,220 --> 01:26:28,700
 amazing they're very accommodating and we are really accommodating as well so if you feel like

900
01:26:28,700 --> 01:26:33,720
 you want to contribute to any layer of the testing stack please do write tests write a sort of test

901
01:26:33,720 --> 01:26:39,780
 write hive tests write spec tests whatever they are and that gives you a new understanding how

902
01:26:39,780 --> 01:26:44,800
 of how ethereum works what the edge cases are so that when you're working on whatever you

903
01:26:44,800 --> 01:26:49,900
 work you want to work on you know what the entire space looks like and what

904
01:26:49,900 --> 01:26:56,480
 considerations you might want to have and thank you help us with testing the

905
01:26:56,480 --> 01:27:01,880
 next fork follow github follow me on Twitter and we hopefully it's left some

906
01:27:01,880 --> 01:27:10,960
 time for questions it's great and it was a lot I it's it's why I was saying in

907
01:27:10,960 --> 01:27:13,960
 the beginning that you became care of a cover house of these tools because

908
01:27:13,960 --> 01:27:16,239
 There are just so many of them.

909
01:27:16,239 --> 01:27:23,260
 And yeah, I just want to repeat what you said, it's one of the great ways to learn how it

910
01:27:23,260 --> 01:27:27,520
 works and just running all these tools, like connecting them to your client and seeing

911
01:27:27,520 --> 01:27:30,279
 the metrics and what is actually happening there.

912
01:27:30,279 --> 01:27:36,140
 It's really great. And also, so what you said that you can avoid running it on the main

913
01:27:36,140 --> 01:27:41,359
 ad publicly. So, guys, if anybody wants to host this, feel free, I guess.

914
01:27:41,359 --> 01:27:45,139
 it I'm actually I was actually running tracer on my note I was trying to figure

915
01:27:45,139 --> 01:27:50,960
 something out I did it but it I read it and maybe I should have hosted it's

916
01:27:50,960 --> 01:27:57,000
 it's pretty cool to know yeah thank you Pari for everything it's it's been it's

917
01:27:57,000 --> 01:28:04,519
 been quite a lot so people like the domain question is it people want to see

918
01:28:04,520 --> 01:28:10,840
 you do some demos, some practical experiment.

919
01:28:10,840 --> 01:28:12,560
 But I'm not sure whether we have time for that

920
01:28:12,560 --> 01:28:15,860
 and whether you are available.

921
01:28:15,860 --> 01:28:17,660
 And you already mentioned many things

922
01:28:17,660 --> 01:28:19,880
 that people can try themselves.

923
01:28:19,880 --> 01:28:23,840
 I can, if you want, quickly run a kurtosis test on something

924
01:28:23,840 --> 01:28:25,460
 and show you guys how that looks,

925
01:28:25,460 --> 01:28:30,480
 if maybe that's the easiest first thing to do.

926
01:28:30,480 --> 01:28:31,940
 But if there's any other questions,

927
01:28:31,939 --> 01:28:34,219
 Maybe you can do the questions before that.

928
01:28:34,219 --> 01:28:36,099
 Yeah, yeah.

929
01:28:36,099 --> 01:28:38,259
 All right.

930
01:28:38,259 --> 01:28:42,359
 Yeah, people wish for the practical experiment.

931
01:28:42,359 --> 01:28:43,639
 Another question coming in.

932
01:28:43,639 --> 01:28:46,099
 OK.

933
01:28:46,099 --> 01:28:48,519
 Yeah, people are asking about the Python specs,

934
01:28:48,519 --> 01:28:52,399
 or the spec tests, whether you use them at some point here.

935
01:28:52,399 --> 01:28:55,819
 And yeah.

936
01:28:55,819 --> 01:29:00,219
 For Python spec tests, so that tends

937
01:29:00,220 --> 01:29:06,539
 be more of individual so the way we kind of have defined or divided the territory so that we can

938
01:29:07,180 --> 01:29:12,860
 both specialize a bit more easily is anything that you can expect to be tested on a single node

939
01:29:13,740 --> 01:29:21,100
 mario testing team uh python spec team they handle it anything that is expected to be tested at the

940
01:29:21,100 --> 01:29:27,100
 interop level the eth panda ops team tests so that's ideally how we've defined them so i

941
01:29:27,100 --> 01:29:33,340
 personally rarely run spec tests. I help maintain some of the servers that run spec tests but

942
01:29:33,340 --> 01:29:39,260
 otherwise I don't run the spec test myself. Right, it makes sense. I guess it's all like the

943
01:29:39,260 --> 01:29:43,340
 progress where it comes from like specs and implementation that client themes and

944
01:29:43,340 --> 01:29:48,220
 statistics themselves and then it proves to be throughout so like you are already the other

945
01:29:48,220 --> 01:29:53,420
 side there. Just for the context because people are also asking about the

946
01:29:53,420 --> 01:29:58,699
 mario's topic, I will just point you to the week four there, it's all it's all nicely explained

947
01:29:59,260 --> 01:30:09,340
 there. Cool. Okay, if someone wants to maybe see a small example, I can show a real-world use case

948
01:30:09,340 --> 01:30:16,140
 of a problem we had last week, and we are still sort of facing, but we wanted to see. So when you

949
01:30:16,140 --> 01:30:24,060
 run this or when you ran this last week what would happen is the first version

950
01:30:24,060 --> 01:30:30,360
 the first participant was just a CL TeKu the default EL is geth works fine

951
01:30:30,360 --> 01:30:35,600
 TeKu builds in the validator so the validator and beacon is in the same

952
01:30:35,600 --> 01:30:42,660
 process this proposes blocks zero problems the next one is separate VC so

953
01:30:42,659 --> 01:30:46,659
 So in this one, you have a Teco beacon and a Teco validator client.

954
01:30:47,059 --> 01:30:48,639
 And this works fine as well.

955
01:30:48,840 --> 01:30:49,819
 It proposes blocks.

956
01:30:50,000 --> 01:30:50,639
 It can attest.

957
01:30:50,760 --> 01:30:51,420
 Everything is okay.

958
01:30:52,099 --> 01:30:58,399
 But when I do separate VC and Snooper enabled, then it was failing.

959
01:30:59,239 --> 01:31:00,619
 And we didn't know why.

960
01:31:00,840 --> 01:31:07,559
 And the reason it was failing is that the Teco beacon and validator client use a binary

961
01:31:07,560 --> 01:31:14,280
 octet stream to communicate um whatever the payloads that they they want to communicate

962
01:31:14,280 --> 01:31:19,320
 and we have uh i might have to share a different screen

963
01:31:22,760 --> 01:31:24,440
 so we have

964
01:31:28,200 --> 01:31:36,200
 one second let me just share my entire screen yeah so uh yeah you guys should be able to see this

965
01:31:36,199 --> 01:31:43,239
 So we have this one tool that was built by each streamer called JSON-RPC-SNOOP. So JSON-RPC-SNOOP

966
01:31:43,800 --> 01:31:49,559
 is built in Rust and this tool was not able to understand a binary octet stream

967
01:31:50,840 --> 01:31:57,000
 because when that was hit it was hitting edge case so you can see it tries to unwrap it and

968
01:31:57,000 --> 01:32:05,559
 that didn't work out and then it errored out and it crashed and it crashed and we weren't

969
01:32:05,560 --> 01:32:11,640
 able to figure out what was going on so the practical way we figured out what happened was

970
01:32:13,000 --> 01:32:18,920
 then um we spoke to the techu team to ask why this was potentially going on and then

971
01:32:18,920 --> 01:32:25,080
 we had the aha moment oh yeah it's probably because um of octet band restream you can

972
01:32:25,080 --> 01:32:32,600
 disable that so what we did is we added this extra vc parameter and this says uh don't do that just

973
01:32:32,600 --> 01:32:39,880
 give me sse i'm happy and with this i was proposing again so i knew that it was because my

974
01:32:39,880 --> 01:32:48,440
 json rpc snooper was broken so now um the only variable that was left to do is remove this update

975
01:32:48,440 --> 01:32:56,520
 the json rpc snooper and then i have to update the image right so what i did was in my local version

976
01:32:56,520 --> 01:33:13,960
 I would do, yeah, in my local Docker image, I was updating this. So whatever Pari Tosh dot json RPC

977
01:33:15,720 --> 01:33:20,440
 test one, and then I can run this exact same test.

978
01:33:20,439 --> 01:33:36,339
 like this. And now what happens is this exact test definition that I know is broken,

979
01:33:36,979 --> 01:33:43,899
 will use this Docker image instead of what was configured in the remote repository. And I tested

980
01:33:43,899 --> 01:33:49,119
 this extensively locally. And once it worked, I was happy with the solution. I made all the

981
01:33:49,119 --> 01:33:53,739
 adquisite PRs and then we consider this a resolved issue. We found something else

982
01:33:53,739 --> 01:33:57,939
 with the event stream, we're still trying to figure out that something else so if

983
01:33:57,939 --> 01:34:03,739
 someone wants a moderately difficult problem, try this out, try out this config

984
01:34:03,739 --> 01:34:08,539
 and you will see that Teco proposes blocks but every now and then it fails

985
01:34:08,539 --> 01:34:13,880
 with the proposal, just the third participant, and then go to the JSON RPC

986
01:34:13,880 --> 01:34:17,359
 snupper and figure out why it's failing and make a PR and we're very happy about

987
01:34:17,359 --> 01:34:23,000
 about it and I showed you how to test the entire thing locally so you know how to reproduce it you

988
01:34:23,000 --> 01:34:28,659
 know when it's not failing yeah you kind of got the entire picture of how we do prototyping and

989
01:34:28,659 --> 01:34:35,239
 fixing none of this requires me to talk to anyone outside of myself I can test this a million times

990
01:34:35,239 --> 01:34:40,960
 I've never written rust code in my life I was able to use different tools to understand what

991
01:34:40,960 --> 01:34:47,920
 error might have been and try out a few solutions myself without having to push any big changes

992
01:34:47,920 --> 01:34:55,920
 without knowing it works so that's a practical example um yeah i mean i can just run this for

993
01:34:55,920 --> 01:35:04,560
 you if you want it'll take a while but um you can see all the steps it goes through oh well yeah and

994
01:35:04,560 --> 01:35:10,480
 as you can imagine this fails immediately uh because this this image does not exist so

995
01:35:12,080 --> 01:35:20,960
 let's switch back to normal and this will most likely work it will spin up all of my instances

996
01:35:20,960 --> 01:35:27,920
 it will create genesis uh i know we're already uh ahead of out of time mario is it still okay

997
01:35:27,920 --> 01:35:33,520
 if i take a few minutes to finish this of course it's only up to you uh we don't want to you know

998
01:35:33,520 --> 01:35:39,360
 take your time so if you're free it's it's okay right people are still uh uh listening and uh

999
01:35:40,240 --> 01:35:45,520
 very thankful for the experiment very excited uh it's great to see it run it is a great example by

1000
01:35:45,520 --> 01:35:52,320
 the way uh the current issue and relevant also because last week we had um uh in this call we

1001
01:35:52,320 --> 01:35:58,160
 had paul from teku uh explaining uh the tech architecture so they should have an idea uh

1002
01:35:58,159 --> 01:35:59,300
 So it's perfect.

1003
01:36:00,180 --> 01:36:00,619
 Perfect.

1004
01:36:00,899 --> 01:36:03,840
 So if someone wants to make a PR fixing all of our problems,

1005
01:36:03,939 --> 01:36:04,559
 we're very happy.

1006
01:36:07,720 --> 01:36:08,479
 Awesome, awesome.

1007
01:36:09,139 --> 01:36:10,340
 Yeah, it might just take a bit

1008
01:36:10,340 --> 01:36:13,000
 because it also has to download the Docker images,

1009
01:36:13,380 --> 01:36:16,399
 but hopefully it does not take too long.

1010
01:36:16,680 --> 01:36:17,800
 As you can see the steps,

1011
01:36:17,880 --> 01:36:19,939
 it kind of goes through the configuration.

1012
01:36:20,579 --> 01:36:23,939
 It just deploys one by one things that need to be deployed.

1013
01:36:24,260 --> 01:36:26,159
 It will fetch peering information.

1014
01:36:26,159 --> 01:36:31,699
 it will set up peering as expected and I hope you also see kind of this benefit of having an

1015
01:36:31,699 --> 01:36:38,519
 overrideable approach if I add VC extra params I know that my validator is running with one extra

1016
01:36:38,519 --> 01:36:42,979
 parameter and I can test something that the other validators don't have so you can do a

1017
01:36:42,979 --> 01:36:57,299
 a lot of iterating testing this way yeah it should just be yeah creating the validators now and maybe

1018
01:36:57,299 --> 01:37:05,059
 one example of uh how this looks under the hood if i do docker ps dash a it's a bunch of docker

1019
01:37:05,059 --> 01:37:12,419
 containers with tasks and you can see my els here and my cls here but i don't recommend interacting

1020
01:37:12,420 --> 01:37:19,300
 with kurtosis that way if you wait for this to get done the kurtosis cli itself allows you to

1021
01:37:19,300 --> 01:37:24,180
 get all of this information in a much nicer to see way you can interact with it directly with

1022
01:37:24,739 --> 01:37:30,980
 docker nothing stops you but it will give you all of these for example urls if i was

1023
01:37:30,980 --> 01:37:41,699
 to go to this url it will open dora for me um so i will uh quickly just share my screen and

1024
01:37:41,699 --> 01:37:43,059
 show you how DORA looks.

1025
01:37:50,579 --> 01:37:56,819
 So this is DORA it's running on the Dineb fork with my local devnet which has three geth

1026
01:37:56,819 --> 01:38:02,179
 participants. You can look at the blocks, you can look at the graffiti, you can see everything,

1027
01:38:02,179 --> 01:38:07,460
 you can see the validator key and the error I'm talking about essentially happens with the first

1028
01:38:07,460 --> 01:38:16,520
 one, the missed block that shouldn't have been missed. And if I was to do kurtosis service logs,

1029
01:38:16,880 --> 01:38:23,579
 then I specify my enclave name. And then I specify the instance I want to get logs from. So

1030
01:38:23,579 --> 01:38:29,699
 please use autofill, it works really nicely. And then I want to follow the logs. And this

1031
01:38:29,699 --> 01:38:37,220
 is my logs from the third CL. And you can see there is some error, but that's about

1032
01:38:37,220 --> 01:38:42,819
 Validator fee recipient, nothing else. Otherwise it looks quite okay. And it just built a block

1033
01:38:42,819 --> 01:38:49,779
 on slot 12. So if I wait a second, slot 12 was built by three. So that whole system works.

1034
01:38:49,779 --> 01:39:01,019
 and for example if I do snopper beacon 3 this is the snopper for beacon 3 and you

1035
01:39:01,019 --> 01:39:06,399
 can see all the request responses that are coming through on that on that

1036
01:39:06,399 --> 01:39:13,119
 interface and then what else is interesting well yeah just look at

1037
01:39:13,119 --> 01:39:30,279
 service logs and if you ever need to know what's going on I forgot the enclave

1038
01:39:30,279 --> 01:39:34,659
 inspect command but you can inspect what is running in a running

1039
01:39:34,659 --> 01:39:41,000
 enclave as well. Great yeah it's really great so you basically like

1040
01:39:41,000 --> 01:39:45,159
 Instead of the Docker tooling, you have this kurtosis wrapper, which gives you all the

1041
01:39:45,159 --> 01:39:49,560
 options, and it's crafted for this, it works really nicely.

1042
01:39:49,560 --> 01:39:51,420
 Yeah, amazing.

1043
01:39:51,420 --> 01:39:57,500
 I think it's a few minutes over, and I don't really want to hold you up longer, but huge

1044
01:39:57,500 --> 01:40:01,800
 thanks for going the extra mile, for giving us the demo.

1045
01:40:01,800 --> 01:40:03,020
 We really appreciate it.

1046
01:40:03,020 --> 01:40:08,520
 I personally love all the DevOps tools, it's really fun how you go further, and we see

1047
01:40:08,520 --> 01:40:11,120
 others will adjacent sniffer.

1048
01:40:11,120 --> 01:40:12,760
 There is also snatched through.

1049
01:40:12,760 --> 01:40:14,760
 There is always something

1050
01:40:14,760 --> 01:40:16,480
 we are working on it, but it's around.

1051
01:40:16,480 --> 01:40:17,820
 So yes.

1052
01:40:17,820 --> 01:40:20,120
 So yes, it is much for all of your work, Pari,

1053
01:40:20,120 --> 01:40:22,620
 and especially for this presentation it was it was

1054
01:40:23,220 --> 01:40:25,780
 it was a great learning experience.

1055
01:40:25,780 --> 01:40:28,120
 Yeah, people are trying to the court houses.

1056
01:40:28,120 --> 01:40:30,280
 They are asking some questions in the discord.

1057
01:40:30,760 --> 01:40:33,580
 If you join the discord, you can you can maybe go there

1058
01:40:33,780 --> 01:40:36,120
 if you have a minute, but it's still up to you.

1059
01:40:36,120 --> 01:40:37,980
 I will show you the link later.

1060
01:40:37,979 --> 01:40:41,099
 But to all of you folks who've been paying attention, thank you so much.

1061
01:40:41,099 --> 01:40:43,099
 I hope you hope you learned something.

1062
01:40:43,319 --> 01:40:45,899
 And if you have some extra questions for Pari

1063
01:40:46,559 --> 01:40:50,559
 or if you're trying these things, please share your results with us.

1064
01:40:50,859 --> 01:40:54,179
 We're very thankful that you gave like very good specific examples

1065
01:40:54,179 --> 01:40:58,519
 of what people can practice, what they can try afterwards.

1066
01:40:58,779 --> 01:41:00,939
 That's it's very helpful.

1067
01:41:00,939 --> 01:41:05,599
 And yeah, and I'll see you folks on Wednesday for a talk by Piper Marianne.

1068
01:41:05,600 --> 01:41:08,079
 and we can wrap it up here.

1069
01:41:08,260 --> 01:41:08,400
 Yeah.

1070
01:41:08,760 --> 01:41:09,960
 Thank you very much, Pari, again.

1071
01:41:10,120 --> 01:41:10,720
 Appreciate it.

1072
01:41:10,940 --> 01:41:11,380
 You're welcome.

1073
01:41:11,620 --> 01:41:12,380
 See you guys.

1074
01:41:13,700 --> 01:41:14,240
 Bye-bye.

1075
01:41:14,720 --> 01:41:15,020
 Bye.

