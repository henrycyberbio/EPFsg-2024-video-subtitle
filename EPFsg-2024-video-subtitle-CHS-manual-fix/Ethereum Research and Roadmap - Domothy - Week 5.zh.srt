1
00:00:30,000 --> 00:00:59,980
¶¶

2
00:01:30,000 --> 00:01:59,000
¶¶

3
00:02:00,000 --> 00:02:10,000
¶¶

4
00:02:10,000 --> 00:02:39,000
¶¶

5
00:02:40,000 --> 00:03:09,979
¶¶

6
00:03:10,000 --> 00:03:39,979
¶¶

7
00:03:40,000 --> 00:04:09,979
¶¶

8
00:04:10,000 --> 00:04:39,980
¶¶

9
00:04:40,000 --> 00:05:09,980
¶¶

10
00:05:10,000 --> 00:05:17,819
好的，欢迎来到以太坊协议研究小组的第五周

11
00:05:18,639 --> 00:05:20,139
感谢你加入我们

12
00:05:20,899 --> 00:05:27,879
今天，Dom 将在这里介绍以太坊路线图

13
00:05:27,879 --> 00:05:32,240
和目前正在进行的一些研究途径

14
00:05:33,639 --> 00:05:36,920
Mario，我们现在能听到你的声音吗？

15
00:05:37,079 --> 00:05:39,199
是的，当然。嘿，大家，你能听到我的声音吗？

16
00:05:39,420 --> 00:05:39,639
好的，可以

17
00:05:40,000 --> 00:06:10,000
是的。Josh谢谢你的开场，关于我们协议的未来，在过去的三、四周里我们一起学习和享受了不同协议的不同部分，同时协议也出现了

18
00:06:10,000 --> 00:06:14,160
新的改进和功能以及我们需要弄清楚的许多有趣的研究

19
00:06:14,160 --> 00:06:15,620
在我们谈到那些之前

20
00:06:15,620 --> 00:06:20,019
因此，我非常感谢今天有Dom在这里告诉我们所有有关这些的信息

21
00:06:20,019 --> 00:06:21,339
是的，舞台是你的

22
00:06:21,339 --> 00:06:22,339
好的

23
00:06:22,339 --> 00:06:23,339
谢谢

24
00:06:23,339 --> 00:06:24,339


25
00:06:24,339 --> 00:06:26,339
因此，你会看到第一个幻灯片

26
00:06:26,339 --> 00:06:28,740


27
00:06:28,740 --> 00:06:30,459
嗨，大家好

28
00:06:30,459 --> 00:06:35,959
我的合法姓氏是domothy，我喜欢将自己描述为

29
00:06:35,959 --> 00:06:39,660
以太坊基金会 Research R&D

30
00:06:39,660 --> 00:06:46,340
所以今天我要带你浏览整个路线图，所以你从这整张图可以

31
00:06:46,340 --> 00:06:52,360
看到Vitalik他每年的更新

32
00:06:52,360 --> 00:06:58,660
乍一看这有点混乱，所以我希望通过这些不同的-u/erge（版本名的尾缀）

33
00:06:58,660 --> 00:07:04,360
能让你对这些产生一定的理解，因此，向Vitalik致敬，对我来说，这张图基本上是

34
00:07:04,360 --> 00:07:05,819
免费为我概述了整个需要演讲的内容

35
00:07:05,819 --> 00:07:08,420
因为我只需要从左至右

36
00:07:08,420 --> 00:07:10,860
从上到下地列个表

37
00:07:12,840 --> 00:07:15,160
是的，从外部的角度来看

38
00:07:15,160 --> 00:07:16,379
乍一看，这有点混乱

39
00:07:16,379 --> 00:07:20,680
所以我真的认为

40
00:07:20,680 --> 00:07:22,040
如果我的工作做的足够好

41
00:07:22,040 --> 00:07:24,120
你们就可以从这个演讲中获得一些收获

42
00:07:24,120 --> 00:07:26,180
然后会发现这实际上是一个非常漂亮的路线图

43
00:07:26,180 --> 00:07:28,480
它所有的碎片合并在一起

44
00:07:28,480 --> 00:07:31,439
形成一个美丽的区块链

45
00:07:31,439 --> 00:07:40,000
是的，我对这些-urge(版本名的尾缀)都有一个TLDR（总结，直译：太长不看），所以我想一个一个来

46
00:07:40,000 --> 00:07:46,939
从The Merge开始，我们都知道这是以太坊历史上最重要的事件

47
00:07:46,939 --> 00:07:54,980
TLDR是更好的权益证明，你会发现我（从Vitalik那里）得到了所有幻灯片

48
00:07:54,980 --> 00:08:04,980
因此，信标链(Beacon Chain)的发布，从信标链到The Merge，我只是偷了执行层和信标链的图放在这

49
00:08:04,980 --> 00:08:15,980
在合并之前，我们有了所谓的空的信标链，只负责验证者的投票

50
00:08:15,980 --> 00:08:22,980
在整个演讲中...我的猫会很烦人。我提前说声抱歉

51
00:08:22,980 --> 00:08:29,060
嗯，所以信标链有将近一百万个活跃验证者，所以这有很高的经济安全性

52
00:08:29,060 --> 00:08:35,620
与权益证明

53
00:08:37,620 --> 00:08:42,899
和之前的工作证明相比，没有罚款

54
00:08:42,899 --> 00:08:48,420
这样就相当于白花哈希率，你不会得到奖励，而现在你两者都得到了

55
00:08:48,419 --> 00:08:55,139
一是奖励，如果你作恶或做其他类似的事，你也会受到处罚

56
00:08:55,139 --> 00:09:00,959
这不是在信标链规范中指定的

57
00:09:00,959 --> 00:09:04,559
这是一千一百亿美元的经济安全

58
00:09:05,579 --> 00:09:10,659
接下来我要谈到同步委员会(Sync Committees)

59
00:09:10,659 --> 00:09:16,620
协议非常快，它基本上具有一百万个有效的

60
00:09:16,620 --> 00:09:25,799
签名以验证每个时期(epoch)，我认为每个时隙有512个(验证者)

61
00:09:27,200 --> 00:09:33,039
对于不想验证所有内容的客户来说，这非常沉重，所以我们有这个

62
00:09:33,039 --> 00:09:41,100
轮换的512个验证者，他们在链的header(的证明中)有额外的权重

63
00:09:41,100 --> 00:09:46,800
这就是客户基本上信任那个东西，它不是以一种无信任的方式

64
00:09:46,800 --> 00:09:53,940
作为验证每个签名的验证，但是如果你想让一个轻客户端知道规范链中的块是什么块

65
00:09:53,940 --> 00:10:02,040
这也是非常好的，所以，你可以看到此链接

66
00:10:02,040 --> 00:10:09,040
我在github上的注释中添加了有关A16Z的Helios客户端的注释

67
00:10:09,039 --> 00:10:14,259
非常简洁地介绍了类似的客户端协议，它们实际上构建了

68
00:10:14,259 --> 00:10:19,860
使用它的客户端，是的，这只是希望你能对

69
00:10:19,860 --> 00:10:22,419
委员会以及客户端协议留有印象

70
00:10:22,419 --> 00:10:26,199
稍后再谈它们

71
00:10:27,639 --> 00:10:33,179
将来的另一个项目是秘密领袖选举(secret leader election)，它将增强

72
00:10:33,179 --> 00:10:38,179
基本上，这个领袖就是

73
00:10:38,579 --> 00:10:42,479
在那个Slot上负责提议一个区块的验证者

74
00:10:42,479 --> 00:10:45,839
这是现在信标链中的一个已知缺陷

75
00:10:45,839 --> 00:10:48,679
这位领袖（可以被攻击者）提前知道

76
00:10:50,859 --> 00:10:54,219
理论上，攻击者，那些

77
00:10:54,219 --> 00:10:56,819
大型池或恶意验证者

78
00:10:56,819 --> 00:10:59,959
可以将 IP 与特定验证者关联起来

79
00:10:59,959 --> 00:11:02,399
然后对特定验证者发动DDoS攻击

80
00:11:02,399 --> 00:11:03,759

81
00:11:03,759 --> 00:11:07,199
使得他们无法正常提出区块

82
00:11:07,199 --> 00:11:11,199
然后所有的MEV将流入下一个块

83
00:11:11,199 --> 00:11:13,899
到目前为止，我们还没有发现这种攻击

84
00:11:13,899 --> 00:11:16,000
或其他类似的（攻击）

85
00:11:16,000 --> 00:11:18,600
所以敲木头不会发生（希望它会发生的意思）

86
00:11:18,600 --> 00:11:20,579
但是，如果（这个攻击）真的发生了

87
00:11:20,579 --> 00:11:23,100
我们要有这个事项

88
00:11:23,100 --> 00:11:25,059
并且提高它的优先级

89
00:11:25,059 --> 00:11:28,759
我们知道该协议称为Whisk

90
00:11:28,759 --> 00:11:32,000
基本上每个验证者都会添加一个随机位

91
00:11:32,000 --> 00:11:39,519
对此潜在验证者列表有自己的随机性

92
00:11:39,519 --> 00:11:44,879
简而言之，它们就像，没人知道下一个领袖是谁

93
00:11:44,879 --> 00:11:49,500
除了那个领袖本人，他们发现了他自己，就像他们发现了一个区块

94
00:11:49,500 --> 00:11:53,360
因此不可能提前攻击他们

95
00:11:53,360 --> 00:11:56,980
因为你不知道你要攻击谁

96
00:11:56,980 --> 00:12:06,220
（路线图）中间有一条小线，这就代表现在

97
00:12:06,220 --> 00:12:09,740
线左侧的都是已经完成的

98
00:12:09,740 --> 00:12:12,560
右边的基本上都是正在进行中的

99
00:12:12,560 --> 00:12:17,560
因此，秘密领袖选举完成了一半，因为我们知道该怎么做

100
00:12:17,560 --> 00:12:21,800
但并不急迫地去完成它，因为它并不是高优先级事项

101
00:12:21,799 --> 00:12:24,019
然后，就像我说的那样，我们知道要实施什么

102
00:12:24,019 --> 00:12:27,819
除非我们开始看到实际的严重攻击

103
00:12:30,779 --> 00:12:33,399
然后，我不确定第三周

104
00:12:33,399 --> 00:12:36,599
在共识层（讲座）上，是否谈论了最终确认

105
00:12:36,599 --> 00:12:40,519
但基本上，这是个区块链中的新概念

106
00:12:40,519 --> 00:12:45,519
合并后，在12.6分钟或两个Epoch之后

107
00:12:46,240 --> 00:12:48,439
你会有这个称为最终确认的区块

108
00:12:49,319 --> 00:12:50,799
它是什么，绿色，蓝色，粉红色？

109
00:12:50,799 --> 00:12:52,799
我认为你必须问Vitalik

110
00:12:52,799 --> 00:12:56,759
我认为蓝色是大型事项

111
00:12:56,759 --> 00:12:59,539
绿色就像普通事项一样

112
00:12:59,539 --> 00:13:04,279
但是，就像这三个事项，SSF是大型的

113
00:13:04,279 --> 00:13:06,620
然后粉红色就像

114
00:13:06,620 --> 00:13:10,939
我认为这完全是用于量子的东西

115
00:13:10,939 --> 00:13:13,919
是的，就像未来（要做的）一样

116
00:13:17,279 --> 00:13:18,819
是的，关于最终确认

117
00:13:18,820 --> 00:13:21,200
12.6分钟后，区块被最终确认

118
00:13:21,200 --> 00:13:24,200
然后，如果你想从区块链中踢出该区块

119
00:13:24,200 --> 00:13:25,800
那需要花很多钱

120
00:13:25,800 --> 00:13:29,640
最低限度是必须立即花费

121
00:13:29,640 --> 00:13:31,740
质押总量的三分之一

122
00:13:31,740 --> 00:13:34,160
然后，这将是非常容易被发现的事情

123
00:13:34,160 --> 00:13:38,860
所以这是我们想增强的东西

124
00:13:38,860 --> 00:13:42,080
并让每个Slot都被最终确认

125
00:13:42,080 --> 00:13:46,680
每12秒，如果我们增加了Slot时间

126
00:13:46,679 --> 00:13:51,079
也可能超过12秒

127
00:13:55,239 --> 00:13:57,919
我不认为同步委员会被削减

128
00:13:57,919 --> 00:14:01,299
但是他们有较多的奖励

129
00:14:01,299 --> 00:14:04,239
我不确定处罚的部分，这是一个很好的问题

130
00:14:09,899 --> 00:14:12,059
好吧，是的，有一个

131
00:14:12,059 --> 00:14:14,620
SSF是一个活跃的研究领域

132
00:14:14,620 --> 00:14:16,779
还有几种实现的方法

133
00:14:16,779 --> 00:14:19,899
大部分都与签名数量有关

134
00:14:19,899 --> 00:14:23,000
我们必须在信标链上进行处理

135
00:14:23,000 --> 00:14:26,220
所以现在有一百万个活跃验证者

136
00:14:26,220 --> 00:14:29,879
这太重了，无法在一个Slot中处理

137
00:14:29,879 --> 00:14:34,220
因此，我们要做的是更少的验证者

138
00:14:34,220 --> 00:14:38,019
与Max Ebit一样，我稍后再过来

139
00:14:38,019 --> 00:14:39,080
或者我们可以

140
00:14:39,080 --> 00:14:51,700
或者，可以使用较少的主动验证者，例如轮换的方式，而不是

141
00:14:51,700 --> 00:14:56,100
一百万验证者同时都活跃起来，你只能有一小部分
142
00:14:56,100 --> 00:15:01,900
他们会定期进出睡眠状态，这意味着对最终确认的攻击成本将下降

143
00:15:01,900 --> 00:15:08,200
但是，你仍然至少需要大部分的质押权益，即使不是超级大部分

144
00:15:08,200 --> 00:15:16,759
但是如果涉及的主动验证者较少，实际的削减将会下降

145
00:15:16,759 --> 00:15:22,500
Vitalik有一个ETH研究文章，为此提供了一些解决方案

146
00:15:22,500 --> 00:15:28,600
其中一个是拥有大验证者，例如2^13个验证者，而不是一百万

147
00:15:28,600 --> 00:15:36,740
因此，它从一百万到8,192，然后通过某种分布式验证者

148
00:15:36,740 --> 00:15:41,259
这项技术旨在维护验证过程无需许可的目标

149
00:15:42,440 --> 00:15:44,639
好吧，让我先离开一下

150
00:15:47,039 --> 00:15:48,240
不给它说话！

151
00:15:50,960 --> 00:15:53,139
yeah，签名聚合方案是另一个

152
00:15:53,139 --> 00:15:55,799
我基本上过分简化了它

153
00:15:55,799 --> 00:15:57,899
为了时间和简单

154
00:15:58,879 --> 00:16:03,220
但是现在，我认为这是在下一个幻灯片中，是的

155
00:16:03,220 --> 00:16:07,259
在左侧，你拥有整个验证者的子网和字段

156
00:16:07,259 --> 00:16:09,800
假设它们被聚合在一起

157
00:16:09,800 --> 00:16:11,040
就成了一个单一的签名

158
00:16:11,040 --> 00:16:15,080
因此，而不是验证每个签名
159
00:16:15,080 --> 00:16:17,759
而是将它们折叠成一个签名

160
00:16:17,759 --> 00:16:21,360
这只是每个验证者签名的总和

161
00:16:22,399 --> 00:16:24,019
为此，你需要一些字段

162
00:16:24,019 --> 00:16:29,019
因此，如果受影响的验证者是否确实签名
163
00:16:30,500 --> 00:16:31,700
或证明区块

164
00:16:31,700 --> 00:16:37,940
因此，将来，这张幻灯片讲了两个方面

165
00:16:37,940 --> 00:16:44,900
第一部分是拥有这种防量子的信标链，因为我们今天使用的

166
00:16:44,900 --> 00:16:50,740
容易受到量子计算机的攻击，所有依赖椭圆曲线的一切加密方法

167
00:16:50,740 --> 00:16:55,240
即我们在信标链上使用的VLS签名

168
00:16:55,240 --> 00:17:01,020
如果我们获得可扩展的量子计算机，这些方法则必须消失

169
00:17:01,019 --> 00:17:10,859
否则可能会发生一系列问题。对了，维塔利克还有一篇关于 STARKs Aggregate 的文章

170
00:17:10,859 --> 00:17:17,740
对于那些不知道的人来说，STARKs Aggregate就像是一个简洁的零知识证明

171
00:17:18,619 --> 00:17:24,619
它完全依赖于哈希，而众所周知，量子计算机无法扰乱哈希

172
00:17:24,619 --> 00:17:27,919
因此，如果你只是将某人签名的证明聚合（Aggregate）在一起

173
00:17:27,919 --> 00:17:30,699
因此，如果你只是将某人签名的证明聚合在一起

174
00:17:30,699 --> 00:17:33,399
我们就能得到一个量子证明信标链

175
00:17:33,399 --> 00:17:36,899
同时也能得到一个组织性较差的证明信标链

176
00:17:36,899 --> 00:17:40,039
你可以看到右边有点混乱

177
00:17:40,039 --> 00:17:42,559
每个人、验证者在收到签名时

178
00:17:42,559 --> 00:17:45,079
都会将它们聚合在一起，直到我们走到最后

179
00:17:47,199 --> 00:17:51,579
然后我们获得了最终的聚合签名

180
00:17:51,579 --> 00:17:54,459
或者说是每个验证者都都用字段投了票的证明

181
00:17:54,460 --> 00:17:56,059
或者说是每个验证者都都用字段投了票的证明

182
00:17:56,059 --> 00:18:00,519
再说一遍，撇开量子的东西不说

183
00:18:00,519 --> 00:18:02,700
仅仅是聚合就很酷

184
00:18:03,900 --> 00:18:06,460
要让这些字段聚合在一起

185
00:18:06,460 --> 00:18:09,000
这是非常困难的问题

186
00:18:09,000 --> 00:18:11,440
因为你之前的证明

187
00:18:11,440 --> 00:18:13,200
已经有了验证者的签名

188
00:18:13,200 --> 00:18:14,799
然后你想把它们聚合在一起

189
00:18:16,600 --> 00:18:18,840
我想 The Merge 就到此为止了
190
00:18:18,840 --> 00:18:23,740
我很快就过完了所有条目

191
00:18:23,740 --> 00:18:26,359
如果有问题，我可以花一些时间讨论它们

192
00:18:26,620 --> 00:18:27,359
我给你们看我的猫

193
00:18:27,680 --> 00:18:29,400
它是所有噪音的来源

194
00:18:40,900 --> 00:18:42,079
纯色 Fungible 橘猫

195
00:18:42,660 --> 00:18:43,759
它非常纯色

196
00:18:46,160 --> 00:18:46,799
【没听清】

197
00:18:48,299 --> 00:18:49,599
它只是想被关注

198
00:18:49,599 --> 00:18:57,899
接下来，这是我认为更有趣的The Surge，因为

199
00:18:57,899 --> 00:18:59,859
因为

200
00:19:00,939 --> 00:19:07,419
是的，The Surge的Rollup会带来更多的数据可用性

201
00:19:07,419 --> 00:19:13,099
我将再次把它的含义非常简单化（的概述），因为这涉及到超多的多项式“魔法”
202
00:19:13,099 --> 00:19:23,099
因此，首先，从一万英尺的高空看Rollup，我们必须理解Rollup的含义，以及以太坊为什么要制定一个以Rollup为中心的路线图
203
00:19:23,099 --> 00:19:33,099
因此，基本上，以太坊的扩容(scaling)目标一直是某种形式的分片，而不是让每个验证者验证整条链

204
00:19:33,099 --> 00:19:42,099
而是我们会有像小型区块链一样的分片，每个验证者负责区块链的一个较小的子集
205
00:19:42,099 --> 00:19:53,219
但是事实证明，这不仅很难做到，而且一旦我们实现了，Rollup将也会变得更加成熟并准备好进行扩容（这时分片就没这么必要了）

206
00:19:53,859 --> 00:19:57,879
他们不会像我们希望的那样使用这些分片（因为Rollup可能找到了其他方法来确保数据的可用性）

207
00:19:58,000 --> 00:20:03,139
因此，就是说我们要做的，好吧，我们现在还不打算扩展执行层

208
00:20:03,179 --> 00:20:05,119
我们将只专注于数据

209
00:20:05,119 --> 00:20:12,899
然后，此数据将是可扩容的，并将其通过Rollup转移到Layer2的执行层

210
00:20:13,179 --> 00:20:30,559
真正很酷的事情是，这是诚实的多数假设，即至少有51％的验证者必须诚实地成为N的一个，其中只需要一个参与者即可确保Rollup诚实地参与

211
00:20:30,559 --> 00:20:33,799
所以有两个类型的Rollup

212
00:20:34,000 --> 00:20:35,359
Optimistic 乐观的Rollup和ZK 零知识（证明）的

213
00:20:35,839 --> 00:20:39,119
Optimistic Rollup

214
00:20:39,119 --> 00:20:40,319
它很容易理解

215
00:20:40,460 --> 00:20:44,079
基本上，每笔交易都被传输到L1

216
00:20:44,079 --> 00:20:45,919
它们都被认为是有效的

217
00:20:45,919 --> 00:20:48,159
不被一一检查

218
00:20:48,279 --> 00:20:50,659
所以他们只是乐观地假设

219
00:20:50,659 --> 00:20:52,379
交易是有效的

220
00:20:52,579 --> 00:20:53,879
但是，如果它们不有效

221
00:20:53,960 --> 00:20:56,000
然后有人可以拿走数据并说

222
00:20:56,059 --> 00:20:58,259
嘿，Sequencer 排序器是邪恶的

223
00:20:58,259 --> 00:21:00,419
然后他试图将自己打印出一堆数据

224
00:21:00,420 --> 00:21:05,420
或在没有私钥的情况下窃取资金

225
00:21:05,600 --> 00:21:08,620
因此，L1有某种欺诈证据

226
00:21:08,620 --> 00:21:10,180
可以纠正这一点

227
00:21:10,279 --> 00:21:12,800
但是只有在存在分歧时（才会这样做）

228
00:21:12,800 --> 00:21:16,680
所以这就像拥有法律制度

229
00:21:16,680 --> 00:21:21,360
在这种情况下，合同由法院强制执行

230
00:21:21,539 --> 00:21:23,640
但实际上

231
00:21:23,640 --> 00:21:25,580
仅仅是能够强制执行合同的威胁

232
00:21:25,580 --> 00:21:28,960
就足以让每个人诚实地参与进来

233
00:21:28,960 --> 00:21:32,920
因为否则每一份合同都要诉诸法院

234
00:21:32,920 --> 00:21:35,299
社会的规模就不会那么大

235
00:21:35,480 --> 00:21:39,039
so，这就是让我一开始就觉得不错的类比

236
00:21:40,299 --> 00:21:44,740
零知识的Rollup涉及更多密码学知识

237
00:21:44,740 --> 00:21:47,460
在这里，你需要

238
00:21:47,460 --> 00:21:51,100
将L2的执行层信息压缩为一个简洁的证明

239
00:21:51,100 --> 00:21:53,900
并使得在L1可以验证它

240
00:21:53,900 --> 00:22:05,800
在这两种情况下你都需要有足够的数据可用性

241
00:22:05,800 --> 00:22:10,600
例如在Optimistic Rollup上，你需要能够拥有数据才能挑战某人

242
00:22:10,600 --> 00:22:17,440
即证明他是恶意的，对于两种情况，你也希望能够强制包含交易

243
00:22:17,440 --> 00:22:22,300
例如你有资金在Rollup中，该Rollup的排序器想审查你

244
00:22:22,299 --> 00:22:24,799
然后，你可以通过第一层合约

245
00:22:24,799 --> 00:22:27,799
并强迫你的资金回到第一层

246
00:22:27,799 --> 00:22:29,399
或去到其他Rollup

247
00:22:29,399 --> 00:22:34,399
是的，这就是关于Rollup的概述

248
00:22:36,259 --> 00:22:38,759
我看到了一个关于将L1数据传输

249
00:22:38,759 --> 00:22:40,019
至L2执行层的问题

250
00:22:40,019 --> 00:22:45,019
那就像是一件手波浪的东西

251
00:22:45,659 --> 00:22:48,899
L1提供有关这些blob空间的数据

252
00:22:48,899 --> 00:22:51,440
我要在下一张幻灯片中浏览

253
00:22:51,440 --> 00:22:53,000
Rollup的作用

254
00:22:53,000 --> 00:22:55,480
只是将所有的执行从链上移开

255
00:22:55,480 --> 00:23:00,620
这些执行在第一层很快就能得到验证

256
00:23:00,620 --> 00:23:05,980
但验证只依赖于数据，而不是实际执行

257
00:23:05,980 --> 00:23:09,019
所以，嗯，我不确定如何解释

258
00:23:09,019 --> 00:23:13,259
就像，呃，它其实比这个更简单，但因为你必须拥有关于

259
00:23:13,259 --> 00:23:19,519
对数据和执行以及一层网络、二层网络的心智模型（才好理解）
260
00:23:19,519 --> 00:23:21,799
但所谓Rollup（卷叠），其实就是卷叠了约10,000个Gas

261
00:23:21,799 --> 00:23:25,059
所以我不是，也没有严重过度简化很多东西

262
00:23:25,400 --> 00:23:26,619
在整个演讲中

263
00:23:28,039 --> 00:23:29,119
嗯，是的

264
00:23:29,180 --> 00:23:29,379
好的

265
00:23:29,379 --> 00:23:31,400
我有关于Rollup的训练轮模型（从中心化到去中心化的过度）的幻灯片

266
00:23:31,400 --> 00:23:37,099
因此，我们必须预先说明

267
00:23:37,099 --> 00:23:42,920
就像你在l2beat.com上看到的那样，今天的Rollup中仍然存在很多风险

268
00:23:42,980 --> 00:23:48,500
我们希望卷积是稳定的、成熟的、

269
00:23:48,500 --> 00:23:51,039
无需许可的、

270
00:23:51,240 --> 00:23:53,380
没有MultiSig和有限的治理

271
00:23:55,599 --> 00:23:58,440
对于Rollup来说，权衡空间很大

272
00:23:58,660 --> 00:24:03,319
End Game是它能像第1层一样去信任化

273
00:24:03,460 --> 00:24:05,140
但是今天还不到了

274
00:24:05,299 --> 00:24:07,420
但这就是我们的目标

275
00:24:10,319 --> 00:24:12,759
好吧，所以在我们聊EIP-4844之前

276
00:24:12,759 --> 00:24:14,900
这是上周的大事

277
00:24:14,900 --> 00:24:22,000
我需要快速解释什么是数据可用性采样，你将不得不忍耐一下

278
00:24:22,000 --> 00:24:30,920
因为这是一个非常酷的概念。它非常涵盖大量数学知识，但是如果你付出一些努力了解我在说什么

279
00:24:30,920 --> 00:24:33,900
我相信这是值得的

280
00:24:34,860 --> 00:24:40,680
因此，数据可用性采样的全部内容是为了回答一个问题，数据可用吗？

281
00:24:40,680 --> 00:24:47,660
还记得吗，如果使用OP Rollup，需要拥有数据以抵抗审查

282
00:24:47,660 --> 00:24:52,299
以及恶意排序器制造的坏事

283
00:24:52,299 --> 00:24:56,900
如果我们知道数据可用，那么我们就知道Rollup是安全的

284
00:24:56,900 --> 00:24:59,060
有人可以挑战排序器

285
00:24:59,060 --> 00:25:03,539
最直接（天真 naive）的方法是下载所有数据，因为不言自明的，如果你能够下载

286
00:25:03,539 --> 00:25:10,100
所有数据，就意味着它可用

287
00:25:10,099 --> 00:25:11,659
但这不是很好

288
00:25:11,659 --> 00:25:14,079
我们希望在一层链上获得更多数据

289
00:25:14,079 --> 00:25:21,079
因此，我们要做的就是获取这些数据，使其成为多项式方程

290
00:25:21,079 --> 00:25:27,219
通过在更多点上评估该方程来扩展它，然后使用所谓的

291
00:25:27,219 --> 00:25:30,079
多项式承诺方案，在下一个幻灯片

292
00:25:30,079 --> 00:25:32,079
从那里（右侧幻灯片），你可以随机抽样

293
00:25:32,079 --> 00:25:37,939
因此，不用担心，我将一步一步（带你）过这里所有的步骤

294
00:25:37,940 --> 00:25:42,740
（这个方案的）想法是，假设你知道两点可以画一条直线、三个点可以画一个抛物线

295
00:25:42,740 --> 00:25:50,740
而根据4096个点可以重建一个4095次（degree，指最高次项的指数）的大多项式

296
00:25:51,779 --> 00:25:56,740
我有一个非常简单的示例，例如数据是(1, 3, 2, 2) （译注：假设自变量是x，因变量是y，此处指的是当x=1,2,3,4时，y=1,3,2,2）

297
00:25:57,299 --> 00:26:03,140
可以构建一个三次方程，然后你可以再扩展四个点再进行求值 （译注：当x=5,6,7,8时，y=7,21,28,92，这就是所谓扩展，扩展值域）

298
00:26:03,140 --> 00:26:05,640
例如(7, 21, 48, 92)

299
00:26:06,500 --> 00:26:09,759
现在你有这八个点

300
00:26:09,759 --> 00:26:11,740
而且你知道用其中的任意四个点

301
00:26:11,740 --> 00:26:14,040
可以重建一个相同的多项式

302
00:26:14,040 --> 00:26:15,700
然后你可以重新求值

303
00:26:15,700 --> 00:26:18,900
并可以算出(1, 3, 2, 2)
304
00:26:18,900 --> 00:26:21,380
这（给我们的）第一个见解是

305
00:26:21,380 --> 00:26:24,600
50％的扩展数据就足够

306
00:26:24,600 --> 00:26:26,259
恢复100％的数据

307
00:26:26,259 --> 00:26:28,160
所以这是要牢记的事情之一

308
00:26:28,160 --> 00:26:32,140
在下一个幻灯片，我们将深入研究

309
00:26:32,140 --> 00:26:34,420
其他大多项式承诺的技术

310
00:26:34,420 --> 00:26:39,420
因此，这里的所有研究都基于多项式

311
00:26:40,259 --> 00:26:41,800
这里到处都是这种魔法

312
00:26:41,800 --> 00:26:45,020
yes，它（他的猫猫）现在一直在相机上穿来穿去

313
00:26:46,920 --> 00:26:49,520
是的，所以我要继续用同样的三次方程（举例）

314
00:26:49,520 --> 00:26:53,780
基本上，你又得再次忍受我的

315
00:26:53,780 --> 00:26:57,280
黑匣子函数了

316
00:26:57,280 --> 00:26:59,460
有点像一个哈希

317
00:26:59,460 --> 00:27:02,340
但是有了更高级的属性

318
00:27:02,340 --> 00:27:05,380
但这需要所有这些大多项式

319
00:27:05,380 --> 00:27:06,799
具有成千上万的系数

320
00:27:06,799 --> 00:27:10,360
然后它将其压缩到一个字节中

321
00:27:10,360 --> 00:27:13,000
是的，就像一个著名的哈希一样

322
00:27:13,000 --> 00:27:14,940
所有节点都知道这一承诺

323
00:27:14,940 --> 00:27:18,220
这就是他们将用来验证证明的方法

324
00:27:18,220 --> 00:27:19,660
我们称之为开证明 opening proofs

325
00:27:22,240 --> 00:27:26,160
是的，一个重点

326
00:27:26,160 --> 00:27:28,920
你的节点可以在那随机请求数据点

327
00:27:28,920 --> 00:27:32,360
因此，你在1到8之间选择，在我的示例中，只选择3

328
00:27:32,500 --> 00:27:36,860
然后你询问声称具有数据的网络或验证者

329
00:27:37,480 --> 00:27:39,560
你说，给我数据点3的值

330
00:27:39,640 --> 00:27:41,460
然后你收到值2

331
00:27:42,600 --> 00:27:46,600
因此，你接收到的验证者

332
00:27:46,600 --> 00:27:51,259
声称多项式P在数据点3处求值等于2

333
00:27:52,100 --> 00:27:54,759
但不仅如此，他还给你一个证明pi

334
00:27:54,759 --> 00:27:58,980
这就是你用来验证承诺的方法

335
00:27:58,980 --> 00:28:05,140
P要满足在3上实际等于2

336
00:28:05,220 --> 00:28:07,299
因此，你无需对整个承诺求值

337
00:28:08,019 --> 00:28:08,839
对整个多项式求值

338
00:28:09,059 --> 00:28:11,460
因为这是数千个系数

339
00:28:12,160 --> 00:28:13,339
它需要太多时间

340
00:28:13,440 --> 00:28:15,460
因此，你只需基于这些证据

341
00:28:17,180 --> 00:28:18,980
并记住前一个幻灯片

342
00:28:19,099 --> 00:28:22,960
50％的数据足以恢复100％的数据

343
00:28:22,960 --> 00:28:36,960
所以这有点像一个小游戏，你想我是一个恶意验证者，我想要说服你发布所有数据，然后你要求我提供一些随机点以供预测

344
00:28:37,579 --> 00:28:44,340
而且，如果我能为你提供数据和证明，这意味着至少此次抽样是（数据）可用的

345
00:28:45,600 --> 00:28:51,960
而且，如果我只发布1％的（数据），那还不够，对吗？

346
00:28:51,960 --> 00:28:57,920
你要求的样本恰好就在其中的概率是1%，即有1%的概率我证明了

347
00:28:57,920 --> 00:29:04,440
我确实发布了（所有数据）。因此，如果我想最大限度地欺骗你，以为数据是可用的

348
00:29:04,440 --> 00:29:10,559
但实际上不是，是的，我将不得不发布大约49.9％的数据

349
00:29:10,559 --> 00:29:18,279
以便你无法重建整个数据。因此，你可以在最坏的情况下思考

350
00:29:18,279 --> 00:29:23,000
你的样本有二分之一的机会

351
00:29:23,180 --> 00:29:25,940
碰巧就在那一半

352
00:29:25,940 --> 00:29:27,559
我确实发布了的数据中

353
00:29:28,279 --> 00:29:31,799
因此，这还不足以满足

354
00:29:32,039 --> 00:29:34,019
因此，你只需要要求另一个随机数据点

355
00:29:34,019 --> 00:29:35,019
我无法预测（是哪个数据点）

356
00:29:35,099 --> 00:29:37,539
然后，如果恰好在我确实发布了的

357
00:29:37,539 --> 00:29:38,420
那一半

358
00:29:38,619 --> 00:29:41,819
然后，这两次抽样的复合（联合概率）是25％

359
00:29:41,819 --> 00:29:45,319
然后，你要求另一次抽样（使得这个概率）变为12.5％

360
00:29:45,319 --> 00:29:47,660
只需30次抽样

361
00:29:47,660 --> 00:29:53,900
你会看到有数十亿分之一的机会会被愚弄，所以在某些层面上

362
00:29:53,900 --> 00:29:59,900
这不是不可能发生的，所以只说，好吧，我满足于我没有下载所有数据

363
00:29:59,900 --> 00:30:04,300
我只做了30次抽样的整个数据，就足以说服我

364
00:30:04,300 --> 00:30:09,420
数据是可用的，因此这基本上是数据采样的症结

365
00:30:09,420 --> 00:30:12,259
我们将用来扩展此数据可用性

366
00:30:18,100 --> 00:30:23,279
重要的是要知道的事情是，此证明非常简短

367
00:30:23,279 --> 00:30:25,960
与数千个系数相比

368
00:30:27,039 --> 00:30:31,039
就所需的计算能力而言，验证它也很短

369
00:30:31,980 --> 00:30:37,560
并且那30次抽样，它们独立于实际上有多少数据

370
00:30:37,559 --> 00:30:44,099
因此，即使仅是一兆字节或一千个trabytes，这30个样本也可以为你提供十亿个机会

371
00:30:44,200 --> 00:30:46,899
所以这是一个常数

372
00:30:48,659 --> 00:30:54,500
就像是一件神奇的事情，只有30个样本就足够了，无论实际上有多少数据

373
00:30:56,359 --> 00:30:56,559


374
00:30:57,839 --> 00:31:06,980
 是的，节点能够回答这个问题，即只需做一些抽样检查就能获得数据

375
00:31:07,559 --> 00:31:11,000
而无需下载所有数据

376
00:31:12,599 --> 00:31:15,879
这是我们目前在区块链中采用的非常简单的方法

377
00:31:19,319 --> 00:31:26,039
因此，我们可以回到EIP-4844，它最近在主网上被激活

378
00:31:26,039 --> 00:31:33,559
这是件大事，它为刚才我谈到的大规模采样奠定了基础

379
00:31:33,559 --> 00:31:39,559
但现在还没有大规模采样，我们仍然处于那种非炫酷状态，我们需要证明 meme 和上面的情况

380
00:31:39,559 --> 00:31:45,079
我们依赖于每个节点下载它构建的每一个 blob

381
00:31:45,079 --> 00:31:50,039
我们已经在用承诺schema做多项式魔法了
382
00:31:50,039 --> 00:31:58,119
我们依靠KZG，对于那些想要深入研究它的人来说

383
00:31:58,119 --> 00:32:03,159
如果你愿意忽略配对并只接受它们的表面值

384
00:32:03,559 --> 00:32:07,059
这是一个相对简单的加密构造

385
00:32:07,059 --> 00:32:11,019
但是，是的，既然我们正在下载所有内容

386
00:32:11,019 --> 00:32:14,559
我们必须在带宽和存储方面保持保守

387
00:32:14,559 --> 00:32:17,259
 因此，我们开始时每个区块有三个Blob

388
00:32:17,259 --> 00:32:19,259
最多六个

389
00:32:19,259 --> 00:32:23,019
而且价格像EIP-1559那样

390
00:32:23,019 --> 00:32:25,119
如果你在一个区块中有三个以上

391
00:32:25,119 --> 00:32:27,759
那么下一个块将更加昂贵

392
00:32:27,759 --> 00:32:30,159
直到平均为三个

393
00:32:30,160 --> 00:32:34,680
目前，我们基本上每块平均要做一个Blob

394
00:32:35,440 --> 00:32:40,080
在昨晚的截图上看（平均每个块是）1.16个，但变异性（波动）很大

395
00:32:40,660 --> 00:32:46,400
因此，Blob大约在1 wei，价格很便宜

396
00:32:46,519 --> 00:32:49,640
所以那是10的负18次方

397
00:32:49,779 --> 00:32:55,220
我认为这是ETH的八十亿分之一，或者是Gway的十亿分之一

398
00:32:55,220 --> 00:32:59,420
因此，现在在链上发布数据非常便宜

399
00:32:59,420 --> 00:33:23,200
我从Etherscan截到这张图，我认为是Arbitrum的，单个交易中发布了六个Blob，它们花了786,000 wei，每个Blob的.000131 wei，这基本上等于没花

400
00:33:23,200 --> 00:33:28,740
哦，是的，我们要去量子

401
00:33:28,740 --> 00:33:39,640
Blob费用也燃烧了吗？是的，就像基本费用，Blob费用也用来管理阻塞

402
00:33:39,640 --> 00:33:44,600
所以它也被烧毁了，你可以去ultrasound.money查看

403
00:33:44,600 --> 00:33:50,519
有一个小组件，我认为现在我们大约5Gwei被Rollup烧毁了

404
00:33:50,519 --> 00:33:56,839
大量数据，所以我们仍然很拥挤，这很酷，我们在L2几乎可以免费的执行交易

405
00:33:56,839 --> 00:34:07,480
之后，和之前一样，我们在很远的未来有关于量子的东西

406
00:34:07,480 --> 00:34:15,239
因为，我们现在拥有KZG几乎是完美的

407
00:34:15,239 --> 00:34:20,759
虽然它不是量子安全的，并且需要一个可信的设置，但我们已经有了

408
00:34:20,759 --> 00:34:28,439
超过14万名贡献者参与了这个过程。这意味着我们假设

409
00:34:28,439 --> 00:34:35,879
至少有一名参与者是诚实的，从而生成了一个随机的秘密

410
00:34:35,879 --> 00:34:42,839
如果这个秘密被妥善销毁，那么未来就不会出现虚假证明

411
00:34:42,840 --> 00:34:49,320
因此，只要有一名贡献者是诚实的，这个过程就是安全的

412
00:34:49,320 --> 00:34:55,880
说实话。因此，它被称为可信赖的设置

413
00:34:55,880 --> 00:35:01,240
尽管如此，它并不依赖于信任，因为有140,000个贡献者

414
00:35:05,400 --> 00:35:10,840
将来，我们希望用基于 STARK 或 Lattices 技术的方案替代 KZG

415
00:35:10,840 --> 00:35:17,480
这是另一种复杂的加密技术，量子计算机无法破解

416
00:35:17,480 --> 00:35:26,680
这可能会在未来的某个时间点实现，具体取决于我们的研究进展

417
00:35:27,240 --> 00:35:33,480
我们需要深入研究以确定最佳的实现路径

418
00:35:35,079 --> 00:35:40,200
因此，我们知道流动性碎片化是一个重要问题

419
00:35:40,199 --> 00:35:45,000
通过Rollup技术，我们希望实现更加无缝的用户体验

420
00:35:45,000 --> 00:35:46,179
并将所有复杂性抽象化

421
00:35:46,179 --> 00:35:49,199
因此，你可以研究很多内容

422
00:35:49,199 --> 00:35:51,859
比如基于Rollup的技术和预确认机制

423
00:35:51,859 --> 00:35:53,339
以及共享排序器

424
00:35:53,339 --> 00:35:56,139
我认为其中一些内容会在其他主题中再次提到

425
00:35:58,659 --> 00:36:01,279
我喝口水的同时会查看一下提问

426
00:36:05,799 --> 00:36:09,139
在共识层（CL）或执行层（EL）上，这些内容都在哪里体现？

427
00:36:09,139 --> 00:36:15,379
共识层接收Blob并验证其可用性

428
00:36:15,859 --> 00:36:19,719
所以在共识层这个只需返回布尔值的层面上实现了这个功能

429
00:36:19,719 --> 00:36:27,019
也就是数据是否可用，而且共识层的验证者们

430
00:36:27,199 --> 00:36:31,019
当他们收到Blob数据时，通过这个接收的事实

431
00:36:31,119 --> 00:36:33,819
他们就知道数据是可用的，从而满足了这个功能要求

432
00:36:33,960 --> 00:36:35,319
然后他们就可以把它附加到区块上

433
00:36:35,320 --> 00:36:39,740
所以在执行层，你只能看到KZG承诺

434
00:36:39,940 --> 00:36:43,180
也就是这些多项式的承诺函数

435
00:36:44,380 --> 00:36:47,539
当然，这些承诺必须与实际的Blob数据相匹配

436
00:36:47,660 --> 00:36:49,640
这是验证者要进行的另一项检查

437
00:36:49,860 --> 00:36:52,720
但数据本身是存在于共识层的

438
00:36:52,720 --> 00:36:56,800
大约18天后才会被修剪掉或进行类似处理

439
00:36:58,860 --> 00:36:59,420
对的

440
00:37:00,539 --> 00:37:03,400
是的，所以现在我们正在讨论The Scourge

441
00:37:03,400 --> 00:37:13,559
我不会详细讲解每一个项目，但我会快速浏览一下

442
00:37:13,559 --> 00:37:18,079
所有这些都与MEV和质押经济学相关

443
00:37:18,079 --> 00:37:24,380
所以我这里有几张幻灯片，比如讨论PBS（proposal builder separation 提案者-构建者分离）

444
00:37:24,380 --> 00:37:36,840
基本上，所有关于MEV的研究都得出结论：MEV市场是不可避免的，因此我们必须至少加以控制

445
00:37:36,840 --> 00:37:43,740
这样，单独质押者仍然可以获得收益，而不需要加入质押池或

446
00:37:44,260 --> 00:37:51,960
依赖专业验证者来赚钱。因此，我们将所有中心化的元素放入一个角落

447
00:37:51,960 --> 00:37:56,579
这些“角落”指的是构建者。这些构建者可以自由地

448
00:37:56,579 --> 00:38:01,920
进行专业化操作，处理任何提取任务，并拥有

449
00:38:01,920 --> 00:38:08,220
最优的算法、最佳的带宽和最好的资源。我们现在有了

450
00:38:08,220 --> 00:38:13,260
临时解决方案（MEV-Boost），但它还未完全整合到协议PBS中

451
00:38:13,260 --> 00:38:16,560
这是一个权宜之计，直到我们能够真正将其纳入协议

452
00:38:22,560 --> 00:38:28,060
是的，我这里有关于最小化验证者选择的内容

453
00:38:28,060 --> 00:38:35,660
如果没有PBS和MEV-Boost，那么验证者会面临许多选择

454
00:38:35,660 --> 00:38:41,760
例如，如何提取最大化的价值。这对无法专注的单独验证者来说是非常不利的

455
00:38:41,760 --> 00:38:43,480
因此，相反，我们可以最大限度地简化质押者的选择

456
00:38:43,480 --> 00:38:49,140
只需从构建者中挑选出最高的出价即可

457
00:38:49,140 --> 00:38:51,420
这样，我们就能解决MEV去中心化带来

458
00:38:52,020 --> 00:38:57,420
的问题

459
00:38:58,640 --> 00:39:02,520
是的，那是MEV-Boost

460
00:39:02,580 --> 00:39:05,980
未来，我们希望将其直接集成到协议中

461
00:39:05,980 --> 00:39:09,180
这样，我们就不必依赖可信中继节点

462
00:39:09,179 --> 00:39:17,359
此外，我们还希望引入更好的机制，例如通过燃烧MEV收益来平滑质押回报

463
00:39:17,359 --> 00:39:23,460
这本身就是一个完全独立的话题，因为一旦我们引入了PBS

464
00:39:23,460 --> 00:39:29,319
我们会意识到MEV的实际规模，比如它在应用程序中的影响

465
00:39:29,319 --> 00:39:35,000
当你仔细思考时，这真的令人难以置信

466
00:39:35,000 --> 00:39:44,440
EVM 内部的 MEV 预言机 Oracle 执行了各种复杂的操作，另一个相关项目是

467
00:39:44,440 --> 00:39:50,840
包含列表 Inclusion Lists ，目前存在大量的讨论，希望能在下一个分叉中实现

468
00:39:50,840 --> 00:39:56,840
这将使像独立质押者这样的验证者能够强制构建者

469
00:39:56,840 --> 00:40:02,280
包含某些交易。即使构建者是中心化的，他们仍然会受到限制

470
00:40:02,280 --> 00:40:10,660
限制他们的操作范围，例如必须包含某些交易

471
00:40:10,660 --> 00:40:18,780
因此，他们将无法像我们在 MEV 和 FOCIL 问题中看到的那样操作
（FOCIL：Fork-choice-enforced inclusion lists 基于分叉选择规则强制包含列表）

472
00:40:18,780 --> 00:40:23,400
这些问题在过去存在，今天仍然是一个重要的挑战

473
00:40:23,400 --> 00:40:27,820
是的，我很快会讲到所谓Endgame的区块生产，你可以

474
00:40:27,820 --> 00:40:33,740
在Vitalik博客上查看，它基本上和我裁剪的图差不多

475
00:40:33,740 --> 00:40:39,580
箭头展示了区块链可能采取的各种路径，最终它们都会到达目标

476
00:40:39,580 --> 00:40:46,860
为了扩展到数十亿用户，区块生产必须集中化

477
00:40:46,860 --> 00:40:51,500
但区块验证将是去中心化的，并且会引入

478
00:40:51,500 --> 00:40:57,260
反审查保护列表，以及我们可以使用的更多小工具

479
00:40:57,820 --> 00:41:03,100
Q：包含列表中会包含哪些交易？

480
00:41:03,100 --> 00:41:09,580
A：任何交易，例如验证者在内存池（MEMPOOL）中看到交易后，可以将其

481
00:41:09,580 --> 00:41:16,559
加入包含列表，然后构建者被迫将这些交易包含在区块中

482
00:41:16,559 --> 00:41:22,019
是的，聊到执行票 Execution Tickets

483
00:41:22,019 --> 00:41:27,740
目前它只是一个探索性的概念，因此不能保证我们会真正实现它

484
00:41:27,739 --> 00:41:35,659
这是一个相对较新的想法，由Justin Drake提出，你可以在他的研究文章中看到相关内容

485
00:41:35,659 --> 00:41:47,399
这是一种非常优雅的方式，用来处理MEV及其相关问题，提供了一种巧妙的解决方案

486
00:41:47,399 --> 00:41:53,699
基本上，它通过出售提前提议区块的权利，创造了所谓的solo tickets

487
00:41:53,699 --> 00:41:57,399
这有点像彩票，这也是“tickets”这个词的由来

488
00:41:58,980 --> 00:42:03,599
这再次体现了更多的分离

489
00:42:03,599 --> 00:42:06,780
因此，这种设计区分了决定链上哪个区块的权利

490
00:42:06,780 --> 00:42:09,759
与实际提出区块的过程

491
00:42:09,759 --> 00:42:13,739
因此，它最初被称为证明者-提案者 分离 attester-proposer separation

492
00:42:13,739 --> 00:42:16,339
后来被重命名为执行票

493
00:42:20,939 --> 00:42:23,319
我不会花太多时间详细讲解

494
00:42:23,320 --> 00:42:25,240
但这是一个非常优雅的设计

495
00:42:25,380 --> 00:42:28,039
因此，我鼓励大家去ETH研究页面查看

496
00:42:28,120 --> 00:42:31,160
在Wiki的注释中有相关链接

497
00:42:32,980 --> 00:42:37,420
不过，是的，我喜欢它仍然保留了Degen MEV彩票的概念

498
00:42:37,420 --> 00:42:39,940
对于任何想参与的人来说，这并不强制

499
00:42:40,019 --> 00:42:42,480
因为那是独立验证者的选择

500
00:42:42,480 --> 00:42:43,460
他们今天很喜欢

501
00:42:43,580 --> 00:42:47,860
但这是我们希望逐渐减少的东西

502
00:42:47,860 --> 00:42:49,640
因为MEV问题很棘手

503
00:42:49,920 --> 00:42:51,600
这是推动改进的动力

504
00:42:53,320 --> 00:43:01,680
接下来，我在应用层面提到了两个用于最小化MEV的小项目

505
00:43:01,680 --> 00:43:08,960
这些项目并没有过多关注核心协议的研究，而是为了推动

506
00:43:08,960 --> 00:43:15,820
智能合约和DAPP开发者，提醒他们注意MEV问题

507
00:43:15,820 --> 00:43:18,320
无论是捕获还是防止它

508
00:43:18,320 --> 00:43:23,039
例如，像Awswap【没听清】这样的工具非常有趣，它可以防止三明治攻击

509
00:43:23,860 --> 00:43:27,559
这些问题主要发生在应用层面

510
00:43:27,700 --> 00:43:29,220
而不是协议层的关注点

511
00:43:32,000 --> 00:43:36,340
然后是我之前提到的预确认 Preconfirmation 机制

512
00:43:36,500 --> 00:43:44,100
它基本上是一种方法，让构建者承诺将你的交易包含在下一个区块中

513
00:43:44,099 --> 00:43:48,819
这就像在区块实际包含交易之前，提前确认你的交易

514
00:43:49,539 --> 00:43:52,079
而且有多种方法可以实现这一点

515
00:43:52,799 --> 00:43:57,719
是的，它与执行票和各种重新排序计划非常契合

516
00:44:00,460 --> 00:44:02,779
是的，有一些关于以太坊的研究

517
00:44:02,900 --> 00:44:04,679
我认为它们在我注释的路线图中有链接

518
00:44:08,239 --> 00:44:12,139
是的，下一个令人兴奋的大主题是质押经济学

519
00:44:12,139 --> 00:44:20,920
如果我们有幸提高最大有效余额的上限，这可能会在下一个分叉中实现

520
00:44:20,920 --> 00:44:28,099
目前，最低和最高的质押金额都是32 ETH，因此

521
00:44:28,099 --> 00:44:34,199
即使验证者积累了额外的ETH，比如你的余额是33 ETH，你仍然只能赚取

522
00:44:34,199 --> 00:44:40,139
基于32 ETH的收益，即使你的余额是33 ETH

523
00:44:40,139 --> 00:44:46,460
从峰值和底线来看，你的有效余额仍然是32 ETH

524
00:44:46,460 --> 00:44:55,819
将最大有效余额从32 ETH提升到200至2048 ETH，主要好处是优化权益分配

525
00:44:55,819 --> 00:45:02,699
例如，当你的余额从32 ETH增加到33 ETH时，额外的余额会自动计入并开始获得奖励

526
00:45:02,699 --> 00:45:08,460
这种机制会自动生效，使得额外的余额能够参与权益计算并获得相应的奖励

527
00:45:10,139 --> 00:45:17,359
但主要目标是从协议的角度来看，确保验证者的权益数量保持一致

528
00:45:17,420 --> 00:45:24,420
因此

529
00:45:24,599 --> 00:45:29,079
成千上万的验证者可以合并他们的权益

530
00:45:29,079 --> 00:45:33,019
并通过一个签名完成验证，而不是发送数千个签名

531
00:45:33,019 --> 00:45:43,019
这将显著减少开销，并为实现单Slot最终确认铺平道路，同时还能优化资源使用

532
00:45:44,360 --> 00:45:46,280
抱歉，我刚才忘记了我要说的话

533
00:45:47,239 --> 00:45:53,159
是的，这是一种实现单Slot最终确认的方式，同时还能降低节点的带宽需求

534
00:45:56,699 --> 00:45:59,719
类似于基于区块未来的概念，你可以拥有未来区块的通道

535
00:45:59,719 --> 00:46:02,879
这与主题稍有相关，但不完全一致

536
00:46:02,879 --> 00:46:05,679
执行票更多是关于信标链的

537
00:46:05,679 --> 00:46:07,000
提案区块

538
00:46:07,000 --> 00:46:11,619
两者之间有一些区别

539
00:46:11,619 --> 00:46:14,399
不过，我不会深入探讨

540
00:46:14,399 --> 00:46:18,639
是的，在质押经济学（Staking Economics）主题中的下一个项目是：

541
00:46:18,639 --> 00:46:25,559
是的

542
00:46:25,559 --> 00:46:26,419


543
00:46:26,420 --> 00:46:33,240
关于总质押量上限的研究，Caspar 提出了几个有争议的提案

544
00:46:33,240 --> 00:46:39,340
其中包括调整 ETH 的发行曲线，以便在某些情况下可能会

545
00:46:39,340 --> 00:46:46,260
出现负收益。这听起来有些奇怪，但如果你仔细想想

546
00:46:46,260 --> 00:46:54,460
即使收益为负 1%，通过 MEV 和交易费用的补偿，你仍然可以获得 1% 的正收益

547
00:46:54,460 --> 00:47:01,220
即使你需要为成为验证者的权利支付信标链费用，你仍然可以从中获利

548
00:47:02,079 --> 00:47:05,039
这与 MEV 和执行层的活动密切相关

549
00:47:08,420 --> 00:47:13,960
是的，这仍然与验证者数量过多的问题有关，意义重大

550
00:47:13,960 --> 00:47:20,920
但这也是经济上的一个缺点，因为供应量过多

551
00:47:20,920 --> 00:47:27,440
因此，另一个小提案是目标定位，比如我们希望将 25% 的

552
00:47:27,440 --> 00:47:33,680
供应量固定下来，并直接在协议中实现。如果低于 25%

553
00:47:33,680 --> 00:47:39,300
发行曲线会提供更多奖励；如果超过 25%，则减少奖励

554
00:47:39,300 --> 00:47:46,880
这是一个积极的研究领域

555
00:47:46,880 --> 00:47:52,840
下一个小项目是关于流动性质押的集中化问题

556
00:47:52,840 --> 00:47:58,220
人们对流动性质押池和LST（流动性质押代币）有很多担忧

557
00:47:58,220 --> 00:48:07,300
因此，有一种想法是直接在协议内部支持流动性质押代币

558
00:48:07,300 --> 00:48:15,119
实际上，这将是零费用（zero fee）的流动性质押代币（LST），而无需依赖集中化的质押池

559
00:48:15,119 --> 00:48:21,039
我还看到另一个想法是限制削减惩罚的上限

560
00:48:21,839 --> 00:48:27,519
如果将削减惩罚限制在例如2 ETH，那么你可以实现完全无信任且无风险的LST

561
00:48:28,880 --> 00:48:35,199
例如，像Rocketpool这样的系统有两层质押担保。现在，仍然有可能

562
00:48:35,199 --> 00:48:40,719
Rocketpool的验证者破坏了最终确认，从而导致整个质押被削减

563
00:48:40,719 --> 00:48:45,199
包括属于质押池的部分。但如果我们将削减惩罚限制在2 ETH

564
00:48:45,199 --> 00:48:50,559
那么每个人只会损失他们的担保部分，其余部分会返还给质押池，这样就可以

565
00:48:50,559 --> 00:49:00,079
通过对信标链机制的一个相对简单的调整，使这些去中心化的

566
00:49:00,079 --> 00:49:02,879
LST比集中化的LST更具可行性

567
00:49:02,880 --> 00:49:11,840
是的，这就是 The Scourge 的全部。我会花更多时间来讲解下一个

568
00:49:11,840 --> 00:49:13,660
因为这是下一步的重要内容之一

569
00:49:18,660 --> 00:49:24,019
就像我们完成了 The Merge 一样，我们也完成了EIP-4844和Blob空间，现在轮到 Verkle Tree 了

570
00:49:24,019 --> 00:49:28,840
我认为这是下一个重要的升级
571
00:49:28,840 --> 00:49:39,519
因为它们非常有趣，这将是一次非常有趣的升级，首先

572
00:49:39,519 --> 00:49:42,880
我不确定有多少人熟悉状态与历史的概念

573
00:49:42,880 --> 00:49:48,559
但它其实很简单，我们可以快速把握，

574
00:49:48,559 --> 00:49:53,660
我在幻灯片中展示了一个小型区块链示例，当前区块N
575
00:49:53,660 --> 00:49:56,380
引用了区块N-1，再引用区块N-2
576
00:49:56,380 --> 00:50:02,220
所有这些区块共同构成了交易历史记录
577
00:50:02,220 --> 00:50:09,820
记录了以太坊上的交易，并通过计算这些交易得出

578
00:50:09,820 --> 00:50:13,980
当前状态，包括所有余额、合约变量等
579
00:50:14,619 --> 00:50:21,579
因此，当我们同步区块链时，基本上需要同步历史记录并计算状态
580
00:50:21,579 --> 00:50:23,480
然后才能开始检查余额

581
00:50:23,480 --> 00:50:26,819
并验证正在进行的新交易
582
00:50:26,819 --> 00:50:29,380
问题是，有没有更好的方法可以实现这一点？

583
00:50:29,380 --> 00:50:32,400
答案是肯定的，可以通过多项式技术实现
584
00:50:32,400 --> 00:50:33,239
正如我们所见
585
00:50:36,279 --> 00:50:39,719
是的，当前的状态是

586
00:50:39,719 --> 00:50:41,579
通过历史记录计算得出的
587
00:50:41,579 --> 00:50:42,900
正如我在上一张幻灯片中提到的

588
00:50:42,900 --> 00:50:45,559
状态也以树的形式组织

589
00:50:45,559 --> 00:50:47,719
原因我们稍后会看到

590
00:50:47,719 --> 00:50:54,219
这是一个非常简单的状态树示例，有四个参与者，每个参与者都有自己的余额

591
00:50:55,119 --> 00:51:02,500
每两个参与者形成一个节点，你将两个子节点的值相加

592
00:51:02,719 --> 00:51:04,839
然后将结果进行哈希处理

593
00:51:04,879 --> 00:51:06,500
依次向上直到状态根

594
00:51:06,500 --> 00:51:09,480
状态根就是区块头中存储的内容

595
00:51:10,939 --> 00:51:13,859
如果没有交易发生，状态根保持不变

596
00:51:13,860 --> 00:51:18,180
状态根可以用来生成所谓的状态访问证明

597
00:51:18,380 --> 00:51:22,519
你只需要提供兄弟节点的数据即可验证

598
00:51:22,900 --> 00:51:29,200
在这个简单的例子中，你可以证明Bob拥有5个ETH

599
00:51:29,960 --> 00:51:34,680
因此，只需发送相关节点的数据即可完成验证

600
00:51:35,460 --> 00:51:38,420
不过，我的猫刚刚弄乱了东西，真的很烦人

601
00:51:38,420 --> 00:51:47,300
好的，Merkle证明其实非常简单。你只需要展示兄弟节点的数据即可

602
00:51:47,300 --> 00:51:52,519
因此，你需要提供Alice的兄弟节点数据，然后将节点数据传递给Charlie 和 Dave

603
00:51:52,519 --> 00:52:00,980
这些数据是串联的。是的，黄色节点是证明的一部分

604
00:52:00,980 --> 00:52:05,240
绿色节点是你可以在末端计算并用来验证证明的节点

605
00:52:05,239 --> 00:52:07,979
因此，如果你一直追溯到状态根

606
00:52:07,979 --> 00:52:11,119
然后验证它是否与状态根匹配

607
00:52:11,119 --> 00:52:13,799
你就可以通过区块标头中的状态根确认

608
00:52:13,799 --> 00:52:15,919
这样，你就可以确信Bob拥有 5 个 ETH

609
00:52:15,919 --> 00:52:19,139
这就是你可以做到的方式

610
00:52:20,079 --> 00:52:22,159
你可以将其发送到诸如轻客户端之类的工具

611
00:52:22,159 --> 00:52:24,439
这些工具无法访问完整状态

612
00:52:24,439 --> 00:52:26,459
它们仅检查同步委员会

613
00:52:26,459 --> 00:52:29,379
以及执行层上的区块标头

614
00:52:29,379 --> 00:52:31,879
无需计算所有交易

615
00:52:31,880 --> 00:52:47,360
但最大的收获是，随着状态规模的不断增长，这些证明开始变得越来越庞大且难以管理，这在以太坊中是一个普遍现象

616
00:52:47,360 --> 00:52:51,480
因为每笔交易基本上都会增加状态

617
00:52:53,039 --> 00:53:01,059
因此，作为替代方案，我们引入了一种Verkle Trees，与之前的树结构类似但有所不同

618
00:53:01,059 --> 00:53:07,940
在这种Verkle Trees中，每个节点基本上是一个数字，它被视为一个值，然后你可以再次应用多项式魔法

619
00:53:10,019 --> 00:53:16,239
因此，状态根不再是简单的哈希串联

620
00:53:16,239 --> 00:53:20,259
正如我们在数据采样中看到的那样，它实际上是一个多项式承诺

621
00:53:21,059 --> 00:53:23,059
所以我有这个例子

622
00:53:24,000 --> 00:53:28,219
是的，用同样的例子来证明Bob拥有五个ETH。你只需要证明

623
00:53:28,219 --> 00:53:34,539
状态根与第一个子节点的承诺相匹配

624
00:53:34,539 --> 00:53:42,539
也就是证明∏1和承诺C1，然后你知道你可以通过承诺C1

625
00:53:42,539 --> 00:53:49,179
去证明∏2，因此你不需要实际的兄弟节点，这是最大的好处

626
00:53:51,659 --> 00:53:55,739
是的，所以接下来我认为你不需要所有这些节点，你只需要路径

627
00:53:55,739 --> 00:54:04,699
和中间节点以及多项式证明，就像多项式的插值一样

628
00:54:04,699 --> 00:54:10,219
实际上为你提供了正确的值，最大的好处是证明实际上可以

629
00:54:10,219 --> 00:54:16,379
与批处理合并，这是另一个深奥的密码学概念，以及多项式承诺

630
00:54:16,380 --> 00:54:17,840
我就不展开了

631
00:54:17,840 --> 00:54:29,519
嗯，是的，所以之后，一旦我们开始使用Verkle Trees进行交易

632
00:54:29,519 --> 00:54:33,780
整个区块链就可以支持无状态验证者

633
00:54:33,780 --> 00:54:39,920
嗯，我不知道从哪里开始，但我开始觉得Verkle Trees的证明非常多

634
00:54:39,920 --> 00:54:44,660
就像我之前提到的那样，它们更短，而且从现在开始，你不再需要兄弟节点

635
00:54:44,659 --> 00:54:54,019
可以使用更宽的树，比如每个节点有256个子节点，而不是16个

636
00:54:54,019 --> 00:55:01,699
这与我们今天使用的Merkle Patricia Tree状态根不同，而且Verkle Trees

637
00:55:01,699 --> 00:55:07,299
也非常友好

638
00:55:07,300 --> 00:55:14,660
它允许你接收证明并将它们Rollup在一起，这使得客户端更加

639
00:55:14,660 --> 00:55:21,220
易于维护，因为他们只需要查询我在

640
00:55:21,220 --> 00:55:27,060
演讲开始时提到的内容，然后他们知道区块在规范链中，然后通过

641
00:55:27,060 --> 00:55:32,980
这些工作证明，他们可以知道余额，他们可以查询余额，或者

642
00:55:32,980 --> 00:55:37,519
任何拥有状态的人都可以计算这些工作证明

643
00:55:37,519 --> 00:55:39,860
并满足客户端的需求，然后说

644
00:55:39,860 --> 00:55:41,159
好吧，这是你的余额

645
00:55:41,159 --> 00:55:44,840
而且你实际上不会以这种方式被欺骗

646
00:55:52,860 --> 00:55:55,659
最重要的是无状态性
647
00:55:55,659 --> 00:56:00,139
如果你是一个轮换节点或验证者
648
00:56:00,139 --> 00:56:01,940
实际上并不需要保存历史记录
649
00:56:01,940 --> 00:56:04,099
你会收到一个区块，比如区块n
650
00:56:04,440 --> 00:56:06,960
但你对其状态一无所知
651
00:56:07,220 --> 00:56:10,539
你所看到的只是区块标头中的状态根
652
00:56:11,059 --> 00:56:13,400
此外，还有一个称为区块证人 block witness 的新概念
653
00:56:13,700 --> 00:56:16,159
它基本上包含了所有的Verkle证明
654
00:56:16,159 --> 00:56:18,519
这些证明是计算交易所需的
655
00:56:19,099 --> 00:56:23,240
例如，当你看到Bob向其他人发送五个ETH时
656
00:56:23,240 --> 00:56:26,940
你需要证明他确实拥有这五个ETH
657
00:56:27,320 --> 00:56:28,900
这将成为证人的一部分
658
00:56:28,900 --> 00:56:34,599
因此，你实际上不需要计算所有之前的区块来验证 Bob 拥有五个ETH
659
00:56:34,960 --> 00:56:37,860
你只需要检查这个证明，而这个证明

660
00:56:38,760 --> 00:56:40,760
已经由你的节点验证
661
00:56:40,820 --> 00:56:45,280
因此，这类似于即时同步，同时也大大减轻了

662
00:56:45,920 --> 00:56:48,660
存储整个状态的负担，这涉及大量的读写操作

663
00:56:49,340 --> 00:56:51,340
和运行成本

664
00:56:51,340 --> 00:57:02,680
我只是快速浏览了一下聊天内容

665
00:57:02,680 --> 00:57:09,579
所以，是的，无状态验证是一件大事，但这只有在使用默克尔树时才有可能

666
00:57:09,579 --> 00:57:15,680
因为默克尔证明太过庞大，区块证人可能会达到兆字节级别

667
00:57:15,679 --> 00:57:20,859
如果我们有大量访问状态的交易，证明的大小会变得非常长

668
00:57:23,859 --> 00:57:26,099
这些无状态验证者是否运行在某些地方？

669
00:57:26,359 --> 00:57:28,599
嗯，目前还没有，因为我们还没有引入Verkle树

670
00:57:28,599 --> 00:57:34,480
但这是一种选择，如果你需要

671
00:57:34,480 --> 00:57:38,500
或者只是想开始同步并检查区块证人

672
00:57:42,460 --> 00:57:43,059
是的

673
00:57:43,059 --> 00:57:49,199
是的，像轻客户端一样的节点变得更轻，因为它们只需要

674
00:57:49,199 --> 00:57:56,639
同步委员会和工作证明来检查余额等内容，而另一个被低估的

675
00:57:56,639 --> 00:58:03,480
无状态验证的方面是，这种模式对依赖后端的开发者非常友好

676
00:58:03,480 --> 00:58:10,440
尤其是那些需要专门为其应用程序用户索引余额的开发者

677
00:58:10,440 --> 00:58:17,940
就像今天一样，他们主要依赖集中式索引，因为如果他们想要跟踪

678
00:58:17,940 --> 00:58:25,659
用户余额和其他仅与用户相关的变量，他们仍然需要

679
00:58:25,659 --> 00:58:28,820
同步整个状态

680
00:58:28,820 --> 00:58:33,440
当你想获取过去的状态时，这会很麻烦，因为你必须索引所有内容

681
00:58:33,440 --> 00:58:39,480
然后跟踪过去的余额，例如历史状态，而不仅仅是当前状态

682
00:58:40,320 --> 00:58:45,679
因此，你可以想象随着时间推移绘制代币或某些资产的价格图表

683
00:58:46,820 --> 00:58:52,019
所以现在，大型档案节点对图表或查询工具的依赖性很高

684
00:58:52,019 --> 00:58:53,579
因为运行一个节点非常困难

685
00:58:53,860 --> 00:59:01,300
但是有了 Verkle 树，它的结构方式允许你只执行与

686
00:59:01,300 --> 00:59:03,539
你的应用相关的区块

687
00:59:03,800 --> 00:59:06,080
因此，如果过去有一千个区块

688
00:59:06,080 --> 00:59:09,140
其中只有 30 个实际上涉及到你的智能合约

689
00:59:09,280 --> 00:59:11,740
那么你只需要执行这 30 个区块

690
00:59:11,740 --> 00:59:13,900
并在后端更新状态

691
00:59:13,900 --> 00:59:16,220
以完成你需要做的任何事情

692
00:59:16,360 --> 00:59:19,519
比如在前端向用户显示信息

693
00:59:20,460 --> 00:59:23,240
正如我所说，这是一个

694
00:59:23,280 --> 00:59:24,519
被低估的方面

695
00:59:24,519 --> 00:59:26,440
我没有看到有人提到

696
00:59:26,560 --> 00:59:28,900
所以这是我现在正在大力呼吁的事情

697
00:59:31,300 --> 00:59:40,740
之后，再次提到 Verkle 树的所有酷炫特性

698
00:59:40,740 --> 00:59:46,900
非常简单的状态访问验证，但我们想要的还远远不够完善

699
00:59:46,900 --> 00:59:53,220
所有事物的零知识证明，因此像轻客户端协议已经非常轻量化，但

700
00:59:53,220 --> 00:59:59,380
随着同步委员会的所有过渡，这些协议将变得更加轻量化
701
00:59:59,380 --> 01:00:05,700
目前，验证只需27小时，这是一个单一的证明，可以快速完成验证
702
01:00:05,700 --> 01:00:12,340
这只是一个小开端，从这里开始，接下来的逻辑步骤是优化信标链的转换
703
01:00:12,340 --> 01:00:19,140
这也可以有效地让轻客户端协议逐步被淘汰   
01:00:19,140 --> 01:00:25,700
如果你能够使用一个snark来验证整个信标链的签名和余额
705
01:00:25,699 --> 01:00:32,980
包括削减和其他内容，那么这就是你在执行层上拥有的共识层
706
01:00:33,539 --> 01:00:40,179
通过snark，你可以高效地验证Verkle状态访问证明，这将显著加快速度
707
01:00:40,179 --> 01:00:47,379
尤其是在验证区块证人时。如果你能够将每个证明合并到一个snark中
708
01:00:47,380 --> 01:00:57,500
那么最终的目标就是让所有EVM执行都基于零知识证明（snark）。因此，你会收到一个

709
01:00:57,500 --> 01:01:03,880
区块，然后检查一个零知识证明，而几乎不需要任何其他证明
710
01:01:03,880 --> 01:01:10,039
并且你无需自己执行实际的EVM计算，而是直接接收区块
711
01:01:10,039 --> 01:01:16,960
你可以对我上面提到的进一步Rollup进行数据采样，并验证这些证明
712
01:01:16,960 --> 01:01:23,840
此外，你可以验证数据的可用性，并且执行实际上与

713
01:01:23,840 --> 01:01:30,000
下一个区块的结果状态根相一致。这是非常未来派的概念，但非常酷

714
01:01:30,000 --> 01:01:36,559
ZK-Rollups实际上正在研究ZK-EVM，我们最终可以将其带回核心协议

715
01:01:36,559 --> 01:01:45,440
形成一个完整的闭环。这就是我们通过这些ZK-Proofs实现第1层可扩展执行的方式

716
01:01:46,960 --> 01:01:59,559
ZK-EVM的操作码在预编译中，我只是简短地提到它，因为它非常酷

717
01:01:59,559 --> 01:02:04,460
EVM可以支持一种验证EVM证明的方法

718
01:02:04,460 --> 01:02:14,360
因此，你可以在本地支持EVM的非常简单的ZK-Rollup

719
01:02:14,360 --> 01:02:21,480
你可以直接在此升级中验证EVM的内部鲁棒性以及EVM的安全机制

720
01:02:21,480 --> 01:02:25,700
在EVM中，这是非常未来派的技术
721
01:02:25,700 --> 01:02:33,160
这种对状态的改进是否会让第2层（L2）变得无关紧要？

722
01:02:33,160 --> 01:02:38,620
从长远来看，它们仍然会相关，但在可扩展性方面的作用可能会减少
723
01:02:38,620 --> 01:02:42,440
不过，我认为这是一种扩展性的复合效应
724
01:02:42,440 --> 01:02:46,679
因此，如果第1层（L1）扩展了，第2层（L2）也会随之轻松扩展
725
01:02:46,679 --> 01:02:52,360
你可以研究这种分形扩展的概念，总会有

726
01:02:52,360 --> 01:02:58,420
某种形式的第2层存在，至少这是我的预期
727
01:02:58,420 --> 01:03:00,320
正如Josh所说
728
01:03:00,320 --> 01:03:05,559
如果第1层扩展了，第2层也会扩展
729
01:03:05,559 --> 01:03:10,679
我之前没有提到，但Verkle树支持无状态验证，你将能够

730
01:03:10,679 --> 01:03:17,319
轻松将Gas限制提高三倍，因此无状态后第1层的费用会更低
731
01:03:17,319 --> 01:03:26,559
超级酷，嗯，接下来两个项目之后，我没有太多要补充的内容，所以我只是

732
01:03:26,559 --> 01:03:33,259
快速总结一下，这一切的目标是实现一个更简单的协议。因此，关于 Big Ticket

733
01:03:33,260 --> 01:03:42,340
中的历史到期问题，EIP-4444也被昵称为four fours。简而言之
734
01:03:42,340 --> 01:03:50,280
节点将不再需要存储超过一年的历史记录。乍一听，这似乎

735
01:03:50,280 --> 01:03:56,460
令人担忧，因为我们习惯了节点验证整个区块链，但事实证明

736
01:03:56,460 --> 01:04:02,740
以太坊在实时结算层中实现的目标并不需要这一点

737
01:04:02,739 --> 01:04:08,319
我不记得是谁提到的，我认为是Tim Bako

738
01:04:08,319 --> 01:04:11,859
我不确定具体的时间框架，但基本上

739
01:04:11,859 --> 01:04:17,199
如果你问一千个节点，最新的区块是什么

740
01:04:17,199 --> 01:04:18,719
你可能会得到一些不一致的答案

741
01:04:18,719 --> 01:04:21,339
比如有些节点没有及时收到最新的区块

742
01:04:21,339 --> 01:04:24,759
并认为之前的区块是链的头部，类似这样的情况

743
01:04:24,759 --> 01:04:30,199
但是，如果你问他们第10,000个区块是什么

744
01:04:30,199 --> 01:04:38,119
他们都会对这一历史达成一致。因此，这种对历史的分歧，尤其是

745
01:04:38,119 --> 01:04:45,719
在最终确认的区块上，基本上是不可能的。因此，对于修剪历史而言

746
01:04:45,719 --> 01:04:49,719
与我们通过简化客户端代码库所获得的优势相比，这并不是一个大问题

747
01:04:50,439 --> 01:04:58,039
因此，像今天已经不再相关的较早分叉所支持的所有旧规则一样

748
01:04:58,039 --> 01:05:03,739
你可以将其从代码库中移除，只关注协议当前的实际运行方式

749
01:05:04,920 --> 01:05:08,000
而且，当然，这大大减少了节点的存储需求
750
01:05:09,460 --> 01:05:12,960
从技术上讲，这可以随时实施
751
01:05:13,039 --> 01:05:14,119
这并不是硬分叉
752
01:05:14,179 --> 01:05:17,639
更像是节点之间的一种点对点协议约定
753
01:05:18,460 --> 01:05:24,739
因此，在激活之前，我们希望通过其他方式可靠地访问历史记录
754
01:05:24,739 --> 01:05:29,739
最去中心化的方式可能是类似门户网络的方案
755
01:05:30,879 --> 01:05:35,879
这类似于一个专门用于共享历史记录的协议
756
01:05:37,339 --> 01:05:42,339
以及类似轻客户端的状态访问证明
757
01:05:42,599 --> 01:05:46,000
当然，还有其他选择
758
01:05:46,000 --> 01:05:47,319
比如保留完整历史记录
759
01:05:47,319 --> 01:05:49,819
通过种子网络或区块浏览器等方式
760
01:05:49,820 --> 01:05:59,900
是的，这基本上是一个软件，我们希望实现它，但我不太了解点对点层的具体情况
761
01:05:59,900 --> 01:06:07,420
EIP-4444 的核心是节点不再需要提供历史记录服务
762
01:06:07,420 --> 01:06:18,900
对于那些问它与下一个 Purge 阶段关系的人来说，所有历史记录都属于状态到期的范畴
763
01:06:18,900 --> 01:06:23,940
我个人不认为这会发生，因为它会破坏太多现有的内容，而这是一种较低优先级的方式
764
01:06:23,940 --> 01:06:32,340
与 PBS 和无状态验证的同步性相比，它的优先级较低，因此成为了一种次要的选择
765
01:06:32,340 --> 01:06:39,700
不过，是的，这并不是 Vitalik 路线图更新中的显著变化
766
01:06:39,700 --> 01:06:46,820
那一年，他只是将它从大票蓝色项目降级为绿色项目。但就我个人而言
767
01:06:46,820 --> 01:06:53,940
我不认为这会发生，因为这需要延长地址长度，并进行

768
01:06:53,940 --> 01:07:00,340
各种复杂的操作，比如状态到期，然后重新部署整个状态中的同一代币
769
01:07:00,340 --> 01:07:06,420
并验证这些破坏性的更改。不过，它仍然被提到
770
01:07:08,740 --> 01:07:11,860
它仍然被提到，因为它在路线图上

771
01:07:11,860 --> 01:07:18,420
是的，是的，只是想废除状态

772
01:07:18,519 --> 01:07:20,820
是的，我认为你可以拥有一个无状态的客户端

773
01:07:20,820 --> 01:07:22,440
这有点像部分无状态化

774
01:07:22,440 --> 01:07:24,400
因此，如果状态的一部分

775
01:07:24,400 --> 01:07:26,019
并没有被频繁访问

776
01:07:26,220 --> 01:07:27,680
你可以在本地修剪它

777
01:07:27,680 --> 01:07:31,440
你可以将节点聚焦于

778
01:07:31,440 --> 01:07:33,980
仅与你账户相关的状态

779
01:07:33,980 --> 01:07:36,680
或者你关心的 Rollup 和类似内容

780
01:07:36,980 --> 01:07:38,840
这就是为什么我认为状态到期

781
01:07:38,840 --> 01:07:40,500
并不是那么重要

782
01:07:40,500 --> 01:07:42,880
现在也不是优先事项

783
01:07:42,880 --> 01:07:47,900
接下来，The Purge阶段的最后一个小项目

784
01:07:47,900 --> 01:07:48,880
是各种协调工作

785
01:07:49,920 --> 01:07:52,820
例如，执行层目前使用所谓的RLP

786
01:07:52,820 --> 01:07:56,800
来对交易和区块进行序列化

787
01:07:57,179 --> 01:08:00,019
而共识层则使用SSZ

788
01:08:00,920 --> 01:08:03,400
未来，我们希望简化这一点

789
01:08:03,400 --> 01:08:06,139
将所有内容统一迁移到SSZ格式

790
01:08:06,139 --> 01:08:10,320
并逐步淘汰所有旧的交易类型

791
01:08:10,320 --> 01:08:18,800
例如像EIP-1559之前的旧交易类型，可能会像所有访问列表一样被纳入计划

792
01:08:18,800 --> 01:08:26,480
强制交易和类似的内容，但这是实现这一目标的方法

793
01:08:26,480 --> 01:08:35,840
这是我猜测的研究方向，是的，这就是我关于Purge阶段的全部内容

794
01:08:35,840 --> 01:08:40,319
我们希望在核心协议中实现，但它不适合其他任何地方

795
01:08:40,319 --> 01:08:45,920
我们开始清理并处理这些杂项内容，其中一个重要的项目是

796
01:08:47,920 --> 01:08:56,159
EOF，即EVM对象格式，最近有很多EIPs在某种程度上与此相关

797
01:08:56,159 --> 01:09:04,560
不过，重组EVM的某些方面仍在进行中，而我实际上并不是

798
01:09:04,560 --> 01:09:09,840
负责讨论EOF的人，所以我只能分享一些关于

799
01:09:09,840 --> 01:09:17,440
EOF的理解。我的理解是，它会以向前兼容的方式升级未来的EVM

800
01:09:17,440 --> 01:09:24,000
使其更加容易。因此，拥有EOF和核心协议后，两层可以

801
01:09:24,000 --> 01:09:32,320
进行创新，利用自己的小型EVM升级内容，然后尝试这些改进

802
01:09:32,319 --> 01:09:36,399
这样就不需要每次都更改第1层

803
01:09:36,399 --> 01:09:37,439
每次如此

804
01:09:39,039 --> 01:09:40,079
是的，就是这样
805
01:09:44,920 --> 01:09:46,359
另一个重要议题

806
01:09:46,359 --> 01:09:48,039
是账户抽象的实现

807
01:09:48,039 --> 01:09:50,079
目前来看

808
01:09:50,079 --> 01:09:52,880
这是以太坊十年来未解决的问题之一

809
01:09:52,880 --> 01:09:56,639
比如带有私钥的钱包

810
01:09:56,639 --> 01:09:59,840
余额管理和相关功能都很不完善

811
01:09:59,840 --> 01:10:05,520
这确实很糟糕，比如没有办法让别人帮你支付Gas费用

812
01:10:05,520 --> 01:10:11,840
也无法轻松地批量处理交易，比如必须先批准一个代币

813
01:10:11,840 --> 01:10:17,760
然后在下一笔交易中进行兑换，对密钥安全的担忧也没有得到很好解决

814
01:10:17,760 --> 01:10:24,480
在加密世界中，这种情况显得尤为尴尬
815
01:10:24,479 --> 01:10:30,639
一些简单的操作，比如撤销密钥或更换密钥，而无需尴尬地转移所有

816
01:10:30,639 --> 01:10:39,019
资金，这些操作往往既昂贵又耗时
817
01:10:39,019 --> 01:10:43,899
账户抽象支持支出条件和社交恢复功能，因此你可以拥有

818
01:10:43,899 --> 01:10:49,119
比冷钱包更灵活的使用体验
819
01:10:49,119 --> 01:10:56,099
例如，你可以设置自定义的支出条件，比如每天最多花费一定金额
820
01:10:56,099 --> 01:10:57,159
以增强安全性
821
01:10:57,159 --> 01:11:03,899
但是，如果我想一次转移过多的资金，我需要一个冷钱包作为额外的密钥存储

822
01:11:03,899 --> 01:11:09,000
因此，你可以拥有一个能够完成所有这些功能并设置可信监护人的钱包

823
01:11:09,000 --> 01:11:11,019
作为恢复机制

824
01:11:11,020 --> 01:11:19,060
智能钱包的设计空间非常广阔，几乎是无限的，但目前

825
01:11:19,060 --> 01:11:25,700
我们只有这些EOA（外部拥有账户），这实在是太糟糕了

826
01:11:25,700 --> 01:11:34,620
重要的EIP和ERC包括3074，它允许将EOA的控制权委托给智能合约

827
01:11:34,619 --> 01:11:40,460
我认为这不在Vitalik的路线图上，但我个人对EIP-3074的前景非常看好

828
01:11:40,460 --> 01:11:49,099
ERC-4337是一种智能钱包标准，它不会影响核心协议，至少目前不会

829
01:11:49,099 --> 01:11:54,859
但它是一个很好的标准化协议

830
01:11:56,460 --> 01:12:03,500
旨在为所有EVM链提供统一的标准，而不是让每个Rollup都有自己的本地标准

831
01:12:03,500 --> 01:12:06,180
他们自己的本地标准是账户抽象

832
01:12:07,539 --> 01:12:11,920
最终可以将一个EOA转换为

833
01:12:11,920 --> 01:12:14,840
与EIP-4337兼容的智能钱包

834
01:12:14,840 --> 01:12:16,380
并最终集成到协议中

835
01:12:16,380 --> 01:12:20,279
INT协议在实现中的重要意义

836
01:12:21,920 --> 01:12:23,760
这基本上将为我们带来

837
01:12:23,760 --> 01:12:28,420
我们所追求的账户抽象理想境界

838
01:12:28,420 --> 01:12:37,980
是的，终极目标EIP-1559一直是人们关注的一个重要问题
839
01:12:37,980 --> 01:12:43,000
它在路线图上的意义是什么？我认为1559已经非常出色，那么
840
01:12:43,000 --> 01:12:49,940
是什么让它成为终极目标？我看到的三个主要点是让它更像自动化的

841
01:12:49,939 --> 01:12:57,219
做市商曲线，而不是跟踪之前区块中的使用量
842
01:12:57,219 --> 01:13:02,259
而是仅跟踪多余的Blob和多余的Gas
843
01:13:02,259 --> 01:13:05,539
因此，如果你超过了1500万的目标

844
01:13:05,539 --> 01:13:09,139
比如你达到了1600万，那么就会增加

845
01:13:09,139 --> 01:13:13,699
100万的额外Gas费用，这种设计随着时间推移

846
01:13:13,699 --> 01:13:19,379
会让系统更加稳定，因为实际上它并不是

847
01:13:19,380 --> 01:13:27,940
严格以1500万为目标，而是以63/64为目标。如果你超过了12.5%

848
01:13:27,940 --> 01:13:32,659
那么会下降12.5%，但实际上并不会完全回到零，而是

849
01:13:32,659 --> 01:13:39,380
略低于零。这是EIP-1559的一个奇怪特性，可以通过这种改进

850
01:13:39,380 --> 01:13:48,100
来跟踪额外的Gas费用。另一个好处是它提高了审查的成本
851
01:13:48,100 --> 01:13:54,340
因为现在如果区块构建者决定删除某些交易，无论出于何种原因
852
01:13:54,900 --> 01:14:01,300
他们不仅会放弃优先费用，还会放弃全部费用。但通过这种设计
853
01:14:02,180 --> 01:14:08,820
他们将不得不放弃所有费用。我不会深入探讨，但这就是它的逻辑
854
01:14:08,820 --> 01:14:16,100
今天，ETH的燃烧量仍然尽可能多，但审查的机会成本将是

855
01:14:16,100 --> 01:14:23,039
全部费用，而不仅仅是从精神模型角度来看优先费用
856
01:14:23,039 --> 01:14:28,900
构建者可以从协议中购买多余的Gas，然后通过交易来填补它

857
01:14:29,840 --> 01:14:32,840
因此，这在某个时间点是必须发生的事情

858
01:14:33,600 --> 01:14:39,820
除此之外，还有两件事是多维EIP-1559，就像我们今天的Blob一样

859
01:14:39,819 --> 01:14:44,719
以太坊资源的定价

860
01:14:44,719 --> 01:14:47,259
截至上周，它是二维的

861
01:14:47,340 --> 01:14:48,259
非常酷

862
01:14:48,979 --> 01:14:51,059
但你可以更进一步

863
01:14:51,059 --> 01:14:52,479
为不同资源单独定价

864
01:14:52,699 --> 01:14:55,399
例如对调用数据进行单独定价

865
01:14:55,399 --> 01:14:58,840
这样就不会影响

866
01:14:58,840 --> 01:15:01,420
对状态的读写成本

867
01:15:01,579 --> 01:15:04,799
然后你可以独立于计算

868
01:15:04,799 --> 01:15:06,639
来管理区块的大小

869
01:15:06,639 --> 01:15:07,880
以及类似的内容

870
01:15:07,880 --> 01:15:10,260
因此，这将使系统更加高效

871
01:15:11,600 --> 01:15:22,260
它会消除当前的奇怪现象，即将所有内容捆绑在一起

872
01:15:22,260 --> 01:15:26,480
这迫使我们必须考虑所有可能的最糟糕情况

873
01:15:26,960 --> 01:15:33,340
因此，今天我们不得不考虑最糟糕的情况

874
01:15:33,340 --> 01:15:38,220
比如有人向状态写入大量数据，从而耗尽每个节点的存储空间

875
01:15:38,220 --> 01:15:43,180
我们必须让向状态写入变得昂贵，同时也要让

876
01:15:43,180 --> 01:15:48,220
生成包含大量调用数据的大区块变得昂贵，以防止节点无法处理。相反

877
01:15:49,100 --> 01:15:53,579
我们可以为每种资源量身定制最坏情况的应对措施

878
01:15:55,260 --> 01:15:59,900
这正是多维EIP-1559的优势所在

879
01:15:59,899 --> 01:16:06,239
最后一个小项目是关于将时间纳入基本费用计算的考量

880
01:16:06,239 --> 01:16:12,359
目前，如果有验证者错过了 Slot，下一个

881
01:16:12,359 --> 01:16:18,439
区块会填充更多交易，这会让协议

882
01:16:18,439 --> 01:16:23,119
误以为需求突然增加，因为协议无法识别

883
01:16:23,119 --> 01:16:29,599
Slot 的缺失，它只是将其视为需求的激增，但实际上

884
01:16:29,599 --> 01:16:34,239
这并不是需求激增，而是一种供应短缺

885
01:16:35,840 --> 01:16:42,000
是的，EIP-4396 提出了将时间纳入基本费用计算的一部分

886
01:16:44,720 --> 01:16:46,239
我认为这就是最后一个项目了

887
01:16:46,239 --> 01:16:56,319
是的，这部分涉及深奥的密码学，例如完全同态加密

888
01:16:56,319 --> 01:17:00,619
加密、单次签名以及所有这些超级未来派的技术，都是

889
01:17:00,619 --> 01:17:08,579
一个积极的研究领域，不仅来自以太坊研究，还包括密码学领域的实际研究

890
01:17:08,579 --> 01:17:14,519
以探索我们可以实现的可能性

891
01:17:14,520 --> 01:17:19,420
我认为单次签名是一个很好的例子

892
01:17:19,420 --> 01:17:28,620
你可以看到，Justin Drake研究了关于量子计算机和许多其他未来派加密技术的论文

893
01:17:28,820 --> 01:17:35,140
然后提出了一种方法，可以在签名后销毁签名本身

894
01:17:35,500 --> 01:17:43,120
此外，这种方法可以被整合到区块链中，就像我们在量子计算机普及的未来所设想的那样

895
01:17:43,119 --> 01:17:48,899
这将消除对完全削减机制的需求，但我需要

896
01:17:48,899 --> 01:17:53,800
强调，这确实是一个未来派的概念，但它非常酷

897
01:17:53,800 --> 01:17:59,239
下一件大事可能是完全加密的交易处理

898
01:17:59,239 --> 01:18:03,819
消除所有有毒的MEV，因为你无法知道交易的具体内容

899
01:18:03,819 --> 01:18:07,619
包括实际的发送方和接收方，因此无法对用户进行三明治攻击

900
01:18:07,619 --> 01:18:19,059
也无法从单个用户那里滑点或提取价值，但仍然会保留无毒的MEV

901
01:18:19,059 --> 01:18:26,099
就像两次交易所之间的套利和清算一样，这些机会仍然会保留。

902
01:18:26,100 --> 01:18:33,460
因此，MBV（最大可提取价值）仍然存在，因为人们希望位于区块的顶部。

903
01:18:33,461 --> 01:18:42,899
是的，我会记得回去分享关于单次签名的相关论文。

904
01:18:42,900 --> 01:18:50,340
是的，最后一个是VDF（可验证延迟函数），简单来说，它是一种。

905
01:18:50,340 --> 01:18:56,659
在一个方向上计算非常缓慢的不可预测工作证明，就像是

906
01:18:57,380 --> 01:19:04,099
你需要等待或执行一些耗时的操作才能完成的功能

907
01:19:04,100 --> 01:19:09,380
然后，你可以快速验证它的结果，就像工作量证明，但不可逆

908
01:19:10,100 --> 01:19:16,180
基本上，它将通过信标链来增强随机性，因为目前

909
01:19:17,300 --> 01:19:22,900
随机性并不完全随机。例如，负责提议区块的验证者

910
01:19:22,900 --> 01:19:28,500
可能会故意错过他们的Slot，从而扰乱随机性，但这只是

911
01:19:28,500 --> 01:19:39,460
对随机性的一点点控制，仍然有很多改进空间

912
01:19:39,460 --> 01:19:44,960
最近的一篇论文表明，我们希望通过VDF实现的架构

913
01:19:44,960 --> 01:19:50,840
实际上是脆弱的

914
01:19:50,840 --> 01:19:56,199
虽然我们并不严格需要它，但如果能实现会更好，所以这更像是

915
01:19:56,199 --> 01:19:59,500
一个锦上添花的路线图项目

916
01:20:01,739 --> 01:20:04,539
是的，就是这样

917
01:20:04,539 --> 01:20:06,319
感谢大家的观看

918
01:20:06,319 --> 01:20:09,119
我想我们还有一些时间，比如10分钟来回答问题

919
01:20:16,659 --> 01:20:18,439
太棒了，非常感谢

920
01:20:18,439 --> 01:20:21,699
是的，那是一个非常精彩的路线图讲解

921
01:20:22,840 --> 01:20:25,639
看来我们有很多问题可能会在聊天中提出来

922
01:20:25,640 --> 01:20:33,160
嗯，是的，让我们看看大家都在这里讨论些什么

923
01:20:41,320 --> 01:20:50,760
嗯，我很好奇你认为当前路线图上最优先的事项是什么？

924
01:20:50,760 --> 01:20:52,220
哪些话题

925
01:20:52,220 --> 01:20:55,760
正在被开发和研究？

926
01:20:55,760 --> 01:20:57,659
你觉得

927
01:20:57,659 --> 01:20:59,760
我们应该特别关注哪些内容？

928
01:20:59,760 --> 01:21:01,520
是哪些

929
01:21:01,520 --> 01:21:03,820
值得我们优先考虑的

930
01:21:03,820 --> 01:21:04,119
内容？

931
01:21:05,300 --> 01:21:07,680
嗯，我认为下一个优先事项是

932
01:21:07,680 --> 01:21:09,440
Verkle Trees，希望

933
01:21:09,440 --> 01:21:11,520
它能包含在下一次升级中，但这是

934
01:21:11,520 --> 01:21:13,600
在默克尔状态树之间的过渡

935
01:21:13,600 --> 01:21:15,539
我们正在迈向 Verkle 树

936
01:21:15,539 --> 01:21:17,180
还有一些

937
01:21:17,180 --> 01:21:19,380
我们需要同时权衡的选项，但我相信这是下一个重要的

938
01:21:19,380 --> 01:21:24,279
升级节点。不过，是的，并行处理的一切都很酷。上周的 Blob 空间缓解了许多

939
01:21:24,279 --> 01:21:31,180
与二层扩展相关的问题。所以这为我们争取到了更多时间去完成另一项

940
01:21:31,180 --> 01:21:37,359
重大任务。是的。看起来 Verkle 树绝对是当前研究的重点之一

941
01:21:37,359 --> 01:21:44,940
它已经有了大量的实施进展

942
01:21:44,939 --> 01:21:49,839
你认为还有哪些

943
01:21:49,839 --> 01:21:51,399
仍然需要大量研究的主题？

944
01:21:52,699 --> 01:21:55,899
也许有很多，你知道

945
01:21:55,899 --> 01:21:56,979
还有许多事情可以去做

946
01:21:56,979 --> 01:21:59,899
你知道，这个研究小组中的某人可能会

947
01:21:59,899 --> 01:22:03,939
将其作为一个个人项目来接手

948
01:22:03,939 --> 01:22:07,199
就像对待一个兴趣项目一样去推进

949
01:22:07,199 --> 01:22:08,299
或者类似的事情

950
01:22:09,859 --> 01:22:13,779
我认为围绕PBS有许多类似的权衡

951
01:22:13,779 --> 01:22:18,219
而且我们一直在各种设计中反复权衡

952
01:22:18,219 --> 01:22:20,420
总是会有一些取舍

953
01:22:20,420 --> 01:22:24,460
比如在延迟方面，我也不太确定

954
01:22:24,460 --> 01:22:29,199
提出的各种设计总是会存在一些问题

955
01:22:29,199 --> 01:22:30,539
这些设计并不总是奏效

956
01:22:30,539 --> 01:22:34,139
请记住，事情总是会有些奇怪

957
01:22:34,139 --> 01:22:35,840
尤其是在包含列表方面

958
01:22:37,019 --> 01:22:39,739
带有无状态验证者的包含列表

959
01:22:39,739 --> 01:22:41,079
兼容性不好

960
01:22:41,079 --> 01:22:43,359
因此，这仍然是一个活跃的研究领域

961
01:22:44,380 --> 01:22:48,000
所以我担心我们可能需要解决

962
01:22:48,000 --> 01:22:51,720
围绕PBS的最低设计问题

963
01:22:52,180 --> 01:22:54,079
这真的很遗憾

964
01:22:54,079 --> 01:22:56,640
因为PBS本身作为一个概念非常酷

965
01:22:59,380 --> 01:23:00,100
非常棒。

966
01:23:04,199 --> 01:23:05,439
奥克斯提问：

967
01:23:05,539 --> 01:23:07,519
哪一件事最有可能

968
01:23:07,519 --> 01:23:09,819
简化所有这些复杂性？

969
01:23:11,079 --> 01:23:16,779
是PBS，还是整个路线图？

970
01:23:17,059 --> 01:23:20,000
我认为，他们通常指的是整个路线图。

971
01:23:22,180 --> 01:23:26,239
似乎路线图中的许多内容只是不断增加了更多的东西，

972
01:23:26,239 --> 01:23:30,619
而不是减少协议的复杂性。

973
01:23:30,619 --> 01:23:34,359
那么，有哪些事情可以清理掉？或者还有什么可以改进的？

974
01:23:34,579 --> 01:23:38,579
是否有可能通过某些方式降低复杂性，或者让其中一些

975
01:23:38,579 --> 01:23:41,600
复杂性能够自我协调运作？

976
01:23:42,899 --> 01:23:44,220
我不太确定。

977
01:23:45,340 --> 01:23:45,680
是的。

978
01:23:46,079 --> 01:23:47,340
简化的方式。

979
01:23:47,340 --> 01:23:47,640
是的。

980
01:23:47,760 --> 01:23:51,720
就像某些解决方案出现后，可以用更简单的方式实现相同的目标。

981
01:23:51,720 --> 01:23:57,359
与我们现有的其他方案相比，这样的方式会显得尤为重要。

982
01:23:57,359 --> 01:24:04,019
这些方案已经被规划了很久，但就像路线图一样，它几乎是

983
01:24:04,020 --> 01:24:06,520
多年研究的成果。

984
01:24:06,520 --> 01:24:08,920
因此，我们基本上已经知道如何去实现它们。

985
01:24:08,920 --> 01:24:12,580
除了我提到的夜间选择之外

986
01:24:12,580 --> 01:24:17,080
EPB，我认为这几乎是必经之路

987
01:24:17,080 --> 01:24:19,320
如果有人说我们可以解决所有这些问题

988
01:24:19,320 --> 01:24:22,820
以更简单的方式，我会感到非常惊讶

989
01:24:22,820 --> 01:24:25,780
但即便如此，我也会非常欢迎这样的解决方案

990
01:24:25,780 --> 01:24:27,560
这确实是有道理的

991
01:24:27,560 --> 01:24:29,980
我很好奇你是否有任何看法

992
01:24:29,979 --> 01:24:34,539
关于这个路线图的广度以及

993
01:24:34,539 --> 01:24:39,219
它可能固化的潜力，以及核心开发者的能力

994
01:24:39,219 --> 01:24:44,439
在协议可能固化之前完成所有这些内容

995
01:24:44,439 --> 01:24:45,279
固化？

996
01:24:47,679 --> 01:24:50,679
是的，固化，我们还没有准备好固化

997
01:24:50,679 --> 01:24:52,599
这是我的看法，不过

998
01:24:53,379 --> 01:24:56,079
你认为固化是

999
01:24:56,079 --> 01:25:01,079
我们可以控制的事情，还是即将发生的事情？

1000
01:25:01,079 --> 01:25:05,680
这确实取决于我们准备承担多少

1002
01:25:09,479 --> 01:25:12,800
所需的风险和实施时间。

1003
01:25:12,800 --> 01:25:14,880
针对剩余的项目，

1004
01:25:14,880 --> 01:25:19,140
我认为目前路线图的大部分内容已经趋于固定。

1005
01:25:19,140 --> 01:25:21,640
因此，大家普遍达成了共识，

1006
01:25:21,640 --> 01:25:22,960
我们需要实现 Verkle Trees。

1007
01:25:22,960 --> 01:25:27,399
尽管在过渡过程中会面临极大的复杂性和风险，

1008
01:25:27,939 --> 01:25:29,939
但这是我们明确要完成的任务。

1009
01:25:31,300 --> 01:25:35,380
不过，我认为在某个时间点，例如未来的10到15年，

1010
01:25:35,380 --> 01:25:36,520
当所有这些事项完成后，

1011
01:25:36,699 --> 01:25:40,779
想要继续提出新的更改将会变得更加困难。

1012
01:25:40,779 --> 01:25:45,060
这与我们当前需要承担的风险水平是相一致的。

1013
01:25:46,180 --> 01:25:49,659
我认为，就像尼克索在聊天中提到的那样，

1014
01:25:49,659 --> 01:25:51,579
固化并不一定是

1015
01:25:51,579 --> 01:25:54,139
完全可能的。总是会有

1016
01:25:54,139 --> 01:25:56,079
某些情况发生，

1017
01:25:56,079 --> 01:25:58,019
迫使我们必须

1018
01:25:58,019 --> 01:25:59,859
对某些内容进行更改。

1019
01:25:59,859 --> 01:26:01,479
但必须有充分的理由。

1020
01:26:01,479 --> 01:26:03,519
我更希望看到

1021
01:26:03,519 --> 01:26:05,599
那扇门稍微留一条缝隙

1022
01:26:05,599 --> 01:26:07,420
即使这意味着是一场艰难的

1023
01:26:07,420 --> 01:26:09,500
上坡战斗

1024
01:26:09,500 --> 01:26:11,479
并且变得越来越困难

1025
01:26:11,479 --> 01:26:12,220
每一步都像攻克堡垒

1026
01:26:14,099 --> 01:26:15,119
当然，是的

1027
01:26:15,619 --> 01:26:17,539
为了澄清，“骨化”

1028
01:26:17,539 --> 01:26:18,899
指的是

1029
01:26:18,899 --> 01:26:26,519
协议的硬化，或者说使其升级变得更加困难

1030
01:26:26,519 --> 01:26:32,099
无论出于何种原因，你知道，很多人都有利益相关

1031
01:26:32,099 --> 01:26:39,839
事情发生了，你知道的，达成对话和共识非常困难，而且很多

1032
01:26:39,839 --> 01:26:46,899
可能的变更都会带来挑战。

1033
01:26:48,899 --> 01:27:00,239
好的。聊天中还有其他问题吗？

1034
01:27:00,239 --> 01:27:13,439
是的，固化不一定像你想的那样是一件坏事。

1035
01:27:13,439 --> 01:27:27,719
太棒了。那么，Mario，你最后还有什么想法吗？嗯，我还有一个问题。

1036
01:27:27,720 --> 01:27:33,560
关于猫的——我们可以让它成为EPF研究小组的吉祥物吗？

1037
01:27:33,560 --> 01:27:36,400
就像我们一样，我们还在寻找一个吉祥物。

1038
01:27:36,400 --> 01:27:38,400
所以，它可以和我们一起发布。

1039
01:27:38,920 --> 01:27:39,140
是的。

1040
01:27:39,140 --> 01:27:41,079
这只橙色的猫叫做 Mimir

1041
01:27:41,079 --> 01:27:42,920
我刚刚在聊天中分享了它的名字

1042
01:27:43,020 --> 01:27:43,699
m-i-m-i-r

1043
01:27:43,699 --> 01:27:44,420
哈哈哈

1044
01:27:45,119 --> 01:27:46,320
它真的非常橙

1045
01:27:47,100 --> 01:27:47,680
非常感谢

1046
01:27:47,680 --> 01:27:47,860
是的

1047
01:27:47,860 --> 01:27:48,400
我们很喜欢它

1048
01:27:48,400 --> 01:27:49,280
我们很喜欢你的分享

1049
01:27:49,280 --> 01:27:49,480
是的

1050
01:27:49,480 --> 01:27:51,320
非常感谢你，Dom，真的很精彩

1051
01:27:51,320 --> 01:27:56,659
是的，我们真的非常感激，嗯，嗯，所有的内容

1052
01:27:56,659 --> 01:28:01,779
尤其是你深入讲解路线图的每个细节

1053
01:28:01,779 --> 01:28:05,779
同时还要应对聊天中的提问和猫咪的干扰

1054
01:28:06,340 --> 01:28:11,619
我们真的非常感激，是的，这真是太棒了，非常感谢你抽时间与我们交流

1055
01:28:11,619 --> 01:28:17,939
在Discord上，我们可以继续讨论一些问题，希望你能参与

1056
01:28:18,500 --> 01:28:22,659
谢谢你邀请我，这真是一次很棒的分享，我非常喜欢路线图的内容

1057
01:28:22,659 --> 01:28:34,519
好的，那么我们周四再见，届时会和Mario一起进行一个研讨会

1058
01:28:34,519 --> 01:28:41,340
是的，本周四我们会继续，我会和大家见面

1059
01:28:41,340 --> 01:28:47,599
进行一个更实用、更动手的研讨会

1060
01:28:47,600 --> 01:28:57,720
下周一我们还会继续，我们将开启研究小组的第二阶段

1061
01:28:57,800 --> 01:29:04,640
我将分享本周晚些时候在Wiki的接下来五个星期的确切时间表

1062
01:29:05,100 --> 01:29:10,000
但是，为了让你提出注意，下周，周一和周四也将在常规时间进行谈判

1063
01:29:10,000 --> 01:29:13,820
所以，我星期四和下周见

1064
01:29:13,819 --> 01:29:20,979
非常感谢大家，我们将在星期四见到你，谢谢你见

1065
01:29:20,979 --> 01:29:23,380
非常感谢你再次参与

1066
01:30:13,819 --> 01:30:21,219
谢谢

